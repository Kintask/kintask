===== ./.env.example =====
# .env.example

# --- Server Configuration ---
PORT=3001

# --- OpenRouter Configuration ---
# Get your API key from https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# --- RecallNet Configuration ---
# Your private key (hex format, optionally prefixed with 0x) for the wallet used with Recall SDK
# Ensure this wallet has Recall testnet tokens (RTC) and potentially parent network tokens for deposits if needed.
RECALL_PRIVATE_KEY=0xyour_recall_wallet_private_key_here_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# Optional: Pre-configure the Recall log bucket address to speed up initialization.
# If commented out, the service will try to find/create a bucket with alias 'kintask-log-bucket-v1'.
# RECALL_LOG_BUCKET=0x...

# --- L2 & Timelock Configuration ---
# RPC URL for the Layer 2 network where the KintaskCommitment contract and Blocklock are deployed.
# Supported examples (Base Sepolia, Optimism Sepolia, Arbitrum Sepolia, Polygon Amoy)
# Ensure this matches the network used for deployment.
L2_RPC_URL=https://sepolia.base.org # Example: Base Sepolia

# Private key for the wallet that will interact with the KintaskCommitment contract (sending commit transactions).
# Ensure this wallet has L2 network native tokens (e.g., Sepolia ETH for Base Sepolia) for gas fees.
WALLET_PRIVATE_KEY=0xyour_l2_interaction_wallet_private_key_here_xxxxxxxxxxxxxxxxxxxx

# Deployed address of the KintaskCommitment contract on the specified L2_RPC_URL network.
# Get this after deploying the contract (e.g., via `pnpm contracts:deploy --network your_l2_network_name`).
KINTASK_CONTRACT_ADDRESS=0xYourKintaskCommitmentContractAddressOnL2

# Deployed address of the Blocklock Sender Proxy contract on the specified L2_RPC_URL network.
# Find the official Blocklock deployment address for your chosen L2 network.
# Check Blocklock documentation or their deployment addresses list.
BLOCKLOCK_SENDER_PROXY_ADDRESS=0xYourBlocklockSenderProxyAddressOnL2

# --- Knowledge Graph & IPFS Configuration ---
# CID of the uploaded knowledge base index file (index.json) on IPFS/Filecoin.
# Run `pnpm kg:upload` in the root directory to generate and upload this, then paste the root CID here.
KB_INDEX_CID=bafy...your_uploaded_kg_index_root_cid

# Optional: Override the default IPFS Gateway used for retrieving the index and fragments.
# Defaults to 'https://w3s.link/ipfs/' if not set. Use a trailing slash.
# IPFS_GATEWAY_URL=https://your-preferred-gateway.com/ipfs/

# --- W3UP/Storacha Configuration (Optional - Kept for potential future use) ---
# Email associated with your w3up agent space.
# W3UP_AGENT_EMAIL=your-agent-email@example.com
# DID of the w3up space where KG data *might* be stored (if using w3up directly).
# KINTASK_SPACE_DID=did:key:zYourW3upSpaceDidKey===== ./dist/config.js =====
"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
// kintask/packages/backend/src/config.ts
const dotenv_1 = __importDefault(require("dotenv"));
const path_1 = __importDefault(require("path"));
// Load .env file specifically from the backend package root
dotenv_1.default.config({ path: path_1.default.resolve(__dirname, '../.env') });
const config = {
    port: process.env.PORT || 3001,
    // OpenRouter Config
    openRouterApiKey: process.env.OPENROUTER_API_KEY,
    // W3UP/Storacha Config
    w3upAgentEmail: process.env.W3UP_AGENT_EMAIL,
    kintaskSpaceDid: process.env.KINTASK_SPACE_DID,
    // KG Index CID
    knowledgeBaseIndexCid: process.env.KB_INDEX_CID,
    // IPFS Gateway for Retrieval (Optional Override)
    ipfsGatewayUrl: process.env.IPFS_GATEWAY_URL || 'https://w3s.link/ipfs/', // Default to w3s.link
    // Recall Config
    recallApiKey: process.env.RECALL_API_KEY,
    recallApiEndpoint: process.env.RECALL_API_ENDPOINT,
    // L2 & Wallet Config
    l2RpcUrl: process.env.L2_RPC_URL,
    walletPrivateKey: process.env.WALLET_PRIVATE_KEY,
    kintaskContractAddress: process.env.KINTASK_CONTRACT_ADDRESS,
    blocklockSenderProxyAddress: process.env.BLOCKLOCK_SENDER_PROXY_ADDRESS,
};
// Runtime validation for critical variables
// Note: Making recallApiKey and recallApiEndpoint optional for simulation
const requiredEnvVars = [
    'openRouterApiKey',
    'w3upAgentEmail',
    'kintaskSpaceDid',
    'knowledgeBaseIndexCid', // Still optional initially until script is run
    'l2RpcUrl',
    'walletPrivateKey',
    'kintaskContractAddress',
    'blocklockSenderProxyAddress',
];
let missingVars = false;
requiredEnvVars.forEach((varName) => {
    // Allow KB_INDEX_CID to be missing initially
    if (varName === 'knowledgeBaseIndexCid' && !config[varName]) {
        console.warn(`Warning: ${varName} is not set. Run the KG upload script ('pnpm kg:upload') first.`);
        return; // Don't mark as fatal error yet
    }
    if (!config[varName]) {
        console.error(`FATAL ERROR: Environment variable ${varName} is not set in packages/backend/.env`);
        missingVars = true;
    }
});
// Optional Recall check
if (!config.recallApiKey || !config.recallApiEndpoint) {
    console.warn("Warning: Recall API Key/Endpoint not set. Recall logging will be simulated.");
}
// Validate Space DID format (basic check)
if (config.kintaskSpaceDid && !config.kintaskSpaceDid.startsWith('did:key:')) {
    console.error(`FATAL ERROR: KINTASK_SPACE_DID (${config.kintaskSpaceDid}) in packages/backend/.env does not look like a valid did:key identifier.`);
    missingVars = true; // Treat as fatal
}
if (missingVars) {
    console.error("\nPlease configure the required variables in packages/backend/.env and restart.");
    process.exit(1); // Exit if critical config is missing
}
exports.default = config;
//# sourceMappingURL=config.js.map===== ./dist/config.js.map =====
{"version":3,"file":"config.js","sourceRoot":"","sources":["../src/config.ts"],"names":[],"mappings":";;;;;AAAA,yCAAyC;AACzC,oDAA4B;AAC5B,gDAAwB;AAExB,4DAA4D;AAC5D,gBAAM,CAAC,MAAM,CAAC,EAAE,IAAI,EAAE,cAAI,CAAC,OAAO,CAAC,SAAS,EAAE,SAAS,CAAC,EAAE,CAAC,CAAC;AAE5D,MAAM,MAAM,GAAG;IACb,IAAI,EAAE,OAAO,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI;IAC9B,oBAAoB;IACpB,gBAAgB,EAAE,OAAO,CAAC,GAAG,CAAC,kBAAkB;IAChD,uBAAuB;IACvB,cAAc,EAAE,OAAO,CAAC,GAAG,CAAC,gBAAgB;IAC5C,eAAe,EAAE,OAAO,CAAC,GAAG,CAAC,iBAAiB;IAC9C,eAAe;IACf,qBAAqB,EAAE,OAAO,CAAC,GAAG,CAAC,YAAY;IAC/C,iDAAiD;IACjD,cAAc,EAAE,OAAO,CAAC,GAAG,CAAC,gBAAgB,IAAI,wBAAwB,EAAE,sBAAsB;IAChG,gBAAgB;IAChB,YAAY,EAAE,OAAO,CAAC,GAAG,CAAC,cAAc;IACxC,iBAAiB,EAAE,OAAO,CAAC,GAAG,CAAC,mBAAmB;IAClD,qBAAqB;IACrB,QAAQ,EAAE,OAAO,CAAC,GAAG,CAAC,UAAU;IAChC,gBAAgB,EAAE,OAAO,CAAC,GAAG,CAAC,kBAAkB;IAChD,sBAAsB,EAAE,OAAO,CAAC,GAAG,CAAC,wBAAwB;IAC5D,2BAA2B,EAAE,OAAO,CAAC,GAAG,CAAC,8BAA8B;CACxE,CAAC;AAEF,4CAA4C;AAC5C,0EAA0E;AAC1E,MAAM,eAAe,GAA8F;IAC/G,kBAAkB;IAClB,gBAAgB;IAChB,iBAAiB;IACjB,uBAAuB,EAAE,+CAA+C;IACxE,UAAU;IACV,kBAAkB;IAClB,wBAAwB;IACxB,6BAA6B;CAChC,CAAC;AAEF,IAAI,WAAW,GAAG,KAAK,CAAC;AACxB,eAAe,CAAC,OAAO,CAAC,CAAC,OAAO,EAAE,EAAE;IAClC,6CAA6C;IAC7C,IAAI,OAAO,KAAK,uBAAuB,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,EAAE,CAAC;QAC1D,OAAO,CAAC,IAAI,CAAC,YAAY,OAAO,iEAAiE,CAAC,CAAC;QACnG,OAAO,CAAC,gCAAgC;IAC5C,CAAC;IACD,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,EAAE,CAAC;QACrB,OAAO,CAAC,KAAK,CAAC,qCAAqC,OAAO,sCAAsC,CAAC,CAAC;QAClG,WAAW,GAAG,IAAI,CAAC;IACrB,CAAC;AACH,CAAC,CAAC,CAAC;AAEH,wBAAwB;AACxB,IAAI,CAAC,MAAM,CAAC,YAAY,IAAI,CAAC,MAAM,CAAC,iBAAiB,EAAE,CAAC;IACpD,OAAO,CAAC,IAAI,CAAC,6EAA6E,CAAC,CAAC;AAChG,CAAC;AAED,0CAA0C;AAC1C,IAAI,MAAM,CAAC,eAAe,IAAI,CAAC,MAAM,CAAC,eAAe,CAAC,UAAU,CAAC,UAAU,CAAC,EAAE,CAAC;IAC3E,OAAO,CAAC,KAAK,CAAC,mCAAmC,MAAM,CAAC,eAAe,2EAA2E,CAAC,CAAC;IACpJ,WAAW,GAAG,IAAI,CAAC,CAAC,iBAAiB;AACzC,CAAC;AAGD,IAAI,WAAW,EAAE,CAAC;IACd,OAAO,CAAC,KAAK,CAAC,iFAAiF,CAAC,CAAC;IACjG,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,qCAAqC;AAC1D,CAAC;AAED,kBAAe,MAAM,CAAC"}===== ./dist/contracts/abi/KintaskCommitment.json =====
// ACTION REQUIRED:
// AFTER RUNNING `pnpm contracts:compile` in the root directory,
// COPY THE CONTENT OF THE FILE:
// `packages/contracts/artifacts/contracts/KintaskCommitment.sol/KintaskCommitment.json`
// AND PASTE IT HERE, REPLACING THIS COMMENT BLOCK AND THE EMPTY {}
{}
===== ./dist/contracts/addresses.js =====
"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.KINTASK_COMMITMENT_CONTRACT_ADDRESS = void 0;
const config_1 = __importDefault(require("../config"));
exports.KINTASK_COMMITMENT_CONTRACT_ADDRESS = config_1.default.kintaskContractAddress || '';
// Add other contract addresses if needed
if (!exports.KINTASK_COMMITMENT_CONTRACT_ADDRESS && process.env.NODE_ENV !== 'test') { // Don't warn during tests maybe
    console.warn("Backend Config Warning: KintaskCommitment Contract address (KINTASK_CONTRACT_ADDRESS) is not set in .env!");
}
//# sourceMappingURL=addresses.js.map===== ./dist/contracts/addresses.js.map =====
{"version":3,"file":"addresses.js","sourceRoot":"","sources":["../../src/contracts/addresses.ts"],"names":[],"mappings":";;;;;;AAAA,uDAA+B;AAElB,QAAA,mCAAmC,GAAG,gBAAM,CAAC,sBAAsB,IAAI,EAAE,CAAC;AAEvF,yCAAyC;AAEzC,IAAI,CAAC,2CAAmC,IAAI,OAAO,CAAC,GAAG,CAAC,QAAQ,KAAK,MAAM,EAAE,CAAC,CAAC,gCAAgC;IAC3G,OAAO,CAAC,IAAI,CAAC,2GAA2G,CAAC,CAAC;AAC9H,CAAC"}===== ./dist/controllers/verifyController.js =====
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.handleVerifyRequest = handleVerifyRequest;
const generatorService_1 = require("../services/generatorService");
const verifierService_1 = require("../services/verifierService");
const recallService_1 = require("../services/recallService");
const utils_1 = require("../utils");
async function handleVerifyRequest(req, res, next) {
    const { question } = req.body;
    const requestTimestamp = new Date().toISOString();
    // Create a unique context ID for this specific request to correlate Recall logs
    const uniqueRequestContext = `req_${Date.now()}_${Math.random().toString(16).substring(2, 8)}`;
    // --- Input Validation ---
    if (!question || typeof question !== 'string' || question.trim() === '') {
        res.status(400).json({ error: 'Invalid request body. Non-empty "question" string is required.' });
        return;
    }
    if (question.length > 1500) { // Limit question length
        res.status(400).json({ error: 'Question exceeds maximum length (1500 characters).' });
        return;
    }
    let verificationResult = null;
    let finalAnswer = "Processing..."; // Initial state
    console.log(`[Controller] Handling request ${uniqueRequestContext} for question: "${question.substring(0, 50)}..."`);
    try {
        // --- Log Start ---
        // Use await to ensure start is logged before proceeding, good for tracing flows
        await (0, recallService_1.logRecallEvent)('VERIFICATION_START', { question: question.substring(0, 200) + (question.length > 200 ? '...' : '') }, uniqueRequestContext);
        // --- 1. Generate Answer (Mocked) ---
        finalAnswer = await (0, generatorService_1.generateAnswer)(question);
        // Check if mock returned an error string
        if (finalAnswer.startsWith('Error:')) {
            await (0, recallService_1.logRecallEvent)('VERIFICATION_ERROR', { step: 'GeneratorMock', error: finalAnswer }, uniqueRequestContext);
            throw new Error(`Mock Generator failed: ${finalAnswer}`);
        }
        await (0, recallService_1.logRecallEvent)('GENERATOR_MOCK_USED', { question: question.substring(0, 50) + '...', generatedAnswer: finalAnswer.substring(0, 50) + '...' }, uniqueRequestContext);
        // --- 2. Perform Verification ---
        verificationResult = await (0, verifierService_1.performVerification)(question, finalAnswer, uniqueRequestContext);
        // Handle critical failure within the verification service itself
        if (!verificationResult) {
            await (0, recallService_1.logRecallEvent)('VERIFICATION_ERROR', { step: 'Verifier', error: "Verifier service returned null" }, uniqueRequestContext);
            throw new Error("Verification service failed to produce a result.");
        }
        // Handle error status returned by the verifier (e.g., Timelock Failed)
        if (verificationResult.finalVerdict.startsWith('Error:')) {
            console.warn(`[Controller] Verification completed with error status: ${verificationResult.finalVerdict}`);
            // Error already logged within performVerification via addStep
            // We will still return a 200 OK but include the error status in the payload
        }
        else {
            // Log successful completion calculation only if no error status from verifier
            await (0, recallService_1.logRecallEvent)('FINAL_VERDICT_CALCULATED', {
                calculatedVerdict: verificationResult.finalVerdict,
                confidence: verificationResult.confidenceScore,
                usedCidsCount: verificationResult.usedFragmentCids.length,
                timelockRequestId: verificationResult.timelockRequestId,
            }, uniqueRequestContext);
        }
        // Log completion of controller handling for this request
        await (0, recallService_1.logRecallEvent)('VERIFICATION_COMPLETE', { finalStatus: verificationResult.finalVerdict }, uniqueRequestContext);
        // --- 3. Prepare SUCCESS API Response Payload ---
        const recallTrace = await (0, recallService_1.getTraceFromRecall)(uniqueRequestContext); // Fetch trace for response
        const responsePayload = {
            answer: finalAnswer,
            status: verificationResult.finalVerdict,
            confidence: verificationResult.confidenceScore,
            usedFragmentCids: verificationResult.usedFragmentCids,
            timelockRequestId: verificationResult.timelockRequestId,
            timelockTxExplorerUrl: verificationResult.timelockCommitTxHash
                ? (0, utils_1.getL2ExplorerUrl)(verificationResult.timelockCommitTxHash) // Util handles undefined RPC/ChainID
                : undefined,
            recallTrace: recallTrace,
            // recallExplorerUrl: // TODO: Add if Recall provides one based on context/trace ID
        };
        console.log(`[Controller] Sending successful response for request ${uniqueRequestContext}`);
        res.status(200).json(responsePayload);
    }
    catch (error) {
        console.error(`[Controller Error Request: ${uniqueRequestContext}]:`, error.message);
        // Log the error that reached the controller catch block
        await (0, recallService_1.logRecallEvent)('VERIFICATION_ERROR', { controllerError: error.message, stack: error.stack?.substring(0, 300) }, uniqueRequestContext);
        // --- Prepare ERROR API Response Payload ---
        const recallTraceOnError = await (0, recallService_1.getTraceFromRecall)(uniqueRequestContext); // Attempt to get trace even on error
        const errorResponse = {
            answer: finalAnswer === "Processing..." ? "Failed to process request." : finalAnswer, // Show generated answer if available
            status: verificationResult?.finalVerdict || 'Error: Verification Failed', // Show status if verifier ran partially
            error: 'Verification process encountered an error.', // Generic error for frontend
            details: error.message, // Specific error message
            recallTrace: recallTraceOnError // Include trace up to failure point
        };
        res.status(500).json(errorResponse);
    }
}
//# sourceMappingURL=verifyController.js.map===== ./dist/controllers/verifyController.js.map =====
{"version":3,"file":"verifyController.js","sourceRoot":"","sources":["../../src/controllers/verifyController.ts"],"names":[],"mappings":";;AAQA,kDAmGC;AA1GD,mEAA8D;AAC9D,iEAAkE;AAClE,6DAA+E;AAE/E,oCAA4C;AAGrC,KAAK,UAAU,mBAAmB,CAAC,GAAY,EAAE,GAAa,EAAE,IAAkB;IACvF,MAAM,EAAE,QAAQ,EAAE,GAAG,GAAG,CAAC,IAAI,CAAC;IAC9B,MAAM,gBAAgB,GAAG,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE,CAAC;IAClD,gFAAgF;IAChF,MAAM,oBAAoB,GAAG,OAAO,IAAI,CAAC,GAAG,EAAE,IAAI,IAAI,CAAC,MAAM,EAAE,CAAC,QAAQ,CAAC,EAAE,CAAC,CAAC,SAAS,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC;IAE/F,2BAA2B;IAC3B,IAAI,CAAC,QAAQ,IAAI,OAAO,QAAQ,KAAK,QAAQ,IAAI,QAAQ,CAAC,IAAI,EAAE,KAAK,EAAE,EAAE,CAAC;QACxE,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,gEAAgE,EAAE,CAAC,CAAC;QAClG,OAAO;IACT,CAAC;IACD,IAAI,QAAQ,CAAC,MAAM,GAAG,IAAI,EAAE,CAAC,CAAC,wBAAwB;QACjD,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,oDAAoD,EAAE,CAAC,CAAC;QACtF,OAAO;IACZ,CAAC;IAED,IAAI,kBAAkB,GAAsC,IAAI,CAAC;IACjE,IAAI,WAAW,GAAG,eAAe,CAAC,CAAC,gBAAgB;IAEnD,OAAO,CAAC,GAAG,CAAC,iCAAiC,oBAAoB,mBAAmB,QAAQ,CAAC,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC,MAAM,CAAC,CAAC;IACrH,IAAI,CAAC;QACH,oBAAoB;QACpB,gFAAgF;QAChF,MAAM,IAAA,8BAAc,EAAC,oBAAoB,EAAE,EAAE,QAAQ,EAAE,QAAQ,CAAC,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAM,GAAG,GAAG,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,oBAAoB,CAAC,CAAC;QAElJ,sCAAsC;QACtC,WAAW,GAAG,MAAM,IAAA,iCAAc,EAAC,QAAQ,CAAC,CAAC;QAC7C,yCAAyC;QACzC,IAAI,WAAW,CAAC,UAAU,CAAC,QAAQ,CAAC,EAAE,CAAC;YAClC,MAAM,IAAA,8BAAc,EAAC,oBAAoB,EAAE,EAAE,IAAI,EAAE,eAAe,EAAE,KAAK,EAAE,WAAW,EAAE,EAAE,oBAAoB,CAAC,CAAC;YAChH,MAAM,IAAI,KAAK,CAAC,0BAA0B,WAAW,EAAE,CAAC,CAAC;QAC9D,CAAC;QACD,MAAM,IAAA,8BAAc,EAAC,qBAAqB,EAAE,EAAE,QAAQ,EAAE,QAAQ,CAAC,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC,GAAG,KAAK,EAAE,eAAe,EAAE,WAAW,CAAC,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC,GAAG,KAAK,EAAE,EAAE,oBAAoB,CAAC,CAAC;QAG1K,kCAAkC;QAClC,kBAAkB,GAAG,MAAM,IAAA,qCAAmB,EAAC,QAAQ,EAAE,WAAW,EAAE,oBAAoB,CAAC,CAAC;QAE5F,iEAAiE;QACjE,IAAI,CAAC,kBAAkB,EAAE,CAAC;YACtB,MAAM,IAAA,8BAAc,EAAC,oBAAoB,EAAE,EAAE,IAAI,EAAE,UAAU,EAAE,KAAK,EAAE,gCAAgC,EAAE,EAAE,oBAAoB,CAAC,CAAC;YAChI,MAAM,IAAI,KAAK,CAAC,kDAAkD,CAAC,CAAC;QACxE,CAAC;QACD,uEAAuE;QACvE,IAAI,kBAAkB,CAAC,YAAY,CAAC,UAAU,CAAC,QAAQ,CAAC,EAAE,CAAC;YACtD,OAAO,CAAC,IAAI,CAAC,0DAA0D,kBAAkB,CAAC,YAAY,EAAE,CAAC,CAAC;YAC1G,8DAA8D;YAC9D,4EAA4E;QACjF,CAAC;aAAM,CAAC;YACJ,8EAA8E;YAC9E,MAAM,IAAA,8BAAc,EAChB,0BAA0B,EAC1B;gBACI,iBAAiB,EAAE,kBAAkB,CAAC,YAAY;gBAClD,UAAU,EAAE,kBAAkB,CAAC,eAAe;gBAC9C,aAAa,EAAE,kBAAkB,CAAC,gBAAgB,CAAC,MAAM;gBACzD,iBAAiB,EAAE,kBAAkB,CAAC,iBAAiB;aAC1D,EACD,oBAAoB,CACvB,CAAC;QACN,CAAC;QAED,yDAAyD;QACzD,MAAM,IAAA,8BAAc,EAAC,uBAAuB,EAAE,EAAE,WAAW,EAAE,kBAAkB,CAAC,YAAY,EAAE,EAAE,oBAAoB,CAAC,CAAC;QAEtH,kDAAkD;QAClD,MAAM,WAAW,GAAG,MAAM,IAAA,kCAAkB,EAAC,oBAAoB,CAAC,CAAC,CAAC,2BAA2B;QAC/F,MAAM,eAAe,GAAsB;YACvC,MAAM,EAAE,WAAW;YACnB,MAAM,EAAE,kBAAkB,CAAC,YAAY;YACvC,UAAU,EAAE,kBAAkB,CAAC,eAAe;YAC9C,gBAAgB,EAAE,kBAAkB,CAAC,gBAAgB;YACrD,iBAAiB,EAAE,kBAAkB,CAAC,iBAAiB;YACvD,qBAAqB,EAAE,kBAAkB,CAAC,oBAAoB;gBAC1D,CAAC,CAAC,IAAA,wBAAgB,EAAC,kBAAkB,CAAC,oBAAoB,CAAC,CAAC,qCAAqC;gBACjG,CAAC,CAAC,SAAS;YACf,WAAW,EAAE,WAAW;YACxB,mFAAmF;SACtF,CAAC;QAEF,OAAO,CAAC,GAAG,CAAC,wDAAwD,oBAAoB,EAAE,CAAC,CAAC;QAC5F,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;IAExC,CAAC;IAAC,OAAO,KAAU,EAAE,CAAC;QACpB,OAAO,CAAC,KAAK,CAAC,8BAA8B,oBAAoB,IAAI,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;QACrF,wDAAwD;QACxD,MAAM,IAAA,8BAAc,EAAC,oBAAoB,EAAE,EAAE,eAAe,EAAE,KAAK,CAAC,OAAO,EAAE,KAAK,EAAE,KAAK,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,EAAE,EAAE,oBAAoB,CAAC,CAAC;QAE5I,6CAA6C;QAC7C,MAAM,kBAAkB,GAAG,MAAM,IAAA,kCAAkB,EAAC,oBAAoB,CAAC,CAAC,CAAC,qCAAqC;QAChH,MAAM,aAAa,GAAsB;YACrC,MAAM,EAAE,WAAW,KAAK,eAAe,CAAC,CAAC,CAAC,4BAA4B,CAAC,CAAC,CAAC,WAAW,EAAE,qCAAqC;YAC3H,MAAM,EAAE,kBAAkB,EAAE,YAAY,IAAI,4BAA4B,EAAE,wCAAwC;YAClH,KAAK,EAAE,4CAA4C,EAAE,6BAA6B;YAClF,OAAO,EAAE,KAAK,CAAC,OAAO,EAAE,yBAAyB;YACjD,WAAW,EAAE,kBAAkB,CAAC,oCAAoC;SACvE,CAAC;QACF,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC;IACtC,CAAC;AACH,CAAC"}===== ./dist/routes/verify.js =====
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const express_1 = require("express");
const verifyController_1 = require("../controllers/verifyController");
const router = (0, express_1.Router)();
/**
 * @route POST /api/verify
 * @description Endpoint to receive a question, generate an answer, verify it,
 *              commit the verdict via timelock, log the process to Recall,
 *              and return the results.
 * @body { "question": "string" } - The user's question. Max length ~1500 chars recommended.
 * @returns {ApiVerifyResponse} 200 - Success response with answer, status, proofs.
 * @returns {object} 400 - Invalid request body (missing question, too long, etc.).
 * @returns {object} 500 - Internal server error during processing.
 */
router.post('/verify', verifyController_1.handleVerifyRequest);
exports.default = router;
//# sourceMappingURL=verify.js.map===== ./dist/routes/verify.js.map =====
{"version":3,"file":"verify.js","sourceRoot":"","sources":["../../src/routes/verify.ts"],"names":[],"mappings":";;AAAA,qCAAiC;AACjC,sEAAsE;AAEtE,MAAM,MAAM,GAAG,IAAA,gBAAM,GAAE,CAAC;AAExB;;;;;;;;;GASG;AACH,MAAM,CAAC,IAAI,CAAC,SAAS,EAAE,sCAAmB,CAAC,CAAC;AAE5C,kBAAe,MAAM,CAAC"}===== ./dist/server.js =====
"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const express_1 = __importDefault(require("express"));
const cors_1 = __importDefault(require("cors"));
const config_1 = __importDefault(require("./config"));
const verify_1 = __importDefault(require("./routes/verify"));
const timelockService_1 = require("./services/timelockService"); // Import listener controls
const app = (0, express_1.default)();
const port = config_1.default.port;
// --- Middleware ---
app.use((0, cors_1.default)()); // Allow requests from frontend (configure origins for production)
app.use(express_1.default.json({ limit: '1mb' })); // Parse JSON request bodies, limit size
app.use((req, res, next) => {
    const start = Date.now();
    res.on('finish', () => {
        const duration = Date.now() - start;
        console.log(`[${new Date().toISOString()}] ${req.method} ${req.originalUrl} ${res.statusCode} ${duration}ms`);
    });
    next();
});
// --- Routes ---
app.use('/api', verify_1.default);
// Root Route / Health Check
app.get('/', (req, res) => {
    res.status(200).json({ status: 'ok', message: 'Kintask Backend is running!' });
});
// --- 404 Handler ---
// Catch-all for routes not defined
app.use((req, res, next) => {
    res.status(404).json({ error: 'Not Found', message: `Endpoint ${req.method} ${req.path} does not exist.` });
});
// --- Global Error Handler ---
// Catches errors passed via next(error)
app.use((err, req, res, next) => {
    console.error("[Global Error Handler]:", err.stack || err);
    // Avoid sending stack trace in production
    const message = process.env.NODE_ENV === 'production' ? 'An unexpected error occurred.' : err.message;
    res.status(500).json({
        error: 'Internal Server Error',
        message: message,
    });
});
// --- Start Server ---
const server = app.listen(port, () => {
    console.log(`[server]: Kintask Backend server is running at http://localhost:${port}`);
    // Initialize Timelock Listener on startup
    try {
        (0, timelockService_1.startRevealListener)();
    }
    catch (listenerError) {
        console.error("[Server Startup] Failed to start Timelock listener:", listenerError);
    }
});
// --- Graceful Shutdown ---
const gracefulShutdown = (signal) => {
    console.log(`\n${signal} signal received: closing HTTP server...`);
    // Stop listener first
    (0, timelockService_1.stopRevealListener)();
    server.close(() => {
        console.log('HTTP server closed.');
        // Perform other cleanup if needed (e.g., DB connections)
        console.log("Exiting process.");
        process.exit(0);
    });
    // Force close server after a timeout if graceful shutdown fails
    setTimeout(() => {
        console.error('Could not close connections in time, forcefully shutting down');
        process.exit(1);
    }, 10000); // 10 seconds timeout
};
process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT')); // Catches Ctrl+C
//# sourceMappingURL=server.js.map===== ./dist/server.js.map =====
{"version":3,"file":"server.js","sourceRoot":"","sources":["../src/server.ts"],"names":[],"mappings":";;;;;AAAA,sDAA4E;AAC5E,gDAAwB;AACxB,sDAA8B;AAC9B,6DAA2C;AAC3C,gEAAqF,CAAC,2BAA2B;AAEjH,MAAM,GAAG,GAAY,IAAA,iBAAO,GAAE,CAAC;AAC/B,MAAM,IAAI,GAAG,gBAAM,CAAC,IAAI,CAAC;AAEzB,qBAAqB;AACrB,GAAG,CAAC,GAAG,CAAC,IAAA,cAAI,GAAE,CAAC,CAAC,CAAC,kEAAkE;AACnF,GAAG,CAAC,GAAG,CAAC,iBAAO,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,KAAK,EAAE,CAAC,CAAC,CAAC,CAAC,wCAAwC;AACjF,GAAG,CAAC,GAAG,CAAC,CAAC,GAAY,EAAE,GAAa,EAAE,IAAkB,EAAE,EAAE;IACxD,MAAM,KAAK,GAAG,IAAI,CAAC,GAAG,EAAE,CAAC;IACzB,GAAG,CAAC,EAAE,CAAC,QAAQ,EAAE,GAAG,EAAE;QACjB,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,EAAE,GAAG,KAAK,CAAC;QACpC,OAAO,CAAC,GAAG,CAAC,IAAI,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE,KAAK,GAAG,CAAC,MAAM,IAAI,GAAG,CAAC,WAAW,IAAI,GAAG,CAAC,UAAU,IAAI,QAAQ,IAAI,CAAC,CAAC;IACnH,CAAC,CAAC,CAAC;IACH,IAAI,EAAE,CAAC;AACX,CAAC,CAAC,CAAC;AAEH,iBAAiB;AACjB,GAAG,CAAC,GAAG,CAAC,MAAM,EAAE,gBAAY,CAAC,CAAC;AAE9B,4BAA4B;AAC5B,GAAG,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,GAAY,EAAE,GAAa,EAAE,EAAE;IAC3C,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,EAAE,MAAM,EAAE,IAAI,EAAE,OAAO,EAAE,6BAA6B,EAAC,CAAC,CAAC;AAChF,CAAC,CAAC,CAAC;AAEH,sBAAsB;AACtB,mCAAmC;AACnC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,EAAE;IACvB,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,WAAW,EAAE,OAAO,EAAE,YAAY,GAAG,CAAC,MAAM,IAAI,GAAG,CAAC,IAAI,kBAAkB,EAAE,CAAC,CAAC;AAChH,CAAC,CAAC,CAAC;AAGH,+BAA+B;AAC/B,wCAAwC;AACxC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAU,EAAE,GAAY,EAAE,GAAa,EAAE,IAAkB,EAAE,EAAE;IACtE,OAAO,CAAC,KAAK,CAAC,yBAAyB,EAAE,GAAG,CAAC,KAAK,IAAI,GAAG,CAAC,CAAC;IAC3D,0CAA0C;IAC1C,MAAM,OAAO,GAAG,OAAO,CAAC,GAAG,CAAC,QAAQ,KAAK,YAAY,CAAC,CAAC,CAAC,+BAA+B,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC;IACtG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC;QACjB,KAAK,EAAE,uBAAuB;QAC9B,OAAO,EAAE,OAAO;KACnB,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,uBAAuB;AACvB,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,EAAE,GAAG,EAAE;IACnC,OAAO,CAAC,GAAG,CAAC,mEAAmE,IAAI,EAAE,CAAC,CAAC;IACvF,0CAA0C;IAC1C,IAAI,CAAC;QACD,IAAA,qCAAmB,GAAE,CAAC;IAC1B,CAAC;IAAC,OAAO,aAAa,EAAE,CAAC;QACpB,OAAO,CAAC,KAAK,CAAC,qDAAqD,EAAE,aAAa,CAAC,CAAC;IACzF,CAAC;AACH,CAAC,CAAC,CAAC;AAEH,4BAA4B;AAC5B,MAAM,gBAAgB,GAAG,CAAC,MAAc,EAAE,EAAE;IACxC,OAAO,CAAC,GAAG,CAAC,KAAK,MAAM,0CAA0C,CAAC,CAAC;IACnE,sBAAsB;IACtB,IAAA,oCAAkB,GAAE,CAAC;IACrB,MAAM,CAAC,KAAK,CAAC,GAAG,EAAE;QACd,OAAO,CAAC,GAAG,CAAC,qBAAqB,CAAC,CAAC;QACnC,yDAAyD;QACzD,OAAO,CAAC,GAAG,CAAC,kBAAkB,CAAC,CAAC;QAChC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IACpB,CAAC,CAAC,CAAC;IAEH,gEAAgE;IAC/D,UAAU,CAAC,GAAG,EAAE;QACZ,OAAO,CAAC,KAAK,CAAC,+DAA+D,CAAC,CAAC;QAC/E,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IACpB,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,qBAAqB;AACrC,CAAC,CAAC;AAEF,OAAO,CAAC,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE,CAAC,gBAAgB,CAAC,SAAS,CAAC,CAAC,CAAC;AACzD,OAAO,CAAC,EAAE,CAAC,QAAQ,EAAE,GAAG,EAAE,CAAC,gBAAgB,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,iBAAiB"}===== ./dist/services/filecoinService.js =====
"use strict";
// kintask/packages/backend/src/services/filecoinService.ts
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.getKnowledgeIndex = getKnowledgeIndex;
exports.fetchKnowledgeFragment = fetchKnowledgeFragment;
exports.clearFilecoinCache = clearFilecoinCache;
const axios_1 = __importDefault(require("axios"));
const config_1 = __importDefault(require("../config")); // Import configuration to get gateway URL and index CID
// --- Configuration ---
// Use the gateway specified in config, defaulting to a reliable public one (w3s.link)
const IPFS_GATEWAY = config_1.default.ipfsGatewayUrl || 'https://w3s.link/ipfs/';
const MAX_RETRIES = 3; // Number of retry attempts for failed fetches
const RETRY_DELAY_MS = 800; // Initial delay before retrying (will increase exponentially)
const REQUEST_TIMEOUT = 25000; // Timeout for each HTTP request in milliseconds (25 seconds)
console.log(`[Filecoin Service] Using IPFS Gateway for retrieval: ${IPFS_GATEWAY}`);
const cache = new Map();
const CACHE_TTL_MS = 10 * 60 * 1000; // Cache validity duration (e.g., 10 minutes)
// --- Cache Utility Functions ---
/**
 * Stores data in the in-memory cache.
 * @param key - The cache key (typically the CID).
 * @param data - The data to store.
 */
function setCache(key, data) {
    if (!key)
        return; // Do not cache with empty key
    cache.set(key, { data, timestamp: Date.now() });
    // console.log(`[Cache] Set cache for key: ${key.substring(0,10)}...`);
}
/**
 * Retrieves data from the cache if it exists and is not expired.
 * @param key - The cache key (typically the CID).
 * @returns The cached data or null if not found or expired.
 */
function getCache(key) {
    if (!key)
        return null;
    const entry = cache.get(key);
    if (entry && (Date.now() - entry.timestamp < CACHE_TTL_MS)) {
        // console.log(`[Cache] Hit for key: ${key.substring(0,10)}...`);
        return entry.data;
    }
    // console.log(`[Cache] Miss or expired for key: ${key.substring(0,10)}...`);
    cache.delete(key); // Remove expired or non-existent entry
    return null;
}
// --- Core Fetching Logic ---
/**
 * Fetches data from the configured IPFS gateway with caching and retry logic.
 * @param url - The full URL to fetch from the gateway.
 * @param cacheKey - The key to use for caching (typically the CID).
 * @returns The fetched data (parsed as JSON if applicable) or null if fetch fails.
 */
async function fetchWithRetry(url, cacheKey) {
    // 1. Check Cache first
    const cachedData = getCache(cacheKey);
    if (cachedData) {
        return cachedData;
    }
    console.log(`[Filecoin Service] Fetching: ${url} (Cache Key: ${cacheKey.substring(0, 10)}...)`);
    // 2. Attempt Fetch with Retries
    for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
        try {
            const response = await axios_1.default.get(url, {
                timeout: REQUEST_TIMEOUT,
                // Ensure correct headers for potentially receiving JSON
                headers: {
                    'Accept': 'application/json, application/octet-stream, */*',
                    // 'User-Agent': 'KintaskBackend/1.0' // Optional: Identify your client
                }
            });
            // Check content type for JSON if expecting it (primarily for fragments/index)
            const contentType = response.headers['content-type'];
            const isJsonExpected = url.includes(config_1.default.knowledgeBaseIndexCid || 'INVALID_CID') || cacheKey !== config_1.default.knowledgeBaseIndexCid; // Assume fragments & index are JSON
            if (isJsonExpected && (!contentType || !contentType.includes('application/json'))) {
                // Gateways sometimes return HTML error pages or non-JSON for DAG issues
                console.warn(`[Filecoin Service] Attempt ${attempt} for ${cacheKey}: Expected JSON but received Content-Type: ${contentType}. Raw data sample:`, typeof response.data === 'string' ? response.data.substring(0, 100) + '...' : typeof response.data);
                // Treat non-JSON response as an error for expected JSON content
                throw new Error(`Expected JSON content, but received ${contentType || 'unknown content type'}`);
            }
            // Check for successful status code
            if (response.status === 200 && response.data) {
                console.log(`[Filecoin Service] Successfully fetched ${cacheKey.substring(0, 10)}... (Attempt ${attempt})`);
                setCache(cacheKey, response.data); // Cache the successful response
                return response.data;
            }
            else {
                // Log unexpected success status codes (e.g., 204 No Content?)
                console.warn(`[Filecoin Service] Fetch attempt ${attempt} for ${cacheKey} returned unexpected status: ${response.status}`);
                // Continue to retry loop
            }
        }
        catch (error) {
            const axiosError = error;
            console.warn(`[Filecoin Service] Error fetch attempt ${attempt}/${MAX_RETRIES} for ${cacheKey}:`, axiosError.message);
            // Log details from the error response if available
            if (axiosError.response) {
                console.warn(`  Gateway Response Status: ${axiosError.response.status}`);
                // console.warn(`  Gateway Response Headers:`, axiosError.response.headers); // Can be verbose
                // console.warn(`  Gateway Response Data:`, axiosError.response.data); // Can be verbose/large
                // Don't retry on 404 Not Found - the content likely doesn't exist
                if (axiosError.response.status === 404) {
                    console.error(`[Filecoin Service] CID ${cacheKey} not found on gateway (404). Stopping retries.`);
                    return null; // Indicate definitively not found
                }
                // Consider stopping retries on other client errors (4xx) too?
            }
            else if (axiosError.code === 'ECONNABORTED' || axiosError.message.includes('timeout')) {
                console.warn(`  Gateway request timed out.`);
            }
            // If it's the last attempt, log final failure and return null
            if (attempt === MAX_RETRIES) {
                console.error(`[Filecoin Service] Final fetch attempt failed for CID: ${cacheKey} after ${MAX_RETRIES} tries.`);
                return null;
            }
            // Wait before retrying with exponential backoff
            const delay = RETRY_DELAY_MS * Math.pow(2, attempt - 1); // 1s, 2s, 4s...
            console.log(`  Retrying in ${delay}ms...`);
            await new Promise(resolve => setTimeout(resolve, delay));
        }
    }
    // Should not be reached if error handling above is correct, but acts as a fallback
    console.error(`[Filecoin Service] Fetch failed unexpectedly for ${cacheKey} after all attempts.`);
    return null;
}
// --- Exported Service Functions ---
/**
 * Fetches and parses the Knowledge Graph index file from Filecoin/IPFS.
 * @returns The keyword-to-CID index object, or null if fetching fails.
 */
async function getKnowledgeIndex() {
    const indexCid = config_1.default.knowledgeBaseIndexCid;
    if (!indexCid) {
        console.error('[Filecoin Service] FATAL ERROR: KB_INDEX_CID is not configured in backend .env.');
        return null;
    }
    const url = `${IPFS_GATEWAY}${indexCid}`;
    console.log(`[Filecoin Service] Getting Knowledge Index (CID: ${indexCid.substring(0, 10)}...)`);
    const indexFile = await fetchWithRetry(url, indexCid); // Use index CID as cache key
    if (indexFile && typeof indexFile.index === 'object' && indexFile.index !== null) {
        // Optional: Log how many keywords are in the loaded index
        console.log(`[Filecoin Service] Successfully loaded index with ${Object.keys(indexFile.index).length} keywords.`);
        return indexFile.index;
    }
    else {
        console.error(`[Filecoin Service] Failed to fetch or parse index file structure from CID: ${indexCid}`);
        return null;
    }
}
/**
 * Fetches and parses a single Knowledge Fragment JSON object from Filecoin/IPFS using its CID.
 * @param cid - The Content Identifier (CID) of the fragment to fetch.
 * @returns The parsed KnowledgeFragment object, or null if fetching or parsing fails.
 */
async function fetchKnowledgeFragment(cid) {
    // Basic CID format validation
    if (!cid || typeof cid !== 'string' || (!cid.startsWith('bafy') && !cid.startsWith('Qm'))) {
        console.error(`[Filecoin Service] Invalid CID format provided for fragment fetch: ${cid}`);
        return null;
    }
    const url = `${IPFS_GATEWAY}${cid}`;
    // Use fragment CID as the cache key
    const fragment = await fetchWithRetry(url, cid);
    // Optional: Add schema validation here after fetching if needed
    // if (fragment && !isValidKnowledgeFragment(fragment)) {
    //     console.error(`[Filecoin Service] Fetched data for CID ${cid} is not a valid KnowledgeFragment.`);
    //     return null;
    // }
    return fragment;
}
// Optional: Add a function to clear the cache if needed for debugging
function clearFilecoinCache() {
    console.log("[Filecoin Service] Clearing in-memory cache.");
    cache.clear();
}
//# sourceMappingURL=filecoinService.js.map===== ./dist/services/filecoinService.js.map =====
{"version":3,"file":"filecoinService.js","sourceRoot":"","sources":["../../src/services/filecoinService.ts"],"names":[],"mappings":";AAAA,2DAA2D;;;;;AA6J3D,8CAmBC;AAOD,wDAkBC;AAGD,gDAGC;AA7MD,kDAA0C;AAC1C,uDAA+B,CAAC,wDAAwD;AAGxF,wBAAwB;AACxB,sFAAsF;AACtF,MAAM,YAAY,GAAG,gBAAM,CAAC,cAAc,IAAI,wBAAwB,CAAC;AACvE,MAAM,WAAW,GAAG,CAAC,CAAC,CAAC,8CAA8C;AACrE,MAAM,cAAc,GAAG,GAAG,CAAC,CAAC,8DAA8D;AAC1F,MAAM,eAAe,GAAG,KAAK,CAAC,CAAC,6DAA6D;AAE5F,OAAO,CAAC,GAAG,CAAC,wDAAwD,YAAY,EAAE,CAAC,CAAC;AAgBpF,MAAM,KAAK,GAAG,IAAI,GAAG,EAA2B,CAAC;AACjD,MAAM,YAAY,GAAG,EAAE,GAAG,EAAE,GAAG,IAAI,CAAC,CAAC,6CAA6C;AAElF,kCAAkC;AAElC;;;;GAIG;AACH,SAAS,QAAQ,CAAI,GAAW,EAAE,IAAO;IACrC,IAAI,CAAC,GAAG;QAAE,OAAO,CAAC,8BAA8B;IAChD,KAAK,CAAC,GAAG,CAAC,GAAG,EAAE,EAAE,IAAI,EAAE,SAAS,EAAE,IAAI,CAAC,GAAG,EAAE,EAAE,CAAC,CAAC;IAChD,uEAAuE;AAC3E,CAAC;AAED;;;;GAIG;AACH,SAAS,QAAQ,CAAI,GAAW;IAC5B,IAAI,CAAC,GAAG;QAAE,OAAO,IAAI,CAAC;IACtB,MAAM,KAAK,GAAG,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;IAC7B,IAAI,KAAK,IAAI,CAAC,IAAI,CAAC,GAAG,EAAE,GAAG,KAAK,CAAC,SAAS,GAAG,YAAY,CAAC,EAAE,CAAC;QACzD,iEAAiE;QACjE,OAAO,KAAK,CAAC,IAAS,CAAC;IAC3B,CAAC;IACD,6EAA6E;IAC7E,KAAK,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,uCAAuC;IAC1D,OAAO,IAAI,CAAC;AAChB,CAAC;AAED,8BAA8B;AAE9B;;;;;GAKG;AACH,KAAK,UAAU,cAAc,CAAI,GAAW,EAAE,QAAgB;IAC1D,uBAAuB;IACvB,MAAM,UAAU,GAAG,QAAQ,CAAI,QAAQ,CAAC,CAAC;IACzC,IAAI,UAAU,EAAE,CAAC;QACb,OAAO,UAAU,CAAC;IACtB,CAAC;IAED,OAAO,CAAC,GAAG,CAAC,gCAAgC,GAAG,gBAAgB,QAAQ,CAAC,SAAS,CAAC,CAAC,EAAC,EAAE,CAAC,MAAM,CAAC,CAAC;IAE/F,gCAAgC;IAChC,KAAK,IAAI,OAAO,GAAG,CAAC,EAAE,OAAO,IAAI,WAAW,EAAE,OAAO,EAAE,EAAE,CAAC;QACtD,IAAI,CAAC;YACD,MAAM,QAAQ,GAAG,MAAM,eAAK,CAAC,GAAG,CAAI,GAAG,EAAE;gBACrC,OAAO,EAAE,eAAe;gBACxB,wDAAwD;gBACxD,OAAO,EAAE;oBACL,QAAQ,EAAE,iDAAiD;oBAC3D,uEAAuE;iBACzE;aACJ,CAAC,CAAC;YAEJ,8EAA8E;YAC9E,MAAM,WAAW,GAAG,QAAQ,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC;YACrD,MAAM,cAAc,GAAG,GAAG,CAAC,QAAQ,CAAC,gBAAM,CAAC,qBAAqB,IAAI,aAAa,CAAC,IAAI,QAAQ,KAAK,gBAAM,CAAC,qBAAqB,CAAC,CAAC,oCAAoC;YAErK,IAAI,cAAc,IAAI,CAAC,CAAC,WAAW,IAAI,CAAC,WAAW,CAAC,QAAQ,CAAC,kBAAkB,CAAC,CAAC,EAAE,CAAC;gBAChF,wEAAwE;gBACxE,OAAO,CAAC,IAAI,CAAC,8BAA8B,OAAO,QAAQ,QAAQ,8CAA8C,WAAW,oBAAoB,EAAE,OAAO,QAAQ,CAAC,IAAI,KAAK,QAAQ,CAAC,CAAC,CAAC,QAAQ,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,OAAO,QAAQ,CAAC,IAAI,CAAC,CAAC;gBACrP,gEAAgE;gBAC/D,MAAM,IAAI,KAAK,CAAC,uCAAuC,WAAW,IAAI,sBAAsB,EAAE,CAAC,CAAC;YACrG,CAAC;YAED,mCAAmC;YACnC,IAAI,QAAQ,CAAC,MAAM,KAAK,GAAG,IAAI,QAAQ,CAAC,IAAI,EAAE,CAAC;gBAC3C,OAAO,CAAC,GAAG,CAAC,2CAA2C,QAAQ,CAAC,SAAS,CAAC,CAAC,EAAC,EAAE,CAAC,gBAAgB,OAAO,GAAG,CAAC,CAAC;gBAC3G,QAAQ,CAAC,QAAQ,EAAE,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC,gCAAgC;gBACnE,OAAO,QAAQ,CAAC,IAAI,CAAC;YACzB,CAAC;iBAAM,CAAC;gBACJ,8DAA8D;gBAC9D,OAAO,CAAC,IAAI,CAAC,oCAAoC,OAAO,QAAQ,QAAQ,gCAAgC,QAAQ,CAAC,MAAM,EAAE,CAAC,CAAC;gBAC3H,yBAAyB;YAC7B,CAAC;QAEL,CAAC;QAAC,OAAO,KAAU,EAAE,CAAC;YAClB,MAAM,UAAU,GAAG,KAAmB,CAAC;YACvC,OAAO,CAAC,IAAI,CAAC,0CAA0C,OAAO,IAAI,WAAW,QAAQ,QAAQ,GAAG,EAAE,UAAU,CAAC,OAAO,CAAC,CAAC;YAEtH,mDAAmD;YACnD,IAAI,UAAU,CAAC,QAAQ,EAAE,CAAC;gBACrB,OAAO,CAAC,IAAI,CAAC,8BAA8B,UAAU,CAAC,QAAQ,CAAC,MAAM,EAAE,CAAC,CAAC;gBACzE,8FAA8F;gBAC9F,8FAA8F;gBAE9F,kEAAkE;gBAClE,IAAI,UAAU,CAAC,QAAQ,CAAC,MAAM,KAAK,GAAG,EAAE,CAAC;oBACpC,OAAO,CAAC,KAAK,CAAC,0BAA0B,QAAQ,gDAAgD,CAAC,CAAC;oBAClG,OAAO,IAAI,CAAC,CAAC,kCAAkC;gBACpD,CAAC;gBACD,8DAA8D;YACnE,CAAC;iBAAM,IAAI,UAAU,CAAC,IAAI,KAAK,cAAc,IAAI,UAAU,CAAC,OAAO,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE,CAAC;gBACtF,OAAO,CAAC,IAAI,CAAC,8BAA8B,CAAC,CAAC;YACjD,CAAC;YAED,8DAA8D;YAC9D,IAAI,OAAO,KAAK,WAAW,EAAE,CAAC;gBAC1B,OAAO,CAAC,KAAK,CAAC,0DAA0D,QAAQ,UAAU,WAAW,SAAS,CAAC,CAAC;gBAChH,OAAO,IAAI,CAAC;YAChB,CAAC;YAED,gDAAgD;YAChD,MAAM,KAAK,GAAG,cAAc,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,OAAO,GAAG,CAAC,CAAC,CAAC,CAAC,gBAAgB;YACzE,OAAO,CAAC,GAAG,CAAC,iBAAiB,KAAK,OAAO,CAAC,CAAC;YAC3C,MAAM,IAAI,OAAO,CAAC,OAAO,CAAC,EAAE,CAAC,UAAU,CAAC,OAAO,EAAE,KAAK,CAAC,CAAC,CAAC;QAC7D,CAAC;IACL,CAAC;IAED,mFAAmF;IACnF,OAAO,CAAC,KAAK,CAAC,oDAAoD,QAAQ,sBAAsB,CAAC,CAAC;IAClG,OAAO,IAAI,CAAC;AAChB,CAAC;AAED,qCAAqC;AAErC;;;GAGG;AACI,KAAK,UAAU,iBAAiB;IACnC,MAAM,QAAQ,GAAG,gBAAM,CAAC,qBAAqB,CAAC;IAC9C,IAAI,CAAC,QAAQ,EAAE,CAAC;QACZ,OAAO,CAAC,KAAK,CAAC,iFAAiF,CAAC,CAAC;QACjG,OAAO,IAAI,CAAC;IAChB,CAAC;IAED,MAAM,GAAG,GAAG,GAAG,YAAY,GAAG,QAAQ,EAAE,CAAC;IACzC,OAAO,CAAC,GAAG,CAAC,oDAAoD,QAAQ,CAAC,SAAS,CAAC,CAAC,EAAC,EAAE,CAAC,MAAM,CAAC,CAAC;IAChG,MAAM,SAAS,GAAG,MAAM,cAAc,CAAqB,GAAG,EAAE,QAAQ,CAAC,CAAC,CAAC,6BAA6B;IAExG,IAAI,SAAS,IAAI,OAAO,SAAS,CAAC,KAAK,KAAK,QAAQ,IAAI,SAAS,CAAC,KAAK,KAAK,IAAI,EAAE,CAAC;QAC9E,0DAA0D;QAC1D,OAAO,CAAC,GAAG,CAAC,qDAAqD,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,MAAM,YAAY,CAAC,CAAC;QAClH,OAAO,SAAS,CAAC,KAAK,CAAC;IAC5B,CAAC;SAAM,CAAC;QACH,OAAO,CAAC,KAAK,CAAC,8EAA8E,QAAQ,EAAE,CAAC,CAAC;QACxG,OAAO,IAAI,CAAC;IACjB,CAAC;AACL,CAAC;AAED;;;;GAIG;AACI,KAAK,UAAU,sBAAsB,CAAC,GAAW;IACpD,8BAA8B;IAC9B,IAAI,CAAC,GAAG,IAAI,OAAO,GAAG,KAAK,QAAQ,IAAI,CAAC,CAAC,GAAG,CAAC,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC;QACxF,OAAO,CAAC,KAAK,CAAC,sEAAsE,GAAG,EAAE,CAAC,CAAC;QAC3F,OAAO,IAAI,CAAC;IAChB,CAAC;IAED,MAAM,GAAG,GAAG,GAAG,YAAY,GAAG,GAAG,EAAE,CAAC;IACpC,oCAAoC;IACpC,MAAM,QAAQ,GAAG,MAAM,cAAc,CAAoB,GAAG,EAAE,GAAG,CAAC,CAAC;IAEnE,gEAAgE;IAChE,yDAAyD;IACzD,yGAAyG;IACzG,mBAAmB;IACnB,IAAI;IAEJ,OAAO,QAAQ,CAAC;AACpB,CAAC;AAED,sEAAsE;AACtE,SAAgB,kBAAkB;IAC9B,OAAO,CAAC,GAAG,CAAC,8CAA8C,CAAC,CAAC;IAC5D,KAAK,CAAC,KAAK,EAAE,CAAC;AAClB,CAAC"}===== ./dist/services/generatorService.js =====
"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.generateAnswer = generateAnswer;
// kintask/packages/backend/src/services/generatorService.ts
const axios_1 = __importDefault(require("axios")); // Using axios for HTTP requests
const config_1 = __importDefault(require("../config")); // Import configuration (includes API key)
const recallService_1 = require("./recallService"); // Import recall logger for errors
const OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions";
const API_KEY = config_1.default.openRouterApiKey;
// --- Model Configuration ---
// ACTION REQUIRED: Choose a model available on OpenRouter.
// Check https://openrouter.ai/models for options and pricing.
// Using the free Mistral model as a default.
const MODEL_IDENTIFIER = "mistralai/mistral-7b-instruct:free";
// --- End Model Configuration ---
// --- Generation Parameters ---
const MAX_TOKENS = 250; // Max length of the generated response
const TEMPERATURE = 0.5; // Lower value = more deterministic, higher = more creative
const TOP_P = 0.9; // Nucleus sampling
// --- End Generation Parameters ---
let isGeneratorInitialized = false;
function initializeGenerator() {
    if (isGeneratorInitialized)
        return;
    console.log("[Generator Service] Initializing OpenRouter configuration...");
    if (!API_KEY) {
        // This case should be caught by config.ts validation, but double-check
        console.error("[Generator Service] FATAL ERROR: OPENROUTER_API_KEY is not configured.");
        isGeneratorInitialized = false;
        return; // Prevent setting initialized flag
    }
    console.log(`[Generator Service] Configured to use OpenRouter model: ${MODEL_IDENTIFIER}`);
    isGeneratorInitialized = true;
}
// Ensure service is initialized before first use (lazy initialization)
// initializeGenerator(); // Call this explicitly in server startup if preferred
async function generateAnswer(question, requestContext) {
    if (!isGeneratorInitialized)
        initializeGenerator(); // Ensure initialized
    if (!API_KEY || !isGeneratorInitialized) {
        console.error("[Generator Service] OpenRouter API Key not configured or service failed initialization.");
        return "Error: AI answer generation service is not available."; // Return error string
    }
    if (!question || question.trim() === '') {
        console.warn("[Generator Service] Received empty question.");
        return "Error: Cannot generate answer for empty question.";
    }
    console.log(`[Generator Service Request: ${requestContext}] Requesting OpenRouter (${MODEL_IDENTIFIER}) answer...`);
    // --- Construct Payload for OpenRouter (OpenAI compatible format) ---
    const systemPrompt = 'You are Kintask, a helpful AI assistant. Provide concise, factual answers based on general knowledge. Avoid hedging or apologies.';
    const payload = {
        model: MODEL_IDENTIFIER,
        messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: question }
        ],
        max_tokens: MAX_TOKENS,
        temperature: TEMPERATURE,
        top_p: TOP_P,
        // stream: false, // Explicitly disable streaming for simple request/response
    };
    // --- End Payload Construction ---
    try {
        const response = await axios_1.default.post(OPENROUTER_API_URL, payload, {
            headers: {
                'Authorization': `Bearer ${API_KEY}`,
                'Content-Type': 'application/json',
                // Recommended headers for OpenRouter analytics/tracking
                'HTTP-Referer': `http://localhost:${config_1.default.port || 3001}`, // Use configured port
                'X-Title': 'Kintask Hackathon', // Your App Name
            },
            timeout: 60000 // 60 second timeout for API call
        });
        // --- Process OpenRouter Response ---
        const choice = response.data?.choices?.[0];
        const answer = choice?.message?.content?.trim();
        const finishReason = choice?.finish_reason;
        console.log(`[Generator Service Request: ${requestContext}] Finish Reason: ${finishReason || 'N/A'}`);
        if (finishReason === 'length') {
            console.warn(`[Generator Service Request: ${requestContext}] OpenRouter response truncated due to max_tokens limit.`);
            // Return the truncated answer, the user might still find it useful
        }
        else if (finishReason !== 'stop' && finishReason !== null) {
            console.warn(`[Generator Service Request: ${requestContext}] Unusual finish reason: ${finishReason}.`);
        }
        if (!answer) {
            console.warn(`[Generator Service Request: ${requestContext}] OpenRouter returned empty answer content. Response:`, JSON.stringify(response.data).substring(0, 200) + "...");
            // Check for explicit errors in the response structure
            const errorMsg = response.data?.error?.message || 'The AI model did not provide a valid text answer.';
            // Log this failure to Recall
            if (requestContext) {
                (0, recallService_1.logRecallEvent)('VERIFICATION_ERROR', { step: 'GeneratorParse', error: errorMsg, responseData: response.data }, requestContext)
                    .catch(err => console.error("Error logging generator parse error to recall:", err));
            }
            return `Error: ${errorMsg}`;
        }
        // --- End Response Processing ---
        console.log(`[Generator Service Request: ${requestContext}] Received OpenRouter answer (truncated): "${answer.substring(0, 100)}..."`);
        return answer;
    }
    catch (error) {
        const axiosError = error;
        console.error(`[Generator Service Request: ${requestContext}] Error fetching answer from OpenRouter:`, axiosError.message);
        let detailedErrorMessage = axiosError.message;
        let responseDataForLog = null;
        if (axiosError.response) {
            console.error(`  Status: ${axiosError.response.status}`);
            const responseData = axiosError.response.data;
            responseDataForLog = responseData; // Log the actual response data if available
            console.error('  Response Data:', JSON.stringify(responseData).substring(0, 300) + "...");
            // Extract specific error message from OpenRouter/model if available
            detailedErrorMessage = responseData?.error?.message || `HTTP Error ${axiosError.response.status}`;
        }
        else if (axiosError.request) {
            console.error('  No response received from OpenRouter.');
            detailedErrorMessage = 'No response received from OpenRouter service.';
        }
        else {
            console.error('  Error setting up OpenRouter request:', error.message);
            detailedErrorMessage = `Request setup error: ${error.message}`;
        }
        // Log error details to Recall
        if (requestContext) {
            (0, recallService_1.logRecallEvent)('VERIFICATION_ERROR', { step: 'GeneratorAPI', error: detailedErrorMessage, responseData: responseDataForLog }, requestContext)
                .catch(err => console.error("Error logging generator API error to recall:", err));
        }
        return `Error: Could not retrieve answer from the AI model (${detailedErrorMessage.substring(0, 80)}...).`; // Return user-friendly error
    }
}
//# sourceMappingURL=generatorService.js.map===== ./dist/services/generatorService.js.map =====
{"version":3,"file":"generatorService.js","sourceRoot":"","sources":["../../src/services/generatorService.ts"],"names":[],"mappings":";;;;;AAyCA,wCAyGC;AAlJD,4DAA4D;AAC5D,kDAA0C,CAAC,gCAAgC;AAC3E,uDAA+B,CAAC,0CAA0C;AAC1E,mDAAiD,CAAC,kCAAkC;AAGpF,MAAM,kBAAkB,GAAG,+CAA+C,CAAC;AAC3E,MAAM,OAAO,GAAG,gBAAM,CAAC,gBAAgB,CAAC;AAExC,8BAA8B;AAC9B,2DAA2D;AAC3D,8DAA8D;AAC9D,6CAA6C;AAC7C,MAAM,gBAAgB,GAAG,oCAAoC,CAAC;AAC9D,kCAAkC;AAElC,gCAAgC;AAChC,MAAM,UAAU,GAAG,GAAG,CAAC,CAAC,uCAAuC;AAC/D,MAAM,WAAW,GAAG,GAAG,CAAC,CAAC,2DAA2D;AACpF,MAAM,KAAK,GAAG,GAAG,CAAC,CAAM,mBAAmB;AAC3C,oCAAoC;AAEpC,IAAI,sBAAsB,GAAG,KAAK,CAAC;AAEnC,SAAS,mBAAmB;IACxB,IAAI,sBAAsB;QAAE,OAAO;IACnC,OAAO,CAAC,GAAG,CAAC,8DAA8D,CAAC,CAAC;IAC5E,IAAI,CAAC,OAAO,EAAE,CAAC;QACX,uEAAuE;QACvE,OAAO,CAAC,KAAK,CAAC,wEAAwE,CAAC,CAAC;QACxF,sBAAsB,GAAG,KAAK,CAAC;QAC/B,OAAO,CAAC,mCAAmC;IAC/C,CAAC;IACA,OAAO,CAAC,GAAG,CAAC,2DAA2D,gBAAgB,EAAE,CAAC,CAAC;IAC5F,sBAAsB,GAAG,IAAI,CAAC;AAClC,CAAC;AAED,uEAAuE;AACvE,gFAAgF;AAGzE,KAAK,UAAU,cAAc,CAAC,QAAgB,EAAE,cAAuB;IAC1E,IAAI,CAAC,sBAAsB;QAAE,mBAAmB,EAAE,CAAC,CAAC,qBAAqB;IAEzE,IAAI,CAAC,OAAO,IAAI,CAAC,sBAAsB,EAAE,CAAC;QACtC,OAAO,CAAC,KAAK,CAAC,yFAAyF,CAAC,CAAC;QACzG,OAAO,uDAAuD,CAAC,CAAC,sBAAsB;IAC1F,CAAC;IACD,IAAI,CAAC,QAAQ,IAAI,QAAQ,CAAC,IAAI,EAAE,KAAK,EAAE,EAAE,CAAC;QACtC,OAAO,CAAC,IAAI,CAAC,8CAA8C,CAAC,CAAC;QAC7D,OAAO,mDAAmD,CAAC;IAC/D,CAAC;IAED,OAAO,CAAC,GAAG,CAAC,+BAA+B,cAAc,4BAA4B,gBAAgB,aAAa,CAAC,CAAC;IAEpH,sEAAsE;IACtE,MAAM,YAAY,GAAG,mIAAmI,CAAC;IACzJ,MAAM,OAAO,GAAG;QACZ,KAAK,EAAE,gBAAgB;QACvB,QAAQ,EAAE;YACN,EAAE,IAAI,EAAE,QAAQ,EAAE,OAAO,EAAE,YAAY,EAAE;YACzC,EAAE,IAAI,EAAE,MAAM,EAAE,OAAO,EAAE,QAAQ,EAAE;SACtC;QACD,UAAU,EAAE,UAAU;QACtB,WAAW,EAAE,WAAW;QACxB,KAAK,EAAE,KAAK;QACZ,6EAA6E;KAChF,CAAC;IACF,mCAAmC;IAEnC,IAAI,CAAC;QACD,MAAM,QAAQ,GAAG,MAAM,eAAK,CAAC,IAAI,CAC7B,kBAAkB,EAClB,OAAO,EACP;YACI,OAAO,EAAE;gBACL,eAAe,EAAE,UAAU,OAAO,EAAE;gBACpC,cAAc,EAAE,kBAAkB;gBAClC,wDAAwD;gBACxD,cAAc,EAAE,oBAAoB,gBAAM,CAAC,IAAI,IAAI,IAAI,EAAE,EAAE,sBAAsB;gBACjF,SAAS,EAAE,mBAAmB,EAAE,gBAAgB;aACnD;YACD,OAAO,EAAE,KAAK,CAAC,iCAAiC;SACnD,CACJ,CAAC;QAEF,sCAAsC;QACtC,MAAM,MAAM,GAAG,QAAQ,CAAC,IAAI,EAAE,OAAO,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,MAAM,GAAG,MAAM,EAAE,OAAO,EAAE,OAAO,EAAE,IAAI,EAAE,CAAC;QAChD,MAAM,YAAY,GAAG,MAAM,EAAE,aAAa,CAAC;QAE3C,OAAO,CAAC,GAAG,CAAC,+BAA+B,cAAc,oBAAoB,YAAY,IAAI,KAAK,EAAE,CAAC,CAAC;QAEtG,IAAI,YAAY,KAAK,QAAQ,EAAE,CAAC;YAC5B,OAAO,CAAC,IAAI,CAAC,+BAA+B,cAAc,0DAA0D,CAAC,CAAC;YACtH,mEAAmE;QACvE,CAAC;aAAM,IAAI,YAAY,KAAK,MAAM,IAAI,YAAY,KAAK,IAAI,EAAE,CAAC;YACzD,OAAO,CAAC,IAAI,CAAC,+BAA+B,cAAc,4BAA4B,YAAY,GAAG,CAAC,CAAC;QAC5G,CAAC;QAED,IAAI,CAAC,MAAM,EAAE,CAAC;YACV,OAAO,CAAC,IAAI,CAAC,+BAA+B,cAAc,uDAAuD,EAAE,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC,IAAI,CAAC,CAAC,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,KAAK,CAAC,CAAC;YAC5K,sDAAsD;YACtD,MAAM,QAAQ,GAAI,QAAQ,CAAC,IAAY,EAAE,KAAK,EAAE,OAAO,IAAI,mDAAmD,CAAC;YAC/G,6BAA6B;YAC5B,IAAI,cAAc,EAAE,CAAC;gBACjB,IAAA,8BAAc,EAAC,oBAAoB,EAAE,EAAE,IAAI,EAAE,gBAAgB,EAAE,KAAK,EAAE,QAAQ,EAAE,YAAY,EAAE,QAAQ,CAAC,IAAI,EAAE,EAAE,cAAc,CAAC;qBAC1H,KAAK,CAAC,GAAG,CAAC,EAAE,CAAC,OAAO,CAAC,KAAK,CAAC,gDAAgD,EAAE,GAAG,CAAC,CAAC,CAAC;YAC3F,CAAC;YACF,OAAO,UAAU,QAAQ,EAAE,CAAC;QAChC,CAAC;QACD,kCAAkC;QAElC,OAAO,CAAC,GAAG,CAAC,+BAA+B,cAAc,8CAA8C,MAAM,CAAC,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,MAAM,CAAC,CAAC;QACvI,OAAO,MAAM,CAAC;IAElB,CAAC;IAAC,OAAO,KAAU,EAAE,CAAC;QAClB,MAAM,UAAU,GAAG,KAAmB,CAAC;QACvC,OAAO,CAAC,KAAK,CAAC,+BAA+B,cAAc,0CAA0C,EAAE,UAAU,CAAC,OAAO,CAAC,CAAC;QAE3H,IAAI,oBAAoB,GAAG,UAAU,CAAC,OAAO,CAAC;QAC9C,IAAI,kBAAkB,GAAQ,IAAI,CAAC;QAEnC,IAAI,UAAU,CAAC,QAAQ,EAAE,CAAC;YACtB,OAAO,CAAC,KAAK,CAAC,aAAa,UAAU,CAAC,QAAQ,CAAC,MAAM,EAAE,CAAC,CAAC;YACzD,MAAM,YAAY,GAAG,UAAU,CAAC,QAAQ,CAAC,IAAI,CAAC;YAC9C,kBAAkB,GAAG,YAAY,CAAC,CAAC,4CAA4C;YAC/E,OAAO,CAAC,KAAK,CAAC,kBAAkB,EAAE,IAAI,CAAC,SAAS,CAAC,YAAY,CAAC,CAAC,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,KAAK,CAAC,CAAC;YAC1F,oEAAoE;YACpE,oBAAoB,GAAI,YAAoB,EAAE,KAAK,EAAE,OAAO,IAAI,cAAc,UAAU,CAAC,QAAQ,CAAC,MAAM,EAAE,CAAC;QAC/G,CAAC;aAAM,IAAI,UAAU,CAAC,OAAO,EAAE,CAAC;YAC3B,OAAO,CAAC,KAAK,CAAC,yCAAyC,CAAC,CAAC;YACzD,oBAAoB,GAAG,+CAA+C,CAAC;QAC5E,CAAC;aAAM,CAAC;YACH,OAAO,CAAC,KAAK,CAAC,wCAAwC,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;YACvE,oBAAoB,GAAG,wBAAwB,KAAK,CAAC,OAAO,EAAE,CAAC;QACpE,CAAC;QAED,8BAA8B;QAC9B,IAAI,cAAc,EAAE,CAAC;YACjB,IAAA,8BAAc,EAAC,oBAAoB,EAAE,EAAE,IAAI,EAAE,cAAc,EAAE,KAAK,EAAE,oBAAoB,EAAE,YAAY,EAAE,kBAAkB,EAAE,EAAE,cAAc,CAAC;iBACxI,KAAK,CAAC,GAAG,CAAC,EAAE,CAAC,OAAO,CAAC,KAAK,CAAC,8CAA8C,EAAE,GAAG,CAAC,CAAC,CAAC;QAC1F,CAAC;QAED,OAAO,uDAAuD,oBAAoB,CAAC,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC,OAAO,CAAC,CAAC,6BAA6B;IAC7I,CAAC;AACL,CAAC"}===== ./dist/services/recallService.js =====
"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.logRecallEvent = logRecallEvent;
exports.getTraceFromRecall = getTraceFromRecall;
const config_1 = __importDefault(require("../config"));
const chains_1 = require("@recallnet/chains"); // Use the testnet chain definition
const viem_1 = require("viem");
const accounts_1 = require("viem/accounts");
// --- Module State ---
let recallClientInstance = null;
let isRecallInitialized = false;
let logBucketAddress = config_1.default.recallLogBucket || null; // Store the bucket address globally
let account = null;
const RECALL_BUCKET_ALIAS = 'kintask-log-bucket-v1'; // Unique alias for this project's log bucket
let initPromise = null; // To handle concurrent initializations
// --- Helper: Create Viem Wallet Client ---
function getWalletClient() {
    if (!config_1.default.recallPrivateKey) {
        throw new Error('Recall Private Key (PRIVATE_KEY in .env) is not configured.');
    }
    const formattedPrivateKey = config_1.default.recallPrivateKey.startsWith('0x')
        ? config_1.default.recallPrivateKey
        : `0x${config_1.default.recallPrivateKey}`;
    if (!account) { // Cache the account object
        account = (0, accounts_1.privateKeyToAccount)(formattedPrivateKey);
        console.log(`[Recall Service] Using wallet address: ${account.address} on chain ${chains_1.testnet.id}`);
    }
    // Ensure the transport is configured for the correct chain
    return (0, viem_1.createWalletClient)({
        account: account,
        chain: chains_1.testnet, // Explicitly set Recall testnet chain
        transport: (0, viem_1.http)(), // Default HTTP transport - Add RPC URL from testnet config if needed explicitly
        // transport: http(testnet.rpcUrls.default.http[0]),
    });
}
// --- Helper: Create Viem Public Client ---
function getPublicClient() {
    return (0, viem_1.createPublicClient)({
        chain: chains_1.testnet, // Use Recall testnet chain
        transport: (0, viem_1.http)(),
    });
}
// --- Helper: Get or Initialize Recall Client (Singleton Pattern) ---
async function getRecallClient() {
    if (recallClientInstance && isRecallInitialized) {
        return recallClientInstance;
    }
    // Prevent race conditions during initialization
    if (initPromise) {
        // console.log("[Recall Service] Initialization already in progress, awaiting promise...");
        return initPromise;
    }
    initPromise = (async () => {
        console.log("[Recall Service] Initializing Recall Client (getRecallClient)...");
        try {
            // Ensure dynamic import works. If facing issues, consider converting service to ESM
            // or using a different import method if SDK provides CommonJS entry point.
            const { RecallClient } = await import('@recallnet/sdk/client');
            const walletClient = getWalletClient(); // Get viem wallet client configured for Recall testnet
            const client = new RecallClient({ walletClient });
            // Basic check: Ensure client has account after initialization
            if (!client.walletClient.account?.address) {
                throw new Error("Failed to initialize client: Wallet address missing.");
            }
            console.log("[Recall Service] Recall Client Initialized successfully.");
            recallClientInstance = client;
            isRecallInitialized = true; // Mark as initialized
            initPromise = null; // Clear promise
            return client;
        }
        catch (error) {
            console.error("[Recall Service] FATAL ERROR initializing Recall Client:", error.message);
            recallClientInstance = null;
            isRecallInitialized = false;
            initPromise = null;
            throw new Error(`Recall Client initialization failed: ${error.message}`); // Rethrow to calling function
        }
    })();
    return initPromise;
}
// --- Helper: Ensure Credit Balance ---
// Returns true if credit was sufficient OR successfully purchased, false otherwise
async function ensureCreditBalanceIfZero(recall) {
    console.log("[Recall Service] Checking credit balance...");
    try {
        const creditManager = recall.creditManager();
        const { result: creditBalance } = await creditManager.getCreditBalance();
        const creditFree = creditBalance?.creditFree ?? 0n;
        console.log(`[Recall Service] Current credit_free: ${creditFree.toString()}`);
        if (creditFree === 0n) { // Only buy if exactly zero
            console.log('[Recall Service] credit_free is 0, attempting to buy 1 credit...');
            const amountToBuy = (0, viem_1.parseEther)("1");
            const { meta } = await creditManager.buy(amountToBuy);
            const txHash = meta?.tx?.transactionHash;
            if (!txHash)
                throw new Error("Credit purchase transaction did not return a hash.");
            console.log(`[Recall Service] Credit purchase transaction sent: ${txHash}. Waiting for confirmation...`);
            const publicClient = getPublicClient();
            const receipt = await publicClient.waitForTransactionReceipt({ hash: txHash, confirmations: 1 });
            if (receipt.status === 'success') {
                console.log(`[Recall Service] Credit purchased successfully (Tx: ${txHash}).`);
                await new Promise(resolve => setTimeout(resolve, 3000)); // Allow buffer time
                return true;
            }
            else {
                console.error(`[Recall Service] Credit purchase transaction failed (Tx: ${txHash}). Status: ${receipt.status}`);
                throw new Error(`Failed to purchase Recall credit (Tx: ${txHash}, Status: ${receipt.status}).`);
            }
        }
        return true; // Credit was > 0 initially
    }
    catch (error) {
        console.error("[Recall Service] Error checking or buying credit:", error.message);
        if (error instanceof viem_1.ChainMismatchError) {
            console.error("[Recall Service] Chain mismatch detected. Check Recall SDK/Chain config.");
        }
        // Rethrow or return false to indicate failure? Let's rethrow for clarity.
        throw new Error(`Failed to ensure Recall credit balance: ${error.message}`);
    }
}
// --- Helper: Find or Create Log Bucket ---
async function ensureLogBucket(recall) {
    if (logBucketAddress) {
        return logBucketAddress;
    }
    console.log(`[Recall Service] Attempting to find or create log bucket with alias: ${RECALL_BUCKET_ALIAS}`);
    const bucketManager = recall.bucketManager();
    let foundBucket = null;
    try {
        const { result: listResult } = await bucketManager.list();
        const buckets = listResult?.buckets || [];
        console.log(`[Recall Service] Checking ${buckets.length} accessible buckets for alias...`);
        for (const bucketAddr of buckets) {
            try {
                const { result: metaResult } = await bucketManager.getMetadata(bucketAddr);
                if (metaResult?.metadata?.alias === RECALL_BUCKET_ALIAS) {
                    console.log(`[Recall Service] Found existing log bucket: ${bucketAddr}`);
                    foundBucket = bucketAddr;
                    break;
                }
            }
            catch (metaError) { /* Ignore errors getting metadata */ }
        }
        if (!foundBucket) {
            console.log(`[Recall Service] Log bucket alias '${RECALL_BUCKET_ALIAS}' not found. Creating new bucket...`);
            await ensureCreditBalanceIfZero(recall); // Ensure credit before creating
            const createMetaPayload = { alias: RECALL_BUCKET_ALIAS, createdBy: 'KintaskBackend', timestamp: new Date().toISOString() };
            const { result, meta: createMetaInfo } = await bucketManager.create({ metadata: createMetaPayload });
            foundBucket = result?.bucket;
            const createTxHash = createMetaInfo?.tx?.transactionHash;
            if (foundBucket) {
                console.log(`[Recall Service] Successfully created new log bucket: ${foundBucket} (Tx: ${createTxHash})`);
                console.warn(`ACTION REQUIRED: Consider adding/updating RECALL_LOG_BUCKET in .env to: ${foundBucket} for faster startup.`);
            }
            else {
                const errorMsg = createMetaInfo?.error?.message || "Bucket creation call succeeded but no bucket address was returned.";
                console.error("[Recall Service] Bucket creation failed:", errorMsg, createMetaInfo);
                throw new Error(errorMsg);
            }
        }
        logBucketAddress = foundBucket; // Cache address
        return logBucketAddress;
    }
    catch (error) {
        console.error("[Recall Service] Error finding or creating log bucket:", error.message);
        throw new Error(`Failed to ensure Recall log bucket: ${error.message}`);
    }
}
// --- Main Logging Function ---
async function logRecallEvent(type, details, requestContext) {
    if (!requestContext) {
        console.error("[Recall Service] CRITICAL: logRecallEvent called without requestContext.");
        return undefined;
    }
    let recall;
    let bucketAddr;
    try {
        // Get client, bucket, and ensure credit *before* creating log entry object
        recall = await getRecallClient();
        bucketAddr = await ensureLogBucket(recall);
        await ensureCreditBalanceIfZero(recall);
    }
    catch (setupError) {
        console.error(`[Recall Service] Setup failed before logging event ${type} (Context: ${requestContext}):`, setupError.message);
        return undefined; // Cannot log if setup fails
    }
    const logEntry = {
        timestamp: new Date().toISOString(),
        type: type,
        details: details,
        requestContext: requestContext,
    };
    // Prepare data for storage
    const contentString = JSON.stringify(logEntry);
    const fileBuffer = Buffer.from(contentString, 'utf8');
    const timestampSuffix = logEntry.timestamp.replace(/[:.]/g, '-');
    const key = `${requestContext}/${timestampSuffix}_${type}.json`; // Structure logs by request context
    // console.log(`[Recall Service] Logging Event [${requestContext}] Type=${type} to Bucket ${bucketAddr.substring(0,10)}... Key=${key.substring(0,50)}...`);
    try {
        const bucketManager = recall.bucketManager();
        const { meta } = await bucketManager.add(bucketAddr, key, fileBuffer);
        const txHash = meta?.tx?.transactionHash;
        if (!txHash) {
            console.warn(`[Recall Service] Log add successful (according to SDK meta?) for context ${requestContext}, type ${type}, but no txHash returned. Status uncertain.`);
            // Check meta for other status info if available
            return undefined;
        }
        console.log(`[Recall Service] Log Event ${type} stored for context ${requestContext}. TxHash: ${txHash}`);
        return txHash;
    }
    catch (error) {
        console.error(`[Recall Service] Error adding log event ${type} for context ${requestContext} to bucket ${bucketAddr}:`, error.message);
        return undefined; // Indicate logging failure
    }
}
// --- Trace Retrieval Function ---
async function getTraceFromRecall(requestContext) {
    if (!requestContext)
        return [];
    console.log(`[Recall Service] Retrieving trace for context: ${requestContext}`);
    let recall;
    let bucketAddr;
    try {
        recall = await getRecallClient();
        // Use cached bucket address if available, otherwise ensure it exists
        bucketAddr = logBucketAddress || await ensureLogBucket(recall);
    }
    catch (initError) {
        console.error(`[Recall Service] Initialization failed for retrieving trace (Context: ${requestContext}):`, initError.message);
        return [];
    }
    try {
        const bucketManager = recall.bucketManager();
        const prefix = `${requestContext}/`; // Query by the context "folder"
        console.log(`[Recall Service] Querying bucket ${bucketAddr.substring(0, 10)}... for prefix: ${prefix}`);
        const { result: queryResult } = await bucketManager.query(bucketAddr, { prefix: prefix, delimiter: '' });
        const objectInfos = (queryResult?.objects || []);
        const objectKeys = objectInfos.map(obj => obj.key).filter((k) => !!k && k.endsWith('.json'));
        if (objectKeys.length === 0) {
            console.log(`[Recall Service] No log entries found via query for context: ${requestContext}`);
            return [];
        }
        console.log(`[Recall Service] Found ${objectKeys.length} log keys for context ${requestContext}. Fetching content...`);
        // Fetch content concurrently
        const fetchPromises = objectKeys.map(async (key) => {
            try {
                const { result: objectResult } = await bucketManager.get(bucketAddr, key);
                // The result from get might be the buffer directly, or nested { result: { object: Buffer } } ?
                // Assuming result IS the buffer based on example (adjust if needed)
                const objectBuf = objectResult; // Type assertion based on expectation
                if (!objectBuf) {
                    console.warn(`[Recall Service] Got null buffer for key ${key}`);
                    return null;
                }
                // Ensure it's a Buffer before decoding
                const buffer = Buffer.isBuffer(objectBuf) ? objectBuf : Buffer.from(objectBuf);
                const textContent = buffer.toString('utf8');
                const logEntry = JSON.parse(textContent);
                if (logEntry && logEntry.timestamp && logEntry.type && logEntry.details) {
                    return logEntry;
                }
                console.warn(`[Recall Service] Invalid log format found parsing key ${key}`);
                return null;
            }
            catch (fetchError) {
                console.error(`[Recall Service] Error fetching/parsing key ${key}: ${fetchError.message}`);
                if (fetchError.message?.includes("Object not found")) {
                    console.warn(`   -> Object likely deleted or query/get mismatch for key ${key}`);
                }
                return null;
            }
        });
        const logEntries = (await Promise.all(fetchPromises))
            .filter((entry) => entry !== null)
            .sort((a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()); // Sort chronologically
        console.log(`[Recall Service] Successfully retrieved and parsed ${logEntries.length} log entries for context: ${requestContext}`);
        return logEntries;
    }
    catch (error) {
        console.error(`[Recall Service] Error retrieving trace for context ${requestContext}:`, error.message);
        return []; // Return empty trace on error
    }
}
//# sourceMappingURL=recallService.js.map===== ./dist/services/recallService.js.map =====
{"version":3,"file":"recallService.js","sourceRoot":"","sources":["../../src/services/recallService.ts"],"names":[],"mappings":";;;;;AAyLA,wCAwDC;AAGD,gDAuEC;AA3TD,uDAA+B;AAE/B,8CAA4C,CAAC,mCAAmC;AAChF,+BAAgI;AAChI,4CAA6D;AAI7D,uBAAuB;AACvB,IAAI,oBAAoB,GAAwB,IAAI,CAAC;AACrD,IAAI,mBAAmB,GAAG,KAAK,CAAC;AAChC,IAAI,gBAAgB,GAAG,gBAAM,CAAC,eAAe,IAAI,IAAI,CAAC,CAAC,oCAAoC;AAC3F,IAAI,OAAO,GAAmB,IAAI,CAAC;AACnC,MAAM,mBAAmB,GAAG,uBAAuB,CAAC,CAAC,6CAA6C;AAClG,IAAI,WAAW,GAAiC,IAAI,CAAC,CAAC,uCAAuC;AAE7F,4CAA4C;AAC5C,SAAS,eAAe;IACpB,IAAI,CAAC,gBAAM,CAAC,gBAAgB,EAAE,CAAC;QAC3B,MAAM,IAAI,KAAK,CAAC,6DAA6D,CAAC,CAAC;IACnF,CAAC;IACD,MAAM,mBAAmB,GAAG,gBAAM,CAAC,gBAAgB,CAAC,UAAU,CAAC,IAAI,CAAC;QAChE,CAAC,CAAC,gBAAM,CAAC,gBAAiC;QAC1C,CAAC,CAAC,KAAK,gBAAM,CAAC,gBAAgB,EAAmB,CAAC;IAEtD,IAAI,CAAC,OAAO,EAAE,CAAC,CAAC,2BAA2B;QACtC,OAAO,GAAG,IAAA,8BAAmB,EAAC,mBAAmB,CAAC,CAAC;QACnD,OAAO,CAAC,GAAG,CAAC,0CAA0C,OAAO,CAAC,OAAO,aAAa,gBAAO,CAAC,EAAE,EAAE,CAAC,CAAC;IACrG,CAAC;IAED,2DAA2D;IAC3D,OAAO,IAAA,yBAAkB,EAAC;QACtB,OAAO,EAAE,OAAO;QAChB,KAAK,EAAE,gBAAO,EAAE,sCAAsC;QACtD,SAAS,EAAE,IAAA,WAAI,GAAE,EAAE,gFAAgF;QACjF,oDAAoD;KACzE,CAAC,CAAC;AACP,CAAC;AAEA,4CAA4C;AAC5C,SAAS,eAAe;IACpB,OAAO,IAAA,yBAAkB,EAAC;QACtB,KAAK,EAAE,gBAAO,EAAE,2BAA2B;QAC3C,SAAS,EAAE,IAAA,WAAI,GAAE;KACpB,CAAC,CAAC;AACP,CAAC;AAGF,sEAAsE;AACtE,KAAK,UAAU,eAAe;IAC1B,IAAI,oBAAoB,IAAI,mBAAmB,EAAE,CAAC;QAC9C,OAAO,oBAAoB,CAAC;IAChC,CAAC;IACD,gDAAgD;IAChD,IAAI,WAAW,EAAE,CAAC;QACd,2FAA2F;QAC3F,OAAO,WAAW,CAAC;IACvB,CAAC;IAED,WAAW,GAAG,CAAC,KAAK,IAAI,EAAE;QACtB,OAAO,CAAC,GAAG,CAAC,kEAAkE,CAAC,CAAC;QAChF,IAAI,CAAC;YACD,oFAAoF;YACpF,2EAA2E;YAC3E,MAAM,EAAE,YAAY,EAAE,GAAG,MAAM,MAAM,CAAC,uBAAuB,CAAC,CAAC;YAC/D,MAAM,YAAY,GAAG,eAAe,EAAE,CAAC,CAAC,uDAAuD;YAC/F,MAAM,MAAM,GAAG,IAAI,YAAY,CAAC,EAAE,YAAY,EAAE,CAAC,CAAC;YAElD,8DAA8D;YAC9D,IAAI,CAAC,MAAM,CAAC,YAAY,CAAC,OAAO,EAAE,OAAO,EAAE,CAAC;gBACxC,MAAM,IAAI,KAAK,CAAC,sDAAsD,CAAC,CAAC;YAC5E,CAAC;YACD,OAAO,CAAC,GAAG,CAAC,0DAA0D,CAAC,CAAC;YACxE,oBAAoB,GAAG,MAAM,CAAC;YAC9B,mBAAmB,GAAG,IAAI,CAAC,CAAC,sBAAsB;YAClD,WAAW,GAAG,IAAI,CAAC,CAAC,gBAAgB;YACpC,OAAO,MAAM,CAAC;QAClB,CAAC;QAAC,OAAO,KAAU,EAAE,CAAC;YAClB,OAAO,CAAC,KAAK,CAAC,0DAA0D,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;YACzF,oBAAoB,GAAG,IAAI,CAAC;YAC5B,mBAAmB,GAAG,KAAK,CAAC;YAC5B,WAAW,GAAG,IAAI,CAAC;YACnB,MAAM,IAAI,KAAK,CAAC,wCAAwC,KAAK,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,8BAA8B;QAC5G,CAAC;IACL,CAAC,CAAC,EAAE,CAAC;IAEL,OAAO,WAAW,CAAC;AACvB,CAAC;AAED,wCAAwC;AACxC,mFAAmF;AACnF,KAAK,UAAU,yBAAyB,CAAC,MAAoB;IACzD,OAAO,CAAC,GAAG,CAAC,6CAA6C,CAAC,CAAC;IAC3D,IAAI,CAAC;QACD,MAAM,aAAa,GAAG,MAAM,CAAC,aAAa,EAAE,CAAC;QAC7C,MAAM,EAAE,MAAM,EAAE,aAAa,EAAE,GAAG,MAAM,aAAa,CAAC,gBAAgB,EAAE,CAAC;QACzE,MAAM,UAAU,GAAG,aAAa,EAAE,UAAU,IAAI,EAAE,CAAC;QACnD,OAAO,CAAC,GAAG,CAAC,yCAAyC,UAAU,CAAC,QAAQ,EAAE,EAAE,CAAC,CAAC;QAE9E,IAAI,UAAU,KAAK,EAAE,EAAE,CAAC,CAAC,2BAA2B;YAChD,OAAO,CAAC,GAAG,CAAC,kEAAkE,CAAC,CAAC;YAChF,MAAM,WAAW,GAAG,IAAA,iBAAU,EAAC,GAAG,CAAC,CAAC;YACpC,MAAM,EAAE,IAAI,EAAE,GAAG,MAAM,aAAa,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC;YACtD,MAAM,MAAM,GAAG,IAAI,EAAE,EAAE,EAAE,eAAe,CAAC;YACzC,IAAI,CAAC,MAAM;gBAAE,MAAM,IAAI,KAAK,CAAC,oDAAoD,CAAC,CAAC;YAEnF,OAAO,CAAC,GAAG,CAAC,sDAAsD,MAAM,+BAA+B,CAAC,CAAC;YACzG,MAAM,YAAY,GAAG,eAAe,EAAE,CAAC;YACvC,MAAM,OAAO,GAAG,MAAM,YAAY,CAAC,yBAAyB,CAAC,EAAE,IAAI,EAAE,MAAM,EAAE,aAAa,EAAE,CAAC,EAAE,CAAC,CAAC;YAEjG,IAAI,OAAO,CAAC,MAAM,KAAK,SAAS,EAAE,CAAC;gBAC9B,OAAO,CAAC,GAAG,CAAC,uDAAuD,MAAM,IAAI,CAAC,CAAC;gBAC/E,MAAM,IAAI,OAAO,CAAC,OAAO,CAAC,EAAE,CAAC,UAAU,CAAC,OAAO,EAAE,IAAI,CAAC,CAAC,CAAC,CAAC,oBAAoB;gBAC7E,OAAO,IAAI,CAAC;YACjB,CAAC;iBAAM,CAAC;gBACH,OAAO,CAAC,KAAK,CAAC,4DAA4D,MAAM,cAAc,OAAO,CAAC,MAAM,EAAE,CAAC,CAAC;gBAChH,MAAM,IAAI,KAAK,CAAC,yCAAyC,MAAM,aAAa,OAAO,CAAC,MAAM,IAAI,CAAC,CAAC;YACrG,CAAC;QACL,CAAC;QACD,OAAO,IAAI,CAAC,CAAC,2BAA2B;IAC5C,CAAC;IAAC,OAAO,KAAU,EAAE,CAAC;QAClB,OAAO,CAAC,KAAK,CAAC,mDAAmD,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;QACjF,IAAI,KAAK,YAAY,yBAAkB,EAAE,CAAC;YACrC,OAAO,CAAC,KAAK,CAAC,0EAA0E,CAAC,CAAC;QAC/F,CAAC;QACF,0EAA0E;QAC1E,MAAM,IAAI,KAAK,CAAC,2CAA2C,KAAK,CAAC,OAAO,EAAE,CAAC,CAAC;IAChF,CAAC;AACL,CAAC;AAED,4CAA4C;AAC5C,KAAK,UAAU,eAAe,CAAC,MAAoB;IAC/C,IAAI,gBAAgB,EAAE,CAAC;QACnB,OAAO,gBAAgB,CAAC;IAC5B,CAAC;IAED,OAAO,CAAC,GAAG,CAAC,wEAAwE,mBAAmB,EAAE,CAAC,CAAC;IAC3G,MAAM,aAAa,GAAG,MAAM,CAAC,aAAa,EAAE,CAAC;IAC7C,IAAI,WAAW,GAAkB,IAAI,CAAC;IAEtC,IAAI,CAAC;QACD,MAAM,EAAE,MAAM,EAAE,UAAU,EAAE,GAAG,MAAM,aAAa,CAAC,IAAI,EAAE,CAAC;QAC1D,MAAM,OAAO,GAAG,UAAU,EAAE,OAAO,IAAI,EAAE,CAAC;QAC1C,OAAO,CAAC,GAAG,CAAC,6BAA6B,OAAO,CAAC,MAAM,kCAAkC,CAAC,CAAC;QAE3F,KAAK,MAAM,UAAU,IAAI,OAAO,EAAE,CAAC;YAC/B,IAAI,CAAC;gBACD,MAAM,EAAE,MAAM,EAAE,UAAU,EAAE,GAAG,MAAM,aAAa,CAAC,WAAW,CAAC,UAAU,CAAC,CAAC;gBAC3E,IAAI,UAAU,EAAE,QAAQ,EAAE,KAAK,KAAK,mBAAmB,EAAE,CAAC;oBACtD,OAAO,CAAC,GAAG,CAAC,+CAA+C,UAAU,EAAE,CAAC,CAAC;oBACzE,WAAW,GAAG,UAAU,CAAC;oBACzB,MAAM;gBACV,CAAC;YACL,CAAC;YAAC,OAAO,SAAc,EAAE,CAAC,CAAC,oCAAoC,CAAC,CAAC;QACrE,CAAC;QAED,IAAI,CAAC,WAAW,EAAE,CAAC;YACf,OAAO,CAAC,GAAG,CAAC,sCAAsC,mBAAmB,qCAAqC,CAAC,CAAC;YAC5G,MAAM,yBAAyB,CAAC,MAAM,CAAC,CAAC,CAAC,gCAAgC;YAEzE,MAAM,iBAAiB,GAAG,EAAE,KAAK,EAAE,mBAAmB,EAAE,SAAS,EAAE,gBAAgB,EAAE,SAAS,EAAE,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE,EAAE,CAAC;YAC3H,MAAM,EAAE,MAAM,EAAE,IAAI,EAAE,cAAc,EAAE,GAAG,MAAM,aAAa,CAAC,MAAM,CAAC,EAAE,QAAQ,EAAE,iBAAiB,EAAE,CAAC,CAAC;YACrG,WAAW,GAAG,MAAM,EAAE,MAAM,CAAC;YAC7B,MAAM,YAAY,GAAG,cAAc,EAAE,EAAE,EAAE,eAAe,CAAC;YAEzD,IAAI,WAAW,EAAE,CAAC;gBACb,OAAO,CAAC,GAAG,CAAC,yDAAyD,WAAW,SAAS,YAAY,GAAG,CAAC,CAAC;gBAC1G,OAAO,CAAC,IAAI,CAAC,2EAA2E,WAAW,sBAAsB,CAAC,CAAC;YAChI,CAAC;iBAAM,CAAC;gBACH,MAAM,QAAQ,GAAG,cAAc,EAAE,KAAK,EAAE,OAAO,IAAI,oEAAoE,CAAC;gBACxH,OAAO,CAAC,KAAK,CAAC,0CAA0C,EAAE,QAAQ,EAAE,cAAc,CAAC,CAAC;gBACpF,MAAM,IAAI,KAAK,CAAC,QAAQ,CAAC,CAAC;YAC/B,CAAC;QACL,CAAC;QAED,gBAAgB,GAAG,WAAW,CAAC,CAAC,gBAAgB;QAChD,OAAO,gBAAgB,CAAC;IAE5B,CAAC;IAAC,OAAO,KAAU,EAAE,CAAC;QAClB,OAAO,CAAC,KAAK,CAAC,wDAAwD,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;QACvF,MAAM,IAAI,KAAK,CAAC,uCAAuC,KAAK,CAAC,OAAO,EAAE,CAAC,CAAC;IAC5E,CAAC;AACL,CAAC;AAED,gCAAgC;AACzB,KAAK,UAAU,cAAc,CAChC,IAAqB,EACrB,OAA4B,EAC5B,cAAsB;IAGtB,IAAI,CAAC,cAAc,EAAE,CAAC;QACjB,OAAO,CAAC,KAAK,CAAC,0EAA0E,CAAC,CAAC;QAC1F,OAAO,SAAS,CAAC;IACtB,CAAC;IAED,IAAI,MAAoB,CAAC;IACzB,IAAI,UAAkB,CAAC;IACvB,IAAI,CAAC;QACD,2EAA2E;QAC3E,MAAM,GAAG,MAAM,eAAe,EAAE,CAAC;QACjC,UAAU,GAAG,MAAM,eAAe,CAAC,MAAM,CAAC,CAAC;QAC3C,MAAM,yBAAyB,CAAC,MAAM,CAAC,CAAC;IAC5C,CAAC;IAAC,OAAO,UAAe,EAAE,CAAC;QACvB,OAAO,CAAC,KAAK,CAAC,sDAAsD,IAAI,cAAc,cAAc,IAAI,EAAE,UAAU,CAAC,OAAO,CAAC,CAAC;QAC9H,OAAO,SAAS,CAAC,CAAC,4BAA4B;IAClD,CAAC;IAED,MAAM,QAAQ,GAAuB;QACjC,SAAS,EAAE,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE;QACnC,IAAI,EAAE,IAAI;QACV,OAAO,EAAE,OAAO;QAChB,cAAc,EAAE,cAAc;KACjC,CAAC;IAEF,2BAA2B;IAC3B,MAAM,aAAa,GAAG,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC,CAAC;IAC/C,MAAM,UAAU,GAAG,MAAM,CAAC,IAAI,CAAC,aAAa,EAAE,MAAM,CAAC,CAAC;IACtD,MAAM,eAAe,GAAG,QAAQ,CAAC,SAAS,CAAC,OAAO,CAAC,OAAO,EAAE,GAAG,CAAC,CAAC;IACjE,MAAM,GAAG,GAAG,GAAG,cAAc,IAAI,eAAe,IAAI,IAAI,OAAO,CAAC,CAAC,oCAAoC;IAErG,2JAA2J;IAE3J,IAAI,CAAC;QACD,MAAM,aAAa,GAAG,MAAM,CAAC,aAAa,EAAE,CAAC;QAC7C,MAAM,EAAE,IAAI,EAAE,GAAG,MAAM,aAAa,CAAC,GAAG,CAAC,UAAU,EAAE,GAAG,EAAE,UAAU,CAAC,CAAC;QACtE,MAAM,MAAM,GAAG,IAAI,EAAE,EAAE,EAAE,eAAe,CAAC;QAEzC,IAAI,CAAC,MAAM,EAAE,CAAC;YACT,OAAO,CAAC,IAAI,CAAC,4EAA4E,cAAc,UAAU,IAAI,6CAA6C,CAAC,CAAC;YACpK,gDAAgD;YAChD,OAAO,SAAS,CAAC;QACtB,CAAC;QAED,OAAO,CAAC,GAAG,CAAC,8BAA8B,IAAI,uBAAuB,cAAc,aAAa,MAAM,EAAE,CAAC,CAAC;QAC1G,OAAO,MAAM,CAAC;IAElB,CAAC;IAAC,OAAO,KAAU,EAAE,CAAC;QAClB,OAAO,CAAC,KAAK,CAAC,2CAA2C,IAAI,gBAAgB,cAAc,cAAc,UAAU,GAAG,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;QACvI,OAAO,SAAS,CAAC,CAAC,2BAA2B;IACjD,CAAC;AACL,CAAC;AAED,mCAAmC;AAC5B,KAAK,UAAU,kBAAkB,CAAC,cAAsB;IAC3D,IAAI,CAAC,cAAc;QAAE,OAAO,EAAE,CAAC;IAE/B,OAAO,CAAC,GAAG,CAAC,kDAAkD,cAAc,EAAE,CAAC,CAAC;IAChF,IAAI,MAAoB,CAAC;IACzB,IAAI,UAAkB,CAAC;IACvB,IAAI,CAAC;QACD,MAAM,GAAG,MAAM,eAAe,EAAE,CAAC;QACjC,qEAAqE;QACrE,UAAU,GAAG,gBAAgB,IAAI,MAAM,eAAe,CAAC,MAAM,CAAC,CAAC;IACnE,CAAC;IAAC,OAAO,SAAc,EAAE,CAAC;QACrB,OAAO,CAAC,KAAK,CAAC,yEAAyE,cAAc,IAAI,EAAE,SAAS,CAAC,OAAO,CAAC,CAAC;QAC9H,OAAO,EAAE,CAAC;IACf,CAAC;IAED,IAAI,CAAC;QACD,MAAM,aAAa,GAAG,MAAM,CAAC,aAAa,EAAE,CAAC;QAC7C,MAAM,MAAM,GAAG,GAAG,cAAc,GAAG,CAAC,CAAC,gCAAgC;QAErE,OAAO,CAAC,GAAG,CAAC,oCAAoC,UAAU,CAAC,SAAS,CAAC,CAAC,EAAC,EAAE,CAAC,mBAAmB,MAAM,EAAE,CAAC,CAAC;QACvG,MAAM,EAAE,MAAM,EAAE,WAAW,EAAE,GAAG,MAAM,aAAa,CAAC,KAAK,CAAC,UAAU,EAAE,EAAE,MAAM,EAAE,MAAM,EAAE,SAAS,EAAE,EAAE,EAAE,CAAC,CAAC;QAEzG,MAAM,WAAW,GAAG,CAAC,WAAW,EAAE,OAAO,IAAI,EAAE,CAAC,CAAC;QACjD,MAAM,UAAU,GAAG,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,EAAe,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,CAAC;QAE1G,IAAI,UAAU,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;YAC1B,OAAO,CAAC,GAAG,CAAC,gEAAgE,cAAc,EAAE,CAAC,CAAC;YAC9F,OAAO,EAAE,CAAC;QACd,CAAC;QACD,OAAO,CAAC,GAAG,CAAC,0BAA0B,UAAU,CAAC,MAAM,yBAAyB,cAAc,uBAAuB,CAAC,CAAC;QAEvH,6BAA6B;QAC7B,MAAM,aAAa,GAAG,UAAU,CAAC,GAAG,CAAC,KAAK,EAAE,GAAG,EAAE,EAAE;YAC9C,IAAI,CAAC;gBACD,MAAM,EAAE,MAAM,EAAE,YAAY,EAAE,GAAG,MAAM,aAAa,CAAC,GAAG,CAAC,UAAU,EAAE,GAAG,CAAC,CAAC;gBAC1E,+FAA+F;gBAC/F,oEAAoE;gBACpE,MAAM,SAAS,GAAG,YAAqD,CAAC,CAAC,sCAAsC;gBAC/G,IAAI,CAAC,SAAS,EAAE,CAAC;oBACb,OAAO,CAAC,IAAI,CAAC,4CAA4C,GAAG,EAAE,CAAC,CAAC;oBAChE,OAAO,IAAI,CAAC;gBAChB,CAAC;gBACD,uCAAuC;gBACvC,MAAM,MAAM,GAAG,MAAM,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;gBAC/E,MAAM,WAAW,GAAG,MAAM,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;gBAC5C,MAAM,QAAQ,GAAG,IAAI,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;gBAC/D,IAAI,QAAQ,IAAI,QAAQ,CAAC,SAAS,IAAI,QAAQ,CAAC,IAAI,IAAI,QAAQ,CAAC,OAAO,EAAE,CAAC;oBACrE,OAAO,QAAQ,CAAC;gBACrB,CAAC;gBACD,OAAO,CAAC,IAAI,CAAC,yDAAyD,GAAG,EAAE,CAAC,CAAC;gBAC7E,OAAO,IAAI,CAAC;YAChB,CAAC;YAAC,OAAO,UAAe,EAAE,CAAC;gBACtB,OAAO,CAAC,KAAK,CAAC,+CAA+C,GAAG,KAAK,UAAU,CAAC,OAAO,EAAE,CAAC,CAAC;gBAC1F,IAAI,UAAU,CAAC,OAAO,EAAE,QAAQ,CAAC,kBAAkB,CAAC,EAAE,CAAC;oBAClD,OAAO,CAAC,IAAI,CAAC,6DAA6D,GAAG,EAAE,CAAC,CAAC;gBACtF,CAAC;gBACF,OAAO,IAAI,CAAC;YACjB,CAAC;QACN,CAAC,CAAC,CAAC;QAEH,MAAM,UAAU,GAAG,CAAC,MAAM,OAAO,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC;aAChC,MAAM,CAAC,CAAC,KAAK,EAA+B,EAAE,CAAC,KAAK,KAAK,IAAI,CAAC;aAC9D,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,EAAE,GAAG,IAAI,IAAI,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC,uBAAuB;QAE9H,OAAO,CAAC,GAAG,CAAC,sDAAsD,UAAU,CAAC,MAAM,6BAA6B,cAAc,EAAE,CAAC,CAAC;QAClI,OAAO,UAAU,CAAC;IAEvB,CAAC;IAAC,OAAO,KAAU,EAAE,CAAC;QAClB,OAAO,CAAC,KAAK,CAAC,uDAAuD,cAAc,GAAG,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;QACvG,OAAO,EAAE,CAAC,CAAC,8BAA8B;IAC7C,CAAC;AACL,CAAC"}===== ./dist/services/timelockService.js =====
"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.commitVerdictTimelocked = commitVerdictTimelocked;
exports.startRevealListener = startRevealListener;
exports.stopRevealListener = stopRevealListener;
const ethers_1 = require("ethers");
const blocklock_js_1 = require("blocklock-js");
const config_1 = __importDefault(require("../config"));
const KintaskCommitment_json_1 = __importDefault(require("../contracts/abi/KintaskCommitment.json")); // Load the ABI
const addresses_1 = require("../contracts/addresses");
const recallService_1 = require("./recallService"); // Import recall logger for reveal events
// --- Initialization ---
let provider = null;
let wallet = null;
let blocklockJsInstance = null;
let commitmentContract = null;
let isTimelockInitialized = false;
let revealListenerAttached = false;
// Simple mapping to associate blocklock request ID with our internal request context for logging reveals
const blocklockIdToRequestContext = new Map();
const MAX_CONTEXT_MAP_SIZE = 1000; // Prevent memory leak
// Function to initialize (or re-initialize) the service
// Returns true if initialization is complete or already done, false if required config is missing
function initializeTimelockService() {
    if (isTimelockInitialized)
        return true; // Already initialized
    console.log("[Timelock Service] Initializing...");
    try {
        // Validate critical config FIRST
        if (!config_1.default.l2RpcUrl || !config_1.default.walletPrivateKey || !config_1.default.blocklockSenderProxyAddress || !addresses_1.KINTASK_COMMITMENT_CONTRACT_ADDRESS) {
            console.warn("[Timelock Service] Skipping initialization: Missing required L2/Blocklock/Contract configuration in .env");
            return false; // Cannot initialize
        }
        // Validate ABI presence
        if (!KintaskCommitment_json_1.default.abi || KintaskCommitment_json_1.default.abi.length === 0) {
            console.error("[Timelock Service] FATAL ERROR: KintaskCommitment ABI not found or empty. Run 'pnpm contracts:compile' and copy ABI.");
            return false; // Cannot initialize without ABI
        }
        provider = new ethers_1.ethers.JsonRpcProvider(config_1.default.l2RpcUrl);
        wallet = new ethers_1.Wallet(config_1.default.walletPrivateKey, provider);
        blocklockJsInstance = new blocklock_js_1.Blocklock(wallet, config_1.default.blocklockSenderProxyAddress);
        commitmentContract = new ethers_1.Contract(addresses_1.KINTASK_COMMITMENT_CONTRACT_ADDRESS, KintaskCommitment_json_1.default.abi, wallet);
        // Perform async checks AFTER basic setup
        Promise.all([
            provider.getNetwork(),
            commitmentContract.getAddress() // Check if contract connection works
        ]).then(([network, address]) => {
            console.log(`[Timelock Service] Connected to network: ${network.name} (Chain ID: ${network.chainId})`);
            console.log(`[Timelock Service] KintaskCommitment contract instance connected at: ${address}`);
            isTimelockInitialized = true; // Mark as fully initialized only after checks pass
            console.log("[Timelock Service] Initialization complete.");
            // Attempt to start listener only after successful init
            startRevealListener(); // Start listener now that we are initialized
        }).catch(err => {
            console.error("[Timelock Service] Post-initialization check failed (Network or Contract connection issue):", err.message);
            // Keep isTimelockInitialized = false if checks fail
            isTimelockInitialized = false;
        });
        console.log("[Timelock Service] Initialization sequence started (async checks pending)...");
        return true; // Return true indicating initialization started
    }
    catch (error) {
        console.error("[Timelock Service] FATAL Initialization failed:", error.message);
        isTimelockInitialized = false;
        return false; // Indicate failure
    }
}
// Attempt initialization on module load
initializeTimelockService();
// --- Commit Function ---
async function commitVerdictTimelocked(verdict, delayInBlocks = 5, // Default delay
requestContext // Pass context for mapping reveal logs
) {
    // Check initialization status before proceeding
    if (!isTimelockInitialized || !blocklockJsInstance || !commitmentContract || !provider || !wallet) {
        console.error('[Timelock Service] Service not initialized or ready. Cannot commit verdict.');
        return null; // Fail if not ready
    }
    let txResponse = null; // Define txResponse outside try
    const logContext = requestContext || 'unknownContext'; // Use provided context or a default
    try {
        const currentBlockNumber = await provider.getBlockNumber();
        const decryptionBlockNumber = BigInt(currentBlockNumber + delayInBlocks);
        console.log(`[Timelock Service Context: ${logContext}] Current Block: ${currentBlockNumber}, Decryption Block Target: ${decryptionBlockNumber}`);
        // 1. Encode verdict string
        const encoder = ethers_1.AbiCoder.defaultAbiCoder();
        const encodedVerdict = encoder.encode(['string'], [verdict]);
        const encodedVerdictBytes = (0, ethers_1.getBytes)(encodedVerdict);
        // 2. Encrypt using blocklock-js
        console.log(`[Timelock Service Context: ${logContext}] Encrypting verdict "${verdict}"`);
        const ciphertext = blocklockJsInstance.encrypt(encodedVerdictBytes, decryptionBlockNumber);
        const solidityCiphertext = (0, blocklock_js_1.encodeCiphertextToSolidity)(ciphertext);
        const ciphertextHash = (0, ethers_1.keccak256)(solidityCiphertext.v); // Hash the encrypted part V
        console.log(`[Timelock Service Context: ${logContext}] Ciphertext Hash: ${ciphertextHash}`);
        // 3. Call commitVerdict on contract
        console.log(`[Timelock Service Context: ${logContext}] Sending commitVerdict transaction to ${await commitmentContract.getAddress()}...`);
        txResponse = await commitmentContract.commitVerdict(decryptionBlockNumber, solidityCiphertext
        // Optional: Add gas estimation/limit
        // { gasLimit: 300000 } // Example fixed gas limit
        );
        console.log(`[Timelock Service Context: ${logContext}] Commit transaction sent. Hash: ${txResponse.hash}`);
        console.log(`[Timelock Service Context: ${logContext}] Waiting for confirmation (1 block)...`);
        const receipt = await txResponse.wait(1);
        if (!receipt)
            throw new Error(`Commit transaction ${txResponse.hash} confirmation timed out or receipt was null.`);
        console.log(`[Timelock Service Context: ${logContext}] Commit Tx Confirmed. Status: ${receipt.status}, Block: ${receipt.blockNumber}`);
        if (receipt.status !== 1)
            throw new Error(`Commit transaction ${txResponse.hash} failed on-chain (Status: 0). Check explorer.`);
        // 4. Parse Blocklock Request ID from logs emitted by *our* contract
        const eventInterface = commitmentContract.interface.getEvent('VerdictCommitted');
        const eventTopic = eventInterface.topicHash;
        const receiptLogs = receipt.logs || []; // Ensure logs is an array
        const log = receiptLogs.find((l) => l.topics[0] === eventTopic &&
            l.address.toLowerCase() === addresses_1.KINTASK_COMMITMENT_CONTRACT_ADDRESS.toLowerCase());
        if (!log)
            throw new Error(`Could not find VerdictCommitted event log in transaction receipt for ${txResponse.hash}.`);
        const decodedLog = commitmentContract.interface.parseLog({ topics: [...log.topics], data: log.data });
        const blocklockRequestId = decodedLog?.args.blocklockRequestId?.toString();
        if (!blocklockRequestId)
            throw new Error('Failed to decode Blocklock Request ID from VerdictCommitted event.');
        console.log(`[Timelock Service Context: ${logContext}] Successfully committed. Blocklock Request ID: ${blocklockRequestId}`);
        // Store mapping for the listener
        if (requestContext) {
            if (blocklockIdToRequestContext.size >= MAX_CONTEXT_MAP_SIZE) {
                const oldestKey = blocklockIdToRequestContext.keys().next().value;
                blocklockIdToRequestContext.delete(oldestKey);
                console.warn(`[Timelock Service] Context map size limit reached, removed oldest entry: ${oldestKey}`);
            }
            blocklockIdToRequestContext.set(blocklockRequestId, requestContext);
            console.log(`[Timelock Service] Mapped Blocklock ID ${blocklockRequestId} to Context ${requestContext}`);
        }
        else {
            console.warn("[Timelock Service] Request context not provided for mapping reveal listener.");
        }
        return {
            requestId: blocklockRequestId,
            txHash: txResponse.hash,
            ciphertextHash: ciphertextHash
        };
    }
    catch (error) {
        console.error(`[Timelock Service Error Context: ${logContext}] Error during commit:`, error.message);
        if (txResponse?.hash)
            console.error(`[Timelock Service] Failing Transaction Hash: ${txResponse.hash}`);
        return null; // Indicate failure
    }
}
// --- Reveal Listener ---
function startRevealListener() {
    if (revealListenerAttached) {
        // console.log("[Timelock Service] Reveal listener already attached.");
        return;
    }
    // Ensure initialized before attaching listener
    if (!isTimelockInitialized || !commitmentContract) {
        console.warn("[Timelock Service] Cannot start listener, service not fully initialized yet.");
        // Initialization might still be in async checks, listener will start when/if init completes.
        return;
    }
    console.log(`[Timelock Service] Attaching listener for VerdictRevealed events on contract ${addresses_1.KINTASK_COMMITMENT_CONTRACT_ADDRESS}...`);
    try {
        const eventFilter = commitmentContract.filters.VerdictRevealed();
        // Using commitmentContract.on() sets up a persistent listener
        commitmentContract.on(eventFilter, async (requestIdBigInt, requester, revealedVerdictBytes, eventLog) => {
            // Type assertion for ethers v6 EventLog
            const log = eventLog;
            const blocklockRequestId = requestIdBigInt.toString();
            const txHash = log.transactionHash; // Tx hash where the Blocklock callback happened
            console.log(`\n[Timelock Listener] === Received VerdictRevealed Event ===`);
            console.log(`  Blocklock Request ID: ${blocklockRequestId}`);
            console.log(`  Event Source Tx Hash: ${txHash}`); // This is the Blocklock callback tx hash
            // Find the original request context using the mapping
            const requestContext = blocklockIdToRequestContext.get(blocklockRequestId);
            if (!requestContext) {
                console.warn(`[Timelock Listener] Could not find request context for revealed Blocklock ID: ${blocklockRequestId}. Cannot log details to Recall.`);
                // It's possible the context map was cleared or this ID was processed already
                return;
            }
            console.log(`  Associated Request Context: ${requestContext}`);
            // Clean up the mapping immediately to prevent reprocessing
            blocklockIdToRequestContext.delete(blocklockRequestId);
            try {
                // Decode the revealed verdict bytes (assuming it was encoded as a string)
                const encoder = ethers_1.AbiCoder.defaultAbiCoder();
                const [revealedVerdict] = encoder.decode(['string'], revealedVerdictBytes);
                console.log(`[Timelock Listener] Decoded Verdict for context ${requestContext}: "${revealedVerdict}"`);
                // Log this reveal event to Recall Service under the original request context
                await (0, recallService_1.logRecallEvent)('TIMELOCK_REVEAL_RECEIVED', { blocklockRequestId, revealedVerdict, sourceTxHash: txHash, requester }, requestContext);
                console.log(`[Timelock Listener] Logged TIMELOCK_REVEAL_RECEIVED to Recall for context ${requestContext}`);
                // TODO: Compare revealedVerdict with final calculated verdict from verifierService state?
            }
            catch (decodeError) {
                console.error(`[Timelock Listener] Error decoding revealed verdict for ID ${blocklockRequestId}, Context ${requestContext}:`, decodeError.message);
                // Log decode error to recall
                await (0, recallService_1.logRecallEvent)('VERIFICATION_ERROR', { stage: 'TimelockRevealDecode', error: decodeError.message, blocklockRequestId, rawBytes: ethers_1.ethers.hexlify(revealedVerdictBytes) }, requestContext);
            }
        });
        revealListenerAttached = true;
        console.log("[Timelock Service] Listener attached successfully.");
    }
    catch (error) {
        console.error("[Timelock Service] Failed to attach listener:", error.message);
        revealListenerAttached = false;
    }
}
// Function to stop listener (e.g., on shutdown)
function stopRevealListener() {
    if (revealListenerAttached && commitmentContract) {
        console.log("[Timelock Service] Removing VerdictRevealed listener...");
        try {
            // Use off() or removeAllListeners() depending on specific needs and ethers version guarantees
            commitmentContract.off("VerdictRevealed"); // Attempt to remove specific listener type
            // Alternatively: commitmentContract.removeAllListeners("VerdictRevealed");
            revealListenerAttached = false;
            console.log("[Timelock Service] Listener removed.");
        }
        catch (error) {
            console.error("[Timelock Service] Error removing listener:", error.message);
            revealListenerAttached = false;
        }
    }
    else {
        // console.log("[Timelock Service] Listener not attached or contract not initialized.");
    }
}
//# sourceMappingURL=timelockService.js.map===== ./dist/services/timelockService.js.map =====
{"version":3,"file":"timelockService.js","sourceRoot":"","sources":["../../src/services/timelockService.ts"],"names":[],"mappings":";;;;;AA6EA,0DAyFC;AAGD,kDA0EC;AAGD,gDAgBC;AAtQD,mCAAyI;AACzI,+CAAgG;AAChG,uDAA+B;AAC/B,qGAA2E,CAAC,eAAe;AAC3F,sDAA6E;AAC7E,mDAAiD,CAAC,yCAAyC;AAQ3F,yBAAyB;AACzB,IAAI,QAAQ,GAAkC,IAAI,CAAC;AACnD,IAAI,MAAM,GAAkB,IAAI,CAAC;AACjC,IAAI,mBAAmB,GAAqB,IAAI,CAAC;AACjD,IAAI,kBAAkB,GAAoB,IAAI,CAAC;AAC/C,IAAI,qBAAqB,GAAG,KAAK,CAAC;AAClC,IAAI,sBAAsB,GAAG,KAAK,CAAC;AACnC,yGAAyG;AACzG,MAAM,2BAA2B,GAAG,IAAI,GAAG,EAAkB,CAAC;AAC9D,MAAM,oBAAoB,GAAG,IAAI,CAAC,CAAC,sBAAsB;AAEzD,wDAAwD;AACxD,kGAAkG;AAClG,SAAS,yBAAyB;IAC9B,IAAI,qBAAqB;QAAE,OAAO,IAAI,CAAC,CAAC,sBAAsB;IAC9D,OAAO,CAAC,GAAG,CAAC,oCAAoC,CAAC,CAAC;IAClD,IAAI,CAAC;QACD,iCAAiC;QAChC,IAAI,CAAC,gBAAM,CAAC,QAAQ,IAAI,CAAC,gBAAM,CAAC,gBAAgB,IAAI,CAAC,gBAAM,CAAC,2BAA2B,IAAI,CAAC,+CAAmC,EAAE,CAAC;YAC9H,OAAO,CAAC,IAAI,CAAC,0GAA0G,CAAC,CAAC;YACzH,OAAO,KAAK,CAAC,CAAC,oBAAoB;QACtC,CAAC;QACD,wBAAwB;QACvB,IAAI,CAAC,gCAAoB,CAAC,GAAG,IAAI,gCAAoB,CAAC,GAAG,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;YACpE,OAAO,CAAC,KAAK,CAAC,sHAAsH,CAAC,CAAC;YACtI,OAAO,KAAK,CAAC,CAAC,gCAAgC;QACnD,CAAC;QAEH,QAAQ,GAAG,IAAI,eAAM,CAAC,eAAe,CAAC,gBAAM,CAAC,QAAQ,CAAC,CAAC;QACvD,MAAM,GAAG,IAAI,eAAM,CAAC,gBAAM,CAAC,gBAAgB,EAAE,QAAQ,CAAC,CAAC;QACvD,mBAAmB,GAAG,IAAI,wBAAS,CAAC,MAAM,EAAE,gBAAM,CAAC,2BAA2B,CAAC,CAAC;QAChF,kBAAkB,GAAG,IAAI,iBAAQ,CAAC,+CAAmC,EAAE,gCAAoB,CAAC,GAAG,EAAE,MAAM,CAAC,CAAC;QAEzG,yCAAyC;QACxC,OAAO,CAAC,GAAG,CAAC;YACR,QAAQ,CAAC,UAAU,EAAE;YACrB,kBAAkB,CAAC,UAAU,EAAE,CAAC,qCAAqC;SACxE,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,OAAO,EAAE,OAAO,CAAC,EAAE,EAAE;YAC3B,OAAO,CAAC,GAAG,CAAC,4CAA4C,OAAO,CAAC,IAAI,eAAe,OAAO,CAAC,OAAO,GAAG,CAAC,CAAC;YACvG,OAAO,CAAC,GAAG,CAAC,wEAAwE,OAAO,EAAE,CAAC,CAAC;YAC/F,qBAAqB,GAAG,IAAI,CAAC,CAAC,mDAAmD;YACjF,OAAO,CAAC,GAAG,CAAC,6CAA6C,CAAC,CAAC;YAC3D,uDAAuD;YACtD,mBAAmB,EAAE,CAAC,CAAC,6CAA6C;QACzE,CAAC,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,EAAE;YACX,OAAO,CAAC,KAAK,CAAC,6FAA6F,EAAE,GAAG,CAAC,OAAO,CAAC,CAAC;YAC1H,oDAAoD;YACpD,qBAAqB,GAAG,KAAK,CAAC;QAClC,CAAC,CAAC,CAAC;QAEH,OAAO,CAAC,GAAG,CAAC,8EAA8E,CAAC,CAAC;QAC5F,OAAO,IAAI,CAAC,CAAC,gDAAgD;IAElE,CAAC;IAAC,OAAO,KAAU,EAAE,CAAC;QACjB,OAAO,CAAC,KAAK,CAAC,iDAAiD,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;QAChF,qBAAqB,GAAG,KAAK,CAAC;QAC9B,OAAO,KAAK,CAAC,CAAC,mBAAmB;IACtC,CAAC;AACL,CAAC;AAED,wCAAwC;AACxC,yBAAyB,EAAE,CAAC;AAE5B,0BAA0B;AACnB,KAAK,UAAU,uBAAuB,CACzC,OAAe,EACf,gBAAwB,CAAC,EAAE,gBAAgB;AAC3C,cAAuB,CAAC,uCAAuC;;IAG/D,gDAAgD;IAChD,IAAI,CAAC,qBAAqB,IAAI,CAAC,mBAAmB,IAAI,CAAC,kBAAkB,IAAI,CAAC,QAAQ,IAAI,CAAC,MAAM,EAAE,CAAC;QAChG,OAAO,CAAC,KAAK,CAAC,6EAA6E,CAAC,CAAC;QAC7F,OAAO,IAAI,CAAC,CAAC,oBAAoB;IACrC,CAAC;IAED,IAAI,UAAU,GAA+B,IAAI,CAAC,CAAC,gCAAgC;IACnF,MAAM,UAAU,GAAG,cAAc,IAAI,gBAAgB,CAAC,CAAC,oCAAoC;IAE3F,IAAI,CAAC;QACD,MAAM,kBAAkB,GAAG,MAAM,QAAQ,CAAC,cAAc,EAAE,CAAC;QAC3D,MAAM,qBAAqB,GAAG,MAAM,CAAC,kBAAkB,GAAG,aAAa,CAAC,CAAC;QACzE,OAAO,CAAC,GAAG,CAAC,8BAA8B,UAAU,oBAAoB,kBAAkB,8BAA8B,qBAAqB,EAAE,CAAC,CAAC;QAEjJ,2BAA2B;QAC3B,MAAM,OAAO,GAAG,iBAAQ,CAAC,eAAe,EAAE,CAAC;QAC3C,MAAM,cAAc,GAAG,OAAO,CAAC,MAAM,CAAC,CAAC,QAAQ,CAAC,EAAE,CAAC,OAAO,CAAC,CAAC,CAAC;QAC7D,MAAM,mBAAmB,GAAG,IAAA,iBAAQ,EAAC,cAAc,CAAC,CAAC;QAErD,gCAAgC;QAChC,OAAO,CAAC,GAAG,CAAC,8BAA8B,UAAU,yBAAyB,OAAO,GAAG,CAAC,CAAC;QACzF,MAAM,UAAU,GAAwB,mBAAmB,CAAC,OAAO,CAAC,mBAAmB,EAAE,qBAAqB,CAAC,CAAC;QAChH,MAAM,kBAAkB,GAAG,IAAA,yCAA0B,EAAC,UAAU,CAAC,CAAC;QAClE,MAAM,cAAc,GAAG,IAAA,kBAAS,EAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,4BAA4B;QACpF,OAAO,CAAC,GAAG,CAAC,8BAA8B,UAAU,sBAAsB,cAAc,EAAE,CAAC,CAAC;QAE5F,oCAAoC;QACpC,OAAO,CAAC,GAAG,CAAC,8BAA8B,UAAU,0CAA0C,MAAM,kBAAkB,CAAC,UAAU,EAAE,KAAK,CAAC,CAAC;QAC1I,UAAU,GAAG,MAAM,kBAAkB,CAAC,aAAa,CAC/C,qBAAqB,EACrB,kBAAkB;QAClB,qCAAqC;QACrC,kDAAkD;SACrD,CAAC;QACF,OAAO,CAAC,GAAG,CAAC,8BAA8B,UAAU,oCAAoC,UAAU,CAAC,IAAI,EAAE,CAAC,CAAC;QAC3G,OAAO,CAAC,GAAG,CAAC,8BAA8B,UAAU,yCAAyC,CAAC,CAAC;QAC/F,MAAM,OAAO,GAA8B,MAAM,UAAU,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QAEpE,IAAI,CAAC,OAAO;YAAE,MAAM,IAAI,KAAK,CAAC,sBAAsB,UAAU,CAAC,IAAI,8CAA8C,CAAC,CAAC;QACnH,OAAO,CAAC,GAAG,CAAC,8BAA8B,UAAU,kCAAkC,OAAO,CAAC,MAAM,YAAY,OAAO,CAAC,WAAW,EAAE,CAAC,CAAC;QACvI,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC;YAAE,MAAM,IAAI,KAAK,CAAC,sBAAsB,UAAU,CAAC,IAAI,+CAA+C,CAAC,CAAC;QAEhI,oEAAoE;QACpE,MAAM,cAAc,GAAG,kBAAkB,CAAC,SAAS,CAAC,QAAQ,CAAC,kBAAkB,CAAC,CAAC;QACjF,MAAM,UAAU,GAAG,cAAc,CAAC,SAAS,CAAC;QAC5C,MAAM,WAAW,GAAG,OAAO,CAAC,IAAI,IAAI,EAAE,CAAC,CAAC,0BAA0B;QAClE,MAAM,GAAG,GAAG,WAAW,CAAC,IAAI,CAAC,CAAC,CAAM,EAAE,EAAE,CACpC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,UAAU;YAC1B,CAAC,CAAC,OAAO,CAAC,WAAW,EAAE,KAAK,+CAAmC,CAAC,WAAW,EAAE,CAChF,CAAC;QAEF,IAAI,CAAC,GAAG;YAAE,MAAM,IAAI,KAAK,CAAC,wEAAwE,UAAU,CAAC,IAAI,GAAG,CAAC,CAAC;QAEtH,MAAM,UAAU,GAAG,kBAAkB,CAAC,SAAS,CAAC,QAAQ,CAAC,EAAE,MAAM,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,EAAE,IAAI,EAAE,GAAG,CAAC,IAAI,EAAE,CAAC,CAAC;QACtG,MAAM,kBAAkB,GAAG,UAAU,EAAE,IAAI,CAAC,kBAAkB,EAAE,QAAQ,EAAE,CAAC;QAC3E,IAAI,CAAC,kBAAkB;YAAE,MAAM,IAAI,KAAK,CAAC,oEAAoE,CAAC,CAAC;QAE/G,OAAO,CAAC,GAAG,CAAC,8BAA8B,UAAU,mDAAmD,kBAAkB,EAAE,CAAC,CAAC;QAE7H,iCAAiC;QACjC,IAAI,cAAc,EAAE,CAAC;YACjB,IAAI,2BAA2B,CAAC,IAAI,IAAI,oBAAoB,EAAE,CAAC;gBAC3D,MAAM,SAAS,GAAG,2BAA2B,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,KAAK,CAAC;gBACjE,2BAA2B,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;gBAC9C,OAAO,CAAC,IAAI,CAAC,4EAA4E,SAAS,EAAE,CAAC,CAAC;YAC3G,CAAC;YACD,2BAA2B,CAAC,GAAG,CAAC,kBAAkB,EAAE,cAAc,CAAC,CAAC;YACpE,OAAO,CAAC,GAAG,CAAC,0CAA0C,kBAAkB,eAAe,cAAc,EAAE,CAAC,CAAC;QAC7G,CAAC;aAAM,CAAC;YACH,OAAO,CAAC,IAAI,CAAC,8EAA8E,CAAC,CAAC;QAClG,CAAC;QAED,OAAO;YACH,SAAS,EAAE,kBAAkB;YAC7B,MAAM,EAAE,UAAU,CAAC,IAAI;YACvB,cAAc,EAAE,cAAc;SACjC,CAAC;IAEN,CAAC;IAAC,OAAO,KAAU,EAAE,CAAC;QAClB,OAAO,CAAC,KAAK,CAAC,oCAAoC,UAAU,wBAAwB,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;QACrG,IAAI,UAAU,EAAE,IAAI;YAAE,OAAO,CAAC,KAAK,CAAC,gDAAgD,UAAU,CAAC,IAAI,EAAE,CAAC,CAAC;QACvG,OAAO,IAAI,CAAC,CAAC,mBAAmB;IACpC,CAAC;AACL,CAAC;AAED,0BAA0B;AAC1B,SAAgB,mBAAmB;IAC/B,IAAI,sBAAsB,EAAE,CAAC;QACzB,uEAAuE;QACvE,OAAO;IACX,CAAC;IACA,+CAA+C;IAC/C,IAAI,CAAC,qBAAqB,IAAI,CAAC,kBAAkB,EAAE,CAAC;QAChD,OAAO,CAAC,IAAI,CAAC,8EAA8E,CAAC,CAAC;QAC7F,6FAA6F;QAC7F,OAAO;IACX,CAAC;IAEF,OAAO,CAAC,GAAG,CAAC,gFAAgF,+CAAmC,KAAK,CAAC,CAAC;IACtI,IAAI,CAAC;QACD,MAAM,WAAW,GAAG,kBAAkB,CAAC,OAAO,CAAC,eAAe,EAAE,CAAC;QAEhE,8DAA8D;QAC9D,kBAAkB,CAAC,EAAE,CAAC,WAAW,EAAE,KAAK,EAAE,eAAe,EAAE,SAAS,EAAE,oBAAoB,EAAE,QAAQ,EAAE,EAAE;YACrG,wCAAwC;YACxC,MAAM,GAAG,GAAG,QAA+B,CAAC;YAC5C,MAAM,kBAAkB,GAAG,eAAe,CAAC,QAAQ,EAAE,CAAC;YACtD,MAAM,MAAM,GAAG,GAAG,CAAC,eAAe,CAAC,CAAC,gDAAgD;YAEpF,OAAO,CAAC,GAAG,CAAC,8DAA8D,CAAC,CAAC;YAC5E,OAAO,CAAC,GAAG,CAAC,2BAA2B,kBAAkB,EAAE,CAAC,CAAC;YAC7D,OAAO,CAAC,GAAG,CAAC,2BAA2B,MAAM,EAAE,CAAC,CAAC,CAAC,yCAAyC;YAE1F,sDAAsD;YACtD,MAAM,cAAc,GAAG,2BAA2B,CAAC,GAAG,CAAC,kBAAkB,CAAC,CAAC;YAC3E,IAAI,CAAC,cAAc,EAAE,CAAC;gBAClB,OAAO,CAAC,IAAI,CAAC,iFAAiF,kBAAkB,iCAAiC,CAAC,CAAC;gBACnJ,6EAA6E;gBAC7E,OAAO;YACX,CAAC;YACD,OAAO,CAAC,GAAG,CAAC,iCAAiC,cAAc,EAAE,CAAC,CAAC;YAE/D,2DAA2D;YAC3D,2BAA2B,CAAC,MAAM,CAAC,kBAAkB,CAAC,CAAC;YAEvD,IAAI,CAAC;gBACF,0EAA0E;gBAC1E,MAAM,OAAO,GAAG,iBAAQ,CAAC,eAAe,EAAE,CAAC;gBAC3C,MAAM,CAAC,eAAe,CAAC,GAAG,OAAO,CAAC,MAAM,CAAC,CAAC,QAAQ,CAAC,EAAE,oBAAoB,CAAC,CAAC;gBAE3E,OAAO,CAAC,GAAG,CAAC,mDAAmD,cAAc,MAAM,eAAe,GAAG,CAAC,CAAC;gBAEvG,6EAA6E;gBAC7E,MAAM,IAAA,8BAAc,EAChB,0BAA0B,EAC1B,EAAE,kBAAkB,EAAE,eAAe,EAAE,YAAY,EAAE,MAAM,EAAE,SAAS,EAAE,EACxE,cAAc,CACjB,CAAC;gBACF,OAAO,CAAC,GAAG,CAAC,6EAA6E,cAAc,EAAE,CAAC,CAAC;gBAE3G,0FAA0F;YAE7F,CAAC;YAAC,OAAM,WAAgB,EAAE,CAAC;gBACxB,OAAO,CAAC,KAAK,CAAC,8DAA8D,kBAAkB,aAAa,cAAc,GAAG,EAAE,WAAW,CAAC,OAAO,CAAC,CAAC;gBACnJ,6BAA6B;gBAC5B,MAAM,IAAA,8BAAc,EACjB,oBAAoB,EACpB,EAAE,KAAK,EAAE,sBAAsB,EAAE,KAAK,EAAE,WAAW,CAAC,OAAO,EAAE,kBAAkB,EAAE,QAAQ,EAAE,eAAM,CAAC,OAAO,CAAC,oBAAoB,CAAC,EAAE,EACjI,cAAc,CACjB,CAAC;YACL,CAAC;QACL,CAAC,CAAC,CAAC;QAEJ,sBAAsB,GAAG,IAAI,CAAC;QAC9B,OAAO,CAAC,GAAG,CAAC,oDAAoD,CAAC,CAAC;IAEtE,CAAC;IAAC,OAAO,KAAU,EAAE,CAAC;QAClB,OAAO,CAAC,KAAK,CAAC,+CAA+C,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;QAC9E,sBAAsB,GAAG,KAAK,CAAC;IACnC,CAAC;AACL,CAAC;AAED,gDAAgD;AAChD,SAAgB,kBAAkB;IAC7B,IAAI,sBAAsB,IAAI,kBAAkB,EAAE,CAAC;QAC/C,OAAO,CAAC,GAAG,CAAC,yDAAyD,CAAC,CAAC;QACvE,IAAI,CAAC;YACD,8FAA8F;YAC9F,kBAAkB,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC,CAAC,2CAA2C;YACtF,2EAA2E;YAC3E,sBAAsB,GAAG,KAAK,CAAC;YAC/B,OAAO,CAAC,GAAG,CAAC,sCAAsC,CAAC,CAAC;QACxD,CAAC;QAAC,OAAO,KAAU,EAAE,CAAC;YAClB,OAAO,CAAC,KAAK,CAAC,6CAA6C,EAAE,KAAK,CAAC,OAAO,CAAC,CAAC;YAC5E,sBAAsB,GAAG,KAAK,CAAC;QACnC,CAAC;IACL,CAAC;SAAM,CAAC;QACH,wFAAwF;IAC7F,CAAC;AACN,CAAC"}===== ./dist/services/verifierService.js =====
"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.performVerification = performVerification;
const filecoinService_1 = require("./filecoinService");
const timelockService_1 = require("./timelockService");
const recallService_1 = require("./recallService");
const utils_1 = require("../utils"); // Import utility
const config_1 = __importDefault(require("../config")); // Import config to check if timelock is configured
// --- Helper Function ---
const addStep = async (reasoningSteps, requestContext, type, details) => {
    const timestamp = new Date().toISOString();
    // Simple truncation for potentially large values in logs
    const truncatedDetails = Object.entries(details).reduce((acc, [key, value]) => {
        try {
            if (typeof value === 'string') {
                acc[key] = (0, utils_1.truncateText)(value, 250); // Truncate long strings
            }
            else if (Array.isArray(value) && value.length > 15) {
                acc[key] = value.slice(0, 15).concat(['...truncated...']); // Truncate long arrays
            }
            else if (key === 'stack') { // Don't stringify stack traces if too long
                acc[key] = (0, utils_1.truncateText)(value?.toString(), 300);
            }
            else if (typeof value === 'object' && value !== null && JSON.stringify(value).length > 300) {
                acc[key] = { _truncated: true, keys: Object.keys(value).slice(0, 5) }; // Truncate large objects
            }
            else if (typeof value === 'bigint') {
                acc[key] = value.toString(); // Convert BigInts
            }
            else {
                acc[key] = value;
            }
        }
        catch (e) {
            acc[key] = `<<Error truncating value for key ${key}>>`; // Handle potential errors during truncation/stringification
        }
        return acc;
    }, {});
    const stepData = { timestamp, type, details: truncatedDetails, requestContext };
    reasoningSteps.push(stepData);
    // Fire-and-forget logging to Recall
    (0, recallService_1.logRecallEvent)(type, truncatedDetails, requestContext).catch(err => {
        console.error(`[Verifier Service] Background logging to Recall failed for type ${type}:`, err.message);
    });
};
// --- Main Verification Logic Function ---
async function performVerification(question, answer, requestContext // Identifier for this specific verification task
) {
    console.log(`[Verifier Service] Starting verification for context: ${requestContext}`);
    const reasoningSteps = [];
    let usedFragmentCids = []; // Track CIDs successfully fetched AND used in logic
    let preliminaryVerdict = 'Unverified';
    let confidenceScore = 0.5; // Start neutral
    let timelockDetails = null;
    try {
        // --- Step 1: Input Analysis & Keyword Extraction ---
        const questionLower = question.toLowerCase();
        const answerLower = answer.toLowerCase();
        const stopWords = new Set(['the', 'a', 'an', 'is', 'of', 'in', 'on', 'at', 'to', 'for', 'and', 'or', 'what', 'who', 'where', 'when', 'why', 'how', 'tell', 'me', 'about', 'can', 'you', 'please', 'i', 'it', 'my', 'your']);
        const keywords = [...new Set(questionLower.split(/\s+/) // Split by whitespace
                .map(word => word.replace(/[^\w]/g, '').trim()) // Remove punctuation
                .filter(word => word.length >= 3 && !stopWords.has(word)) // Filter length and stopwords
            )];
        await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { step: 'AnalyzeInput', extractedKeywords: keywords });
        // --- Step 2: Fetch Index & Relevant CIDs ---
        await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_ATTEMPT', { stage: 'Index', keywords });
        const index = await (0, filecoinService_1.getKnowledgeIndex)(); // Fetches from cache or network
        let relevantCids = [];
        if (index) {
            keywords.forEach(kw => {
                if (index[kw])
                    relevantCids.push(...index[kw]);
            });
            relevantCids = [...new Set(relevantCids)]; // Deduplicate CIDs
            await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_SUCCESS', { stage: 'Index', foundCidsCount: relevantCids.length });
        }
        else {
            await addStep(reasoningSteps, requestContext, 'VERIFICATION_ERROR', { stage: 'IndexFetch', error: 'Failed to retrieve knowledge index' });
            console.error("[Verifier Service] Failed to retrieve knowledge index. Verification quality may be reduced.");
            // Decide whether to throw or continue. Let's continue for robustness.
        }
        // Limit number of fragments to fetch/process for performance in MVP
        const MAX_FRAGMENTS_TO_PROCESS = 10;
        const cidsToFetch = relevantCids.slice(0, MAX_FRAGMENTS_TO_PROCESS);
        if (relevantCids.length > MAX_FRAGMENTS_TO_PROCESS) {
            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { warning: 'Too many relevant fragments found', count: relevantCids.length, processingLimit: MAX_FRAGMENTS_TO_PROCESS });
        }
        // --- Step 3: Fetch KG Fragments Concurrently ---
        await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_ATTEMPT', { stage: 'Fragments', cidsToFetchCount: cidsToFetch.length });
        const fetchPromises = cidsToFetch.map(cid => (0, filecoinService_1.fetchKnowledgeFragment)(cid).then(fragment => ({ cid, fragment })));
        const fetchedResults = await Promise.all(fetchPromises);
        const fetchedFragments = [];
        const successfullyFetchedCids = new Set();
        const failedFetches = [];
        fetchedResults.forEach(result => {
            if (result.fragment) {
                fetchedFragments.push(result.fragment);
                successfullyFetchedCids.add(result.cid);
            }
            else {
                failedFetches.push(result.cid);
            }
        });
        await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_SUCCESS', { stage: 'Fragments', fetchedCount: fetchedFragments.length, failedCidsCount: failedFetches.length });
        // --- Step 4: Apply Verification Logic ---
        if (fetchedFragments.length === 0 && relevantCids.length > 0) {
            // If index found CIDs but fetching failed for all relevant ones
            console.warn(`[Verifier Service] No relevant knowledge fragments could be fetched for context ${requestContext}, although index suggested ${relevantCids.length}.`);
            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { warning: 'No fragments fetched despite finding relevant CIDs', failedCids });
            preliminaryVerdict = 'Unverified'; // Cannot verify without data
            confidenceScore = 0.1; // Very low confidence
        }
        else if (fetchedFragments.length === 0 && relevantCids.length === 0) {
            // If index found no relevant CIDs
            console.log(`[Verifier Service] No relevant knowledge fragments found in index for context ${requestContext}.`);
            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { info: 'No relevant fragments found in index' });
            preliminaryVerdict = 'Unverified';
            confidenceScore = 0.3; // Slightly higher confidence than fetch failure
        }
        else {
            // Apply logic only if fragments were fetched
            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { step: 'ApplyVerificationLogic', fragmentCount: fetchedFragments.length });
            let supportingScore = 0;
            let contradictingScore = 0;
            let uncertaintyFlags = 0;
            let provenanceIssues = 0;
            const fragmentsUsedInLogic = [];
            for (const fragment of fetchedFragments) {
                const fragmentId = fragment.fragment_id || `cid:${fragment.previous_version_cid?.substring(0, 8) ?? (0, utils_1.truncateText)([...successfullyFetchedCids][fragmentsUsedInLogic.length], 8)}`;
                fragmentsUsedInLogic.push(fragmentId);
                try {
                    const fragmentConf = fragment.provenance?.confidence_score ?? 0.7;
                    // A) Uncertainty Check
                    if (fragmentConf < 0.4) {
                        uncertaintyFlags++;
                        await addStep(reasoningSteps, requestContext, 'PROVENANCE_CHECK', { check: 'LowConfidenceSource', fragmentId, score: fragmentConf });
                    }
                    // B) Fact Matching Logic (Simple Placeholder)
                    if (fragment.type === 'factual_statement' && fragment.content?.subject && fragment.content?.object) {
                        const subject = fragment.content.subject.toLowerCase();
                        const objectVal = fragment.content.object.toLowerCase();
                        if ((keywords.includes(subject) || questionLower.includes(subject)) && answerLower.includes(objectVal)) {
                            supportingScore += fragmentConf;
                            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { check: 'FactMatch', fragmentId, outcome: 'Support', score: fragmentConf });
                        }
                    }
                    // C) Provenance Checks (Recency Example)
                    if (fragment.provenance?.timestamp_created) {
                        const createdDate = new Date(fragment.provenance.timestamp_created);
                        const ageDays = (Date.now() - createdDate.getTime()) / (1000 * 3600 * 24);
                        if (ageDays > 730) {
                            provenanceIssues++;
                            await addStep(reasoningSteps, requestContext, 'PROVENANCE_CHECK', { check: 'Age', fragmentId, ageDays: Math.round(ageDays), outcome: 'Very Stale (>2yr)' });
                        }
                    }
                    // D) Cross-Chain Attestation Check (Simulated Pass)
                    const attestations = fragment.provenance?.external_attestations;
                    if (attestations && attestations.length > 0) {
                        supportingScore += 0.1 * attestations.length; // Small boost
                        await addStep(reasoningSteps, requestContext, 'CROSSCHAIN_CHECK', { check: 'AttestationExists', fragmentId, count: attestations.length, outcome: 'BoostedConfidence(Simulated)' });
                    }
                }
                catch (logicError) {
                    console.error(`[Verifier Service] Error processing fragment ${fragmentId} for context ${requestContext}: ${logicError.message}`);
                    await addStep(reasoningSteps, requestContext, 'VERIFICATION_ERROR', { stage: 'LogicExecution', fragmentId, error: logicError.message });
                }
            } // End fragment loop
            usedFragmentCids = fragmentsUsedInLogic; // Update based on actual usage
            // Determine Preliminary Verdict
            confidenceScore = 0.5 + (supportingScore - contradictingScore) * 0.5 - (provenanceIssues * 0.05) - (uncertaintyFlags * 0.2);
            confidenceScore = Math.max(0.01, Math.min(0.99, confidenceScore)); // Clamp
            if (uncertaintyFlags > 0)
                preliminaryVerdict = 'Flagged: Uncertain';
            else if (contradictingScore > supportingScore * 1.5)
                preliminaryVerdict = 'Flagged: Contradictory';
            else if (supportingScore > 0.5 && confidenceScore > 0.65)
                preliminaryVerdict = 'Verified';
            else
                preliminaryVerdict = 'Unverified';
            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', {
                step: 'LogicComplete',
                calculatedVerdict: preliminaryVerdict,
                calculatedConfidence: confidenceScore,
                supportingScore: supportingScore.toFixed(2),
                contradictoryScore: contradictoryScore.toFixed(2),
                uncertaintyFlags, provenanceIssues
            });
        } // End of else block (if fragments were fetched)
        // --- Step 5: Timelock Commit ---
        // Check if contract address is configured before attempting commit
        if (config_1.default.kintaskContractAddress && config_1.default.blocklockSenderProxyAddress) {
            await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_ATTEMPT', { verdictToCommit: preliminaryVerdict });
            if (!preliminaryVerdict.startsWith('Error:')) { // Only commit if no prior critical error
                timelockDetails = await (0, timelockService_1.commitVerdictTimelocked)(preliminaryVerdict, 5, requestContext);
                if (timelockDetails) {
                    await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_SUCCESS', {
                        requestId: timelockDetails.requestId,
                        txHash: timelockDetails.txHash,
                        ciphertextHash: timelockDetails.ciphertextHash,
                        committedVerdict: preliminaryVerdict
                    });
                }
                else {
                    await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_FAILURE', { error: 'commitVerdictTimelocked returned null or failed' });
                    preliminaryVerdict = 'Error: Timelock Failed'; // Update status
                    confidenceScore = 0; // Reset confidence
                }
            }
            else {
                console.warn(`[Verifier Service] Skipping timelock commit due to prior error status: ${preliminaryVerdict}`);
                await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_FAILURE', { reason: 'Skipped due to prior error', priorStatus: preliminaryVerdict });
            }
        }
        else {
            console.warn(`[Verifier Service] Skipping timelock commit: KINTASK_CONTRACT_ADDRESS or BLOCKLOCK_SENDER_PROXY_ADDRESS not configured.`);
            await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_FAILURE', { reason: 'Skipped: Contract/Proxy address not configured' });
        }
        // --- Step 6: Final Result Object ---
        const finalResult = {
            finalVerdict: preliminaryVerdict,
            confidenceScore: parseFloat(confidenceScore.toFixed(2)), // Format confidence
            usedFragmentCids: usedFragmentCids,
            reasoningSteps: reasoningSteps, // Return collected steps for controller
            timelockRequestId: timelockDetails?.requestId,
            timelockCommitTxHash: timelockDetails?.txHash,
            ciphertextHash: timelockDetails?.ciphertextHash
        };
        console.log(`[Verifier Service] Verification complete for context ${requestContext}. Verdict: ${finalResult.finalVerdict}, Confidence: ${finalResult.confidenceScore}`);
        return finalResult;
    }
    catch (error) {
        console.error(`[Verifier Service Error Request: ${requestContext}]:`, error.message, error.stack);
        await addStep(reasoningSteps, requestContext, 'VERIFICATION_ERROR', { error: error.message, stage: 'TopLevelCatch' });
        // Return a consistent error state result
        return {
            finalVerdict: 'Error: Verification Failed',
            confidenceScore: 0,
            usedFragmentCids: usedFragmentCids,
            reasoningSteps: reasoningSteps,
            timelockRequestId: timelockDetails?.requestId,
            timelockCommitTxHash: timelockDetails?.txHash,
            ciphertextHash: timelockDetails?.ciphertextHash
        };
    }
}
//# sourceMappingURL=verifierService.js.map===== ./dist/services/verifierService.js.map =====
{"version":3,"file":"verifierService.js","sourceRoot":"","sources":["../../src/services/verifierService.ts"],"names":[],"mappings":";;;;;AAsDA,kDAyNC;AAxQD,uDAA8E;AAC9E,uDAA4D;AAC5D,mDAAiD;AACjD,oCAAwC,CAAC,iBAAiB;AAC1D,uDAA+B,CAAC,mDAAmD;AAEnF,0BAA0B;AAC1B,MAAM,OAAO,GAAG,KAAK,EACjB,cAAoC,EACpC,cAAsB,EACtB,IAAqB,EACrB,OAA4B,EAC9B,EAAE;IACA,MAAM,SAAS,GAAG,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE,CAAC;IAC3C,yDAAyD;IACzD,MAAM,gBAAgB,GAAG,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,KAAK,CAAC,EAAE,EAAE;QAC1E,IAAI,CAAC;YACD,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,CAAC;gBAC5B,GAAG,CAAC,GAAG,CAAC,GAAG,IAAA,oBAAY,EAAC,KAAK,EAAE,GAAG,CAAC,CAAC,CAAC,wBAAwB;YACjE,CAAC;iBAAM,IAAI,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,IAAI,KAAK,CAAC,MAAM,GAAG,EAAE,EAAE,CAAC;gBAClD,GAAG,CAAC,GAAG,CAAC,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,MAAM,CAAC,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,uBAAuB;YACvF,CAAC;iBAAM,IAAI,GAAG,KAAK,OAAO,EAAE,CAAC,CAAC,2CAA2C;gBACpE,GAAG,CAAC,GAAG,CAAC,GAAG,IAAA,oBAAY,EAAC,KAAK,EAAE,QAAQ,EAAE,EAAE,GAAG,CAAC,CAAC;YACrD,CAAC;iBAAM,IAAI,OAAO,KAAK,KAAK,QAAQ,IAAI,KAAK,KAAK,IAAI,IAAI,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,MAAM,GAAG,GAAG,EAAE,CAAC;gBAC1F,GAAG,CAAC,GAAG,CAAC,GAAG,EAAE,UAAU,EAAE,IAAI,EAAE,IAAI,EAAE,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,KAAK,CAAC,CAAC,EAAC,CAAC,CAAC,EAAE,CAAC,CAAC,yBAAyB;YACpG,CAAC;iBAAM,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,CAAC;gBAClC,GAAG,CAAC,GAAG,CAAC,GAAG,KAAK,CAAC,QAAQ,EAAE,CAAC,CAAC,kBAAkB;YACpD,CAAC;iBACI,CAAC;gBACF,GAAG,CAAC,GAAG,CAAC,GAAG,KAAK,CAAC;YACrB,CAAC;QACL,CAAC;QAAC,OAAO,CAAC,EAAE,CAAC;YACR,GAAG,CAAC,GAAG,CAAC,GAAG,oCAAoC,GAAG,IAAI,CAAC,CAAC,4DAA4D;QACzH,CAAC;QACD,OAAO,GAAG,CAAC;IACf,CAAC,EAAE,EAAyB,CAAC,CAAC;IAE9B,MAAM,QAAQ,GAAuB,EAAE,SAAS,EAAE,IAAI,EAAE,OAAO,EAAE,gBAAgB,EAAE,cAAc,EAAE,CAAC;IACpG,cAAc,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;IAC9B,oCAAoC;IACpC,IAAA,8BAAc,EAAC,IAAI,EAAE,gBAAgB,EAAE,cAAc,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,EAAE;QAC/D,OAAO,CAAC,KAAK,CAAC,mEAAmE,IAAI,GAAG,EAAE,GAAG,CAAC,OAAO,CAAC,CAAC;IAC3G,CAAC,CAAC,CAAC;AACP,CAAC,CAAC;AAGF,2CAA2C;AACpC,KAAK,UAAU,mBAAmB,CACrC,QAAgB,EAChB,MAAc,EACd,cAAsB,CAAC,iDAAiD;;IAGxE,OAAO,CAAC,GAAG,CAAC,yDAAyD,cAAc,EAAE,CAAC,CAAC;IACvF,MAAM,cAAc,GAAyB,EAAE,CAAC;IAChD,IAAI,gBAAgB,GAAa,EAAE,CAAC,CAAC,oDAAoD;IACzF,IAAI,kBAAkB,GAAuB,YAAY,CAAC;IAC1D,IAAI,eAAe,GAAG,GAAG,CAAC,CAAC,gBAAgB;IAC3C,IAAI,eAAe,GAAwD,IAAI,CAAC;IAEhF,IAAI,CAAC;QACD,sDAAsD;QACtD,MAAM,aAAa,GAAG,QAAQ,CAAC,WAAW,EAAE,CAAC;QAC7C,MAAM,WAAW,GAAG,MAAM,CAAC,WAAW,EAAE,CAAC;QACzC,MAAM,SAAS,GAAG,IAAI,GAAG,CAAC,CAAC,KAAK,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,MAAM,EAAE,IAAI,EAAE,OAAO,EAAE,KAAK,EAAE,KAAK,EAAE,QAAQ,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,EAAE,MAAM,CAAC,CAAC,CAAC;QAC5N,MAAM,QAAQ,GAAG,CAAC,GAAG,IAAI,GAAG,CACxB,aAAa,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,sBAAsB;iBAC5C,GAAG,CAAC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,OAAO,CAAC,QAAQ,EAAE,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,qBAAqB;iBACpE,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,MAAM,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,8BAA8B;aAC/F,CAAC,CAAC;QACH,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,gBAAgB,EAAE,EAAE,IAAI,EAAE,cAAc,EAAE,iBAAiB,EAAE,QAAQ,EAAE,CAAC,CAAC;QAEvH,8CAA8C;QAC9C,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,yBAAyB,EAAE,EAAE,KAAK,EAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,CAAC;QACvG,MAAM,KAAK,GAAG,MAAM,IAAA,mCAAiB,GAAE,CAAC,CAAC,gCAAgC;QACzE,IAAI,YAAY,GAAa,EAAE,CAAC;QAChC,IAAI,KAAK,EAAE,CAAC;YACR,QAAQ,CAAC,OAAO,CAAC,EAAE,CAAC,EAAE;gBAClB,IAAI,KAAK,CAAC,EAAE,CAAC;oBAAE,YAAY,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC,EAAE,CAAC,CAAC,CAAC;YACnD,CAAC,CAAC,CAAC;YACH,YAAY,GAAG,CAAC,GAAG,IAAI,GAAG,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,mBAAmB;YAC9D,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,yBAAyB,EAAE,EAAE,KAAK,EAAE,OAAO,EAAE,cAAc,EAAE,YAAY,CAAC,MAAM,EAAE,CAAC,CAAC;QACtI,CAAC;aAAM,CAAC;YACJ,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,oBAAoB,EAAE,EAAE,KAAK,EAAE,YAAY,EAAE,KAAK,EAAE,oCAAoC,EAAE,CAAC,CAAC;YACzI,OAAO,CAAC,KAAK,CAAC,6FAA6F,CAAC,CAAC;YAC7G,sEAAsE;QAC3E,CAAC;QAED,oEAAoE;QACpE,MAAM,wBAAwB,GAAG,EAAE,CAAC;QACpC,MAAM,WAAW,GAAG,YAAY,CAAC,KAAK,CAAC,CAAC,EAAE,wBAAwB,CAAC,CAAC;QACpE,IAAI,YAAY,CAAC,MAAM,GAAG,wBAAwB,EAAE,CAAC;YAChD,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,gBAAgB,EAAE,EAAE,OAAO,EAAE,mCAAmC,EAAE,KAAK,EAAE,YAAY,CAAC,MAAM,EAAE,eAAe,EAAE,wBAAwB,EAAE,CAAC,CAAC;QAC9L,CAAC;QAGD,kDAAkD;QAClD,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,yBAAyB,EAAE,EAAE,KAAK,EAAE,WAAW,EAAE,gBAAgB,EAAE,WAAW,CAAC,MAAM,EAAE,CAAC,CAAC;QACvI,MAAM,aAAa,GAAG,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CACxC,IAAA,wCAAsB,EAAC,GAAG,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAC,CAAC,EAAE,GAAG,EAAE,QAAQ,EAAE,CAAC,CAAC,CACpE,CAAC;QACF,MAAM,cAAc,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC;QAExD,MAAM,gBAAgB,GAAwB,EAAE,CAAC;QACjD,MAAM,uBAAuB,GAAG,IAAI,GAAG,EAAU,CAAC;QAClD,MAAM,aAAa,GAAa,EAAE,CAAC;QACnC,cAAc,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;YAC5B,IAAI,MAAM,CAAC,QAAQ,EAAE,CAAC;gBAClB,gBAAgB,CAAC,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,CAAC;gBACvC,uBAAuB,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;YAC5C,CAAC;iBAAM,CAAC;gBACJ,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;YACnC,CAAC;QACL,CAAC,CAAC,CAAC;QACH,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,yBAAyB,EAAE,EAAE,KAAK,EAAE,WAAW,EAAE,YAAY,EAAE,gBAAgB,CAAC,MAAM,EAAE,eAAe,EAAE,aAAa,CAAC,MAAM,EAAE,CAAC,CAAC;QAG/K,2CAA2C;QAC3C,IAAI,gBAAgB,CAAC,MAAM,KAAK,CAAC,IAAI,YAAY,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YAC1D,gEAAgE;YAChE,OAAO,CAAC,IAAI,CAAC,mFAAmF,cAAc,8BAA8B,YAAY,CAAC,MAAM,GAAG,CAAC,CAAC;YACpK,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,gBAAgB,EAAE,EAAE,OAAO,EAAE,oDAAoD,EAAE,UAAU,EAAE,CAAC,CAAC;YAC/I,kBAAkB,GAAG,YAAY,CAAC,CAAC,6BAA6B;YAChE,eAAe,GAAG,GAAG,CAAC,CAAC,sBAAsB;QAClD,CAAC;aAAM,IAAI,gBAAgB,CAAC,MAAM,KAAK,CAAC,IAAI,YAAY,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;YACnE,kCAAkC;YACjC,OAAO,CAAC,GAAG,CAAC,iFAAiF,cAAc,GAAG,CAAC,CAAC;YAChH,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,gBAAgB,EAAE,EAAE,IAAI,EAAE,sCAAsC,EAAE,CAAC,CAAC;YAClH,kBAAkB,GAAG,YAAY,CAAC;YAClC,eAAe,GAAG,GAAG,CAAC,CAAC,gDAAgD;QAC7E,CAAC;aACI,CAAC;YACF,6CAA6C;YAC7C,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,gBAAgB,EAAE,EAAE,IAAI,EAAE,wBAAwB,EAAE,aAAa,EAAE,gBAAgB,CAAC,MAAM,EAAE,CAAC,CAAC;YAC5I,IAAI,eAAe,GAAG,CAAC,CAAC;YACxB,IAAI,kBAAkB,GAAG,CAAC,CAAC;YAC3B,IAAI,gBAAgB,GAAG,CAAC,CAAC;YACzB,IAAI,gBAAgB,GAAG,CAAC,CAAC;YACzB,MAAM,oBAAoB,GAAa,EAAE,CAAC;YAE1C,KAAK,MAAM,QAAQ,IAAI,gBAAgB,EAAE,CAAC;gBACtC,MAAM,UAAU,GAAG,QAAQ,CAAC,WAAW,IAAI,OAAO,QAAQ,CAAC,oBAAoB,EAAE,SAAS,CAAC,CAAC,EAAE,CAAC,CAAC,IAAI,IAAA,oBAAY,EAAC,CAAC,GAAG,uBAAuB,CAAC,CAAC,oBAAoB,CAAC,MAAM,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC;gBACjL,oBAAoB,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;gBAEtC,IAAI,CAAC;oBACD,MAAM,YAAY,GAAG,QAAQ,CAAC,UAAU,EAAE,gBAAgB,IAAI,GAAG,CAAC;oBAElE,uBAAuB;oBACvB,IAAI,YAAY,GAAG,GAAG,EAAE,CAAC;wBACrB,gBAAgB,EAAE,CAAC;wBACnB,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,kBAAkB,EAAE,EAAE,KAAK,EAAE,qBAAqB,EAAE,UAAU,EAAE,KAAK,EAAE,YAAY,EAAE,CAAC,CAAC;oBACzI,CAAC;oBAED,8CAA8C;oBAC9C,IAAI,QAAQ,CAAC,IAAI,KAAK,mBAAmB,IAAI,QAAQ,CAAC,OAAO,EAAE,OAAO,IAAI,QAAQ,CAAC,OAAO,EAAE,MAAM,EAAE,CAAC;wBACjG,MAAM,OAAO,GAAG,QAAQ,CAAC,OAAO,CAAC,OAAO,CAAC,WAAW,EAAE,CAAC;wBACvD,MAAM,SAAS,GAAG,QAAQ,CAAC,OAAO,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC;wBACxD,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAAC,OAAO,CAAC,IAAI,aAAa,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,IAAI,WAAW,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE,CAAC;4BACrG,eAAe,IAAI,YAAY,CAAC;4BAChC,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,gBAAgB,EAAE,EAAE,KAAK,EAAE,WAAW,EAAE,UAAU,EAAE,OAAO,EAAE,SAAS,EAAE,KAAK,EAAE,YAAY,EAAE,CAAC,CAAC;wBACjJ,CAAC;oBACL,CAAC;oBAED,yCAAyC;oBACzC,IAAI,QAAQ,CAAC,UAAU,EAAE,iBAAiB,EAAE,CAAC;wBACzC,MAAM,WAAW,GAAG,IAAI,IAAI,CAAC,QAAQ,CAAC,UAAU,CAAC,iBAAiB,CAAC,CAAC;wBACpE,MAAM,OAAO,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,GAAG,WAAW,CAAC,OAAO,EAAE,CAAC,GAAG,CAAC,IAAI,GAAG,IAAI,GAAG,EAAE,CAAC,CAAC;wBAC1E,IAAI,OAAO,GAAG,GAAG,EAAE,CAAC;4BAChB,gBAAgB,EAAE,CAAC;4BACnB,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,kBAAkB,EAAE,EAAE,KAAK,EAAE,KAAK,EAAE,UAAU,EAAE,OAAO,EAAE,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,EAAE,OAAO,EAAE,mBAAmB,EAAE,CAAC,CAAC;wBAChK,CAAC;oBACL,CAAC;oBAED,oDAAoD;oBACnD,MAAM,YAAY,GAAG,QAAQ,CAAC,UAAU,EAAE,qBAAqB,CAAC;oBAC/D,IAAI,YAAY,IAAI,YAAY,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;wBAC1C,eAAe,IAAI,GAAG,GAAG,YAAY,CAAC,MAAM,CAAC,CAAC,cAAc;wBAC5D,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,kBAAkB,EAAE,EAAE,KAAK,EAAE,mBAAmB,EAAE,UAAU,EAAE,KAAK,EAAE,YAAY,CAAC,MAAM,EAAE,OAAO,EAAE,8BAA8B,EAAE,CAAC,CAAC;oBACvL,CAAC;gBAEP,CAAC;gBAAC,OAAO,UAAe,EAAE,CAAC;oBACtB,OAAO,CAAC,KAAK,CAAC,gDAAgD,UAAU,gBAAgB,cAAc,KAAK,UAAU,CAAC,OAAO,EAAE,CAAC,CAAC;oBACjI,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,oBAAoB,EAAE,EAAE,KAAK,EAAE,gBAAgB,EAAE,UAAU,EAAE,KAAK,EAAE,UAAU,CAAC,OAAO,EAAE,CAAC,CAAC;gBAC7I,CAAC;YACL,CAAC,CAAC,oBAAoB;YAEtB,gBAAgB,GAAG,oBAAoB,CAAC,CAAC,+BAA+B;YAExE,gCAAgC;YAChC,eAAe,GAAG,GAAG,GAAG,CAAC,eAAe,GAAG,kBAAkB,CAAC,GAAG,GAAG,GAAG,CAAC,gBAAgB,GAAG,IAAI,CAAC,GAAG,CAAC,gBAAgB,GAAG,GAAG,CAAC,CAAC;YAC5H,eAAe,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,eAAe,CAAC,CAAC,CAAC,CAAC,QAAQ;YAE3E,IAAI,gBAAgB,GAAG,CAAC;gBAAE,kBAAkB,GAAG,oBAAoB,CAAC;iBAC/D,IAAI,kBAAkB,GAAG,eAAe,GAAG,GAAG;gBAAE,kBAAkB,GAAG,wBAAwB,CAAC;iBAC9F,IAAI,eAAe,GAAG,GAAG,IAAI,eAAe,GAAG,IAAI;gBAAE,kBAAkB,GAAG,UAAU,CAAC;;gBACrF,kBAAkB,GAAG,YAAY,CAAC;YAEvC,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,gBAAgB,EAAE;gBAC5D,IAAI,EAAE,eAAe;gBACrB,iBAAiB,EAAE,kBAAkB;gBACrC,oBAAoB,EAAE,eAAe;gBACrC,eAAe,EAAE,eAAe,CAAC,OAAO,CAAC,CAAC,CAAC;gBAC3C,kBAAkB,EAAE,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC;gBACjD,gBAAgB,EAAE,gBAAgB;aACrC,CAAC,CAAC;QACP,CAAC,CAAC,gDAAgD;QAGlD,kCAAkC;QAClC,mEAAmE;QACnE,IAAI,gBAAM,CAAC,sBAAsB,IAAI,gBAAM,CAAC,2BAA2B,EAAE,CAAC;YACtE,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,yBAAyB,EAAE,EAAE,eAAe,EAAE,kBAAkB,EAAE,CAAC,CAAC;YAClH,IAAI,CAAC,kBAAkB,CAAC,UAAU,CAAC,QAAQ,CAAC,EAAE,CAAC,CAAC,yCAAyC;gBACrF,eAAe,GAAG,MAAM,IAAA,yCAAuB,EAAC,kBAAkB,EAAE,CAAC,EAAE,cAAc,CAAC,CAAC;gBACvF,IAAI,eAAe,EAAE,CAAC;oBAClB,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,yBAAyB,EAAE;wBACrE,SAAS,EAAE,eAAe,CAAC,SAAS;wBACpC,MAAM,EAAE,eAAe,CAAC,MAAM;wBAC9B,cAAc,EAAE,eAAe,CAAC,cAAc;wBAC9C,gBAAgB,EAAE,kBAAkB;qBACvC,CAAC,CAAC;gBACP,CAAC;qBAAM,CAAC;oBACJ,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,yBAAyB,EAAE,EAAE,KAAK,EAAE,iDAAiD,EAAE,CAAC,CAAC;oBACvI,kBAAkB,GAAG,wBAAwB,CAAC,CAAC,gBAAgB;oBAC/D,eAAe,GAAG,CAAC,CAAC,CAAC,mBAAmB;gBAC5C,CAAC;YACL,CAAC;iBAAM,CAAC;gBACJ,OAAO,CAAC,IAAI,CAAC,0EAA0E,kBAAkB,EAAE,CAAC,CAAC;gBAC7G,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,yBAAyB,EAAE,EAAE,MAAM,EAAE,4BAA4B,EAAE,WAAW,EAAE,kBAAkB,EAAE,CAAC,CAAC;YACxJ,CAAC;QACL,CAAC;aAAM,CAAC;YACJ,OAAO,CAAC,IAAI,CAAC,yHAAyH,CAAC,CAAC;YACxI,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,yBAAyB,EAAE,EAAE,MAAM,EAAE,gDAAgD,EAAE,CAAC,CAAC;QAC3I,CAAC;QAGD,sCAAsC;QACtC,MAAM,WAAW,GAA+B;YAC5C,YAAY,EAAE,kBAAkB;YAChC,eAAe,EAAE,UAAU,CAAC,eAAe,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,EAAE,oBAAoB;YAC7E,gBAAgB,EAAE,gBAAgB;YAClC,cAAc,EAAE,cAAc,EAAE,wCAAwC;YACxE,iBAAiB,EAAE,eAAe,EAAE,SAAS;YAC7C,oBAAoB,EAAE,eAAe,EAAE,MAAM;YAC7C,cAAc,EAAE,eAAe,EAAE,cAAc;SAClD,CAAC;QAEF,OAAO,CAAC,GAAG,CAAC,wDAAwD,cAAc,cAAc,WAAW,CAAC,YAAY,iBAAiB,WAAW,CAAC,eAAe,EAAE,CAAC,CAAC;QACxK,OAAO,WAAW,CAAC;IAEvB,CAAC;IAAC,OAAO,KAAU,EAAE,CAAC;QAClB,OAAO,CAAC,KAAK,CAAC,oCAAoC,cAAc,IAAI,EAAE,KAAK,CAAC,OAAO,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC;QAClG,MAAM,OAAO,CAAC,cAAc,EAAE,cAAc,EAAE,oBAAoB,EAAE,EAAE,KAAK,EAAE,KAAK,CAAC,OAAO,EAAE,KAAK,EAAE,eAAe,EAAE,CAAC,CAAC;QACtH,yCAAyC;QACxC,OAAO;YACH,YAAY,EAAE,4BAA4B;YAC1C,eAAe,EAAE,CAAC;YAClB,gBAAgB,EAAE,gBAAgB;YAClC,cAAc,EAAE,cAAc;YAC9B,iBAAiB,EAAE,eAAe,EAAE,SAAS;YAC7C,oBAAoB,EAAE,eAAe,EAAE,MAAM;YAC7C,cAAc,EAAE,eAAe,EAAE,cAAc;SAClD,CAAC;IACP,CAAC;AACL,CAAC"}===== ./dist/types/index.js =====
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
//# sourceMappingURL=index.js.map===== ./dist/types/index.js.map =====
{"version":3,"file":"index.js","sourceRoot":"","sources":["../../src/types/index.ts"],"names":[],"mappings":""}===== ./dist/utils/index.js =====
"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.getL2ExplorerUrl = getL2ExplorerUrl;
exports.truncateText = truncateText;
const config_1 = __importDefault(require("../config"));
// Example utility: Build L2 Explorer URL based on configured RPC URL heuristics
function getL2ExplorerUrl(txHash) {
    const rpcUrl = config_1.default.l2RpcUrl?.toLowerCase() || '';
    if (!rpcUrl || !txHash)
        return undefined;
    // Add more mappings as needed for supported testnets/mainnets
    if (rpcUrl.includes('base-sepolia') || rpcUrl.includes('84532')) {
        return `https://sepolia.basescan.org/tx/${txHash}`;
    }
    if (rpcUrl.includes('optimism-sepolia') || rpcUrl.includes('11155420')) {
        return `https://sepolia-optimism.etherscan.io/tx/${txHash}`;
    }
    if (rpcUrl.includes('arbitrum-sepolia') || rpcUrl.includes('421614')) {
        return `https://sepolia.arbiscan.io/tx/${txHash}`;
    }
    // Add Polygon Amoy, etc.
    if (rpcUrl.includes('polygon-amoy') || rpcUrl.includes('80002')) {
        return `https://www.oklink.com/amoy/tx/${txHash}`;
    }
    console.warn(`[Utils] No block explorer URL configured for RPC: ${rpcUrl}`);
    return undefined; // Return undefined if no match
}
// Add other shared utility functions here, e.g., text truncation, basic NLP helpers
function truncateText(text, maxLength) {
    if (!text)
        return '';
    if (text.length <= maxLength)
        return text;
    return text.substring(0, maxLength - 3) + '...';
}
//# sourceMappingURL=index.js.map===== ./dist/utils/index.js.map =====
{"version":3,"file":"index.js","sourceRoot":"","sources":["../../src/utils/index.ts"],"names":[],"mappings":";;;;;AAGA,4CAqBC;AAGD,oCAIC;AA/BD,uDAA+B;AAE/B,gFAAgF;AAChF,SAAgB,gBAAgB,CAAC,MAAc;IAC3C,MAAM,MAAM,GAAG,gBAAM,CAAC,QAAQ,EAAE,WAAW,EAAE,IAAI,EAAE,CAAC;IACpD,IAAI,CAAC,MAAM,IAAI,CAAC,MAAM;QAAE,OAAO,SAAS,CAAC;IAEzC,8DAA8D;IAC9D,IAAI,MAAM,CAAC,QAAQ,CAAC,cAAc,CAAC,IAAI,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,EAAE,CAAC;QAC9D,OAAO,mCAAmC,MAAM,EAAE,CAAC;IACvD,CAAC;IACD,IAAI,MAAM,CAAC,QAAQ,CAAC,kBAAkB,CAAC,IAAI,MAAM,CAAC,QAAQ,CAAC,UAAU,CAAC,EAAE,CAAC;QACrE,OAAO,4CAA4C,MAAM,EAAE,CAAC;IAChE,CAAC;IACA,IAAI,MAAM,CAAC,QAAQ,CAAC,kBAAkB,CAAC,IAAI,MAAM,CAAC,QAAQ,CAAC,QAAQ,CAAC,EAAE,CAAC;QACnE,OAAO,kCAAkC,MAAM,EAAE,CAAC;IACtD,CAAC;IACF,yBAAyB;IACzB,IAAI,MAAM,CAAC,QAAQ,CAAC,cAAc,CAAC,IAAI,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,EAAE,CAAC;QAC9D,OAAO,kCAAkC,MAAM,EAAE,CAAC;IACtD,CAAC;IAED,OAAO,CAAC,IAAI,CAAC,qDAAqD,MAAM,EAAE,CAAC,CAAC;IAC5E,OAAO,SAAS,CAAC,CAAC,+BAA+B;AACrD,CAAC;AAED,oFAAoF;AACpF,SAAgB,YAAY,CAAC,IAA+B,EAAE,SAAiB;IAC3E,IAAI,CAAC,IAAI;QAAE,OAAO,EAAE,CAAC;IACrB,IAAI,IAAI,CAAC,MAAM,IAAI,SAAS;QAAE,OAAO,IAAI,CAAC;IAC1C,OAAO,IAAI,CAAC,SAAS,CAAC,CAAC,EAAE,SAAS,GAAG,CAAC,CAAC,GAAG,KAAK,CAAC;AACpD,CAAC"}===== ./node_modules/.bin/acorn =====
#!/bin/sh
basedir=$(dirname "$(echo "$0" | sed -e 's,\\,/,g')")

case `uname` in
    *CYGWIN*) basedir=`cygpath -w "$basedir"`;;
esac

if [ -z "$NODE_PATH" ]; then
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/acorn@8.14.1/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
else
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/acorn@8.14.1/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules:$NODE_PATH"
fi
if [ -x "$basedir/node" ]; then
  exec "$basedir/node"  "$basedir/../../../../node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/bin/acorn" "$@"
else
  exec node  "$basedir/../../../../node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/bin/acorn" "$@"
fi
===== ./node_modules/.bin/acorn.CMD =====
@SETLOCAL
@IF NOT DEFINED NODE_PATH (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\acorn@8.14.1\node_modules\acorn\bin\node_modules;C:\development\kintask\node_modules\.pnpm\acorn@8.14.1\node_modules\acorn\node_modules;C:\development\kintask\node_modules\.pnpm\acorn@8.14.1\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
) ELSE (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\acorn@8.14.1\node_modules\acorn\bin\node_modules;C:\development\kintask\node_modules\.pnpm\acorn@8.14.1\node_modules\acorn\node_modules;C:\development\kintask\node_modules\.pnpm\acorn@8.14.1\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules;%NODE_PATH%"
)
@IF EXIST "%~dp0\node.exe" (
  "%~dp0\node.exe"  "%~dp0\..\..\..\..\node_modules\.pnpm\acorn@8.14.1\node_modules\acorn\bin\acorn" %*
) ELSE (
  @SET PATHEXT=%PATHEXT:;.JS;=;%
  node  "%~dp0\..\..\..\..\node_modules\.pnpm\acorn@8.14.1\node_modules\acorn\bin\acorn" %*
)
===== ./node_modules/.bin/acorn.ps1 =====
#!/usr/bin/env pwsh
$basedir=Split-Path $MyInvocation.MyCommand.Definition -Parent

$exe=""
$pathsep=":"
$env_node_path=$env:NODE_PATH
$new_node_path="C:\development\kintask\node_modules\.pnpm\acorn@8.14.1\node_modules\acorn\bin\node_modules;C:\development\kintask\node_modules\.pnpm\acorn@8.14.1\node_modules\acorn\node_modules;C:\development\kintask\node_modules\.pnpm\acorn@8.14.1\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWindows) {
  # Fix case when both the Windows and Linux builds of Node
  # are installed in the same directory
  $exe=".exe"
  $pathsep=";"
} else {
  $new_node_path="/mnt/c/development/kintask/node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/acorn@8.14.1/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
}
if ([string]::IsNullOrEmpty($env_node_path)) {
  $env:NODE_PATH=$new_node_path
} else {
  $env:NODE_PATH="$new_node_path$pathsep$env_node_path"
}

$ret=0
if (Test-Path "$basedir/node$exe") {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "$basedir/node$exe"  "$basedir/../../../../node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/bin/acorn" $args
  } else {
    & "$basedir/node$exe"  "$basedir/../../../../node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/bin/acorn" $args
  }
  $ret=$LASTEXITCODE
} else {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "node$exe"  "$basedir/../../../../node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/bin/acorn" $args
  } else {
    & "node$exe"  "$basedir/../../../../node_modules/.pnpm/acorn@8.14.1/node_modules/acorn/bin/acorn" $args
  }
  $ret=$LASTEXITCODE
}
$env:NODE_PATH=$env_node_path
exit $ret
===== ./node_modules/.bin/eslint =====
#!/bin/sh
basedir=$(dirname "$(echo "$0" | sed -e 's,\\,/,g')")

case `uname` in
    *CYGWIN*) basedir=`cygpath -w "$basedir"`;;
esac

if [ -z "$NODE_PATH" ]; then
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/eslint@8.57.1/node_modules/eslint/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/eslint@8.57.1/node_modules/eslint/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/eslint@8.57.1/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
else
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/eslint@8.57.1/node_modules/eslint/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/eslint@8.57.1/node_modules/eslint/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/eslint@8.57.1/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules:$NODE_PATH"
fi
if [ -x "$basedir/node" ]; then
  exec "$basedir/node"  "$basedir/../eslint/bin/eslint.js" "$@"
else
  exec node  "$basedir/../eslint/bin/eslint.js" "$@"
fi
===== ./node_modules/.bin/eslint.CMD =====
@SETLOCAL
@IF NOT DEFINED NODE_PATH (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\eslint@8.57.1\node_modules\eslint\bin\node_modules;C:\development\kintask\node_modules\.pnpm\eslint@8.57.1\node_modules\eslint\node_modules;C:\development\kintask\node_modules\.pnpm\eslint@8.57.1\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
) ELSE (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\eslint@8.57.1\node_modules\eslint\bin\node_modules;C:\development\kintask\node_modules\.pnpm\eslint@8.57.1\node_modules\eslint\node_modules;C:\development\kintask\node_modules\.pnpm\eslint@8.57.1\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules;%NODE_PATH%"
)
@IF EXIST "%~dp0\node.exe" (
  "%~dp0\node.exe"  "%~dp0\..\eslint\bin\eslint.js" %*
) ELSE (
  @SET PATHEXT=%PATHEXT:;.JS;=;%
  node  "%~dp0\..\eslint\bin\eslint.js" %*
)
===== ./node_modules/.bin/eslint.ps1 =====
#!/usr/bin/env pwsh
$basedir=Split-Path $MyInvocation.MyCommand.Definition -Parent

$exe=""
$pathsep=":"
$env_node_path=$env:NODE_PATH
$new_node_path="C:\development\kintask\node_modules\.pnpm\eslint@8.57.1\node_modules\eslint\bin\node_modules;C:\development\kintask\node_modules\.pnpm\eslint@8.57.1\node_modules\eslint\node_modules;C:\development\kintask\node_modules\.pnpm\eslint@8.57.1\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWindows) {
  # Fix case when both the Windows and Linux builds of Node
  # are installed in the same directory
  $exe=".exe"
  $pathsep=";"
} else {
  $new_node_path="/mnt/c/development/kintask/node_modules/.pnpm/eslint@8.57.1/node_modules/eslint/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/eslint@8.57.1/node_modules/eslint/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/eslint@8.57.1/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
}
if ([string]::IsNullOrEmpty($env_node_path)) {
  $env:NODE_PATH=$new_node_path
} else {
  $env:NODE_PATH="$new_node_path$pathsep$env_node_path"
}

$ret=0
if (Test-Path "$basedir/node$exe") {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "$basedir/node$exe"  "$basedir/../eslint/bin/eslint.js" $args
  } else {
    & "$basedir/node$exe"  "$basedir/../eslint/bin/eslint.js" $args
  }
  $ret=$LASTEXITCODE
} else {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "node$exe"  "$basedir/../eslint/bin/eslint.js" $args
  } else {
    & "node$exe"  "$basedir/../eslint/bin/eslint.js" $args
  }
  $ret=$LASTEXITCODE
}
$env:NODE_PATH=$env_node_path
exit $ret
===== ./node_modules/.bin/ts-node-dev =====
#!/bin/sh
basedir=$(dirname "$(echo "$0" | sed -e 's,\\,/,g')")

case `uname` in
    *CYGWIN*) basedir=`cygpath -w "$basedir"`;;
esac

if [ -z "$NODE_PATH" ]; then
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/lib/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
else
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/lib/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules:$NODE_PATH"
fi
if [ -x "$basedir/node" ]; then
  exec "$basedir/node"  "$basedir/../ts-node-dev/lib/bin.js" "$@"
else
  exec node  "$basedir/../ts-node-dev/lib/bin.js" "$@"
fi
===== ./node_modules/.bin/ts-node-dev.CMD =====
@SETLOCAL
@IF NOT DEFINED NODE_PATH (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\lib\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
) ELSE (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\lib\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules;%NODE_PATH%"
)
@IF EXIST "%~dp0\node.exe" (
  "%~dp0\node.exe"  "%~dp0\..\ts-node-dev\lib\bin.js" %*
) ELSE (
  @SET PATHEXT=%PATHEXT:;.JS;=;%
  node  "%~dp0\..\ts-node-dev\lib\bin.js" %*
)
===== ./node_modules/.bin/ts-node-dev.ps1 =====
#!/usr/bin/env pwsh
$basedir=Split-Path $MyInvocation.MyCommand.Definition -Parent

$exe=""
$pathsep=":"
$env_node_path=$env:NODE_PATH
$new_node_path="C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\lib\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWindows) {
  # Fix case when both the Windows and Linux builds of Node
  # are installed in the same directory
  $exe=".exe"
  $pathsep=";"
} else {
  $new_node_path="/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/lib/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
}
if ([string]::IsNullOrEmpty($env_node_path)) {
  $env:NODE_PATH=$new_node_path
} else {
  $env:NODE_PATH="$new_node_path$pathsep$env_node_path"
}

$ret=0
if (Test-Path "$basedir/node$exe") {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "$basedir/node$exe"  "$basedir/../ts-node-dev/lib/bin.js" $args
  } else {
    & "$basedir/node$exe"  "$basedir/../ts-node-dev/lib/bin.js" $args
  }
  $ret=$LASTEXITCODE
} else {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "node$exe"  "$basedir/../ts-node-dev/lib/bin.js" $args
  } else {
    & "node$exe"  "$basedir/../ts-node-dev/lib/bin.js" $args
  }
  $ret=$LASTEXITCODE
}
$env:NODE_PATH=$env_node_path
exit $ret
===== ./node_modules/.bin/tsc =====
#!/bin/sh
basedir=$(dirname "$(echo "$0" | sed -e 's,\\,/,g')")

case `uname` in
    *CYGWIN*) basedir=`cygpath -w "$basedir"`;;
esac

if [ -z "$NODE_PATH" ]; then
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
else
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules:$NODE_PATH"
fi
if [ -x "$basedir/node" ]; then
  exec "$basedir/node"  "$basedir/../typescript/bin/tsc" "$@"
else
  exec node  "$basedir/../typescript/bin/tsc" "$@"
fi
===== ./node_modules/.bin/tsc.CMD =====
@SETLOCAL
@IF NOT DEFINED NODE_PATH (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\bin\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
) ELSE (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\bin\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules;%NODE_PATH%"
)
@IF EXIST "%~dp0\node.exe" (
  "%~dp0\node.exe"  "%~dp0\..\typescript\bin\tsc" %*
) ELSE (
  @SET PATHEXT=%PATHEXT:;.JS;=;%
  node  "%~dp0\..\typescript\bin\tsc" %*
)
===== ./node_modules/.bin/tsc.ps1 =====
#!/usr/bin/env pwsh
$basedir=Split-Path $MyInvocation.MyCommand.Definition -Parent

$exe=""
$pathsep=":"
$env_node_path=$env:NODE_PATH
$new_node_path="C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\bin\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWindows) {
  # Fix case when both the Windows and Linux builds of Node
  # are installed in the same directory
  $exe=".exe"
  $pathsep=";"
} else {
  $new_node_path="/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
}
if ([string]::IsNullOrEmpty($env_node_path)) {
  $env:NODE_PATH=$new_node_path
} else {
  $env:NODE_PATH="$new_node_path$pathsep$env_node_path"
}

$ret=0
if (Test-Path "$basedir/node$exe") {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "$basedir/node$exe"  "$basedir/../typescript/bin/tsc" $args
  } else {
    & "$basedir/node$exe"  "$basedir/../typescript/bin/tsc" $args
  }
  $ret=$LASTEXITCODE
} else {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "node$exe"  "$basedir/../typescript/bin/tsc" $args
  } else {
    & "node$exe"  "$basedir/../typescript/bin/tsc" $args
  }
  $ret=$LASTEXITCODE
}
$env:NODE_PATH=$env_node_path
exit $ret
===== ./node_modules/.bin/tsnd =====
#!/bin/sh
basedir=$(dirname "$(echo "$0" | sed -e 's,\\,/,g')")

case `uname` in
    *CYGWIN*) basedir=`cygpath -w "$basedir"`;;
esac

if [ -z "$NODE_PATH" ]; then
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/lib/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
else
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/lib/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules:$NODE_PATH"
fi
if [ -x "$basedir/node" ]; then
  exec "$basedir/node"  "$basedir/../ts-node-dev/lib/bin.js" "$@"
else
  exec node  "$basedir/../ts-node-dev/lib/bin.js" "$@"
fi
===== ./node_modules/.bin/tsnd.CMD =====
@SETLOCAL
@IF NOT DEFINED NODE_PATH (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\lib\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
) ELSE (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\lib\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules;%NODE_PATH%"
)
@IF EXIST "%~dp0\node.exe" (
  "%~dp0\node.exe"  "%~dp0\..\ts-node-dev\lib\bin.js" %*
) ELSE (
  @SET PATHEXT=%PATHEXT:;.JS;=;%
  node  "%~dp0\..\ts-node-dev\lib\bin.js" %*
)
===== ./node_modules/.bin/tsnd.ps1 =====
#!/usr/bin/env pwsh
$basedir=Split-Path $MyInvocation.MyCommand.Definition -Parent

$exe=""
$pathsep=":"
$env_node_path=$env:NODE_PATH
$new_node_path="C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\lib\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules\ts-node-dev\node_modules;C:\development\kintask\node_modules\.pnpm\ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWindows) {
  # Fix case when both the Windows and Linux builds of Node
  # are installed in the same directory
  $exe=".exe"
  $pathsep=";"
} else {
  $new_node_path="/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/lib/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules/ts-node-dev/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/ts-node-dev@2.0.0_@types+node@20.17.30_typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
}
if ([string]::IsNullOrEmpty($env_node_path)) {
  $env:NODE_PATH=$new_node_path
} else {
  $env:NODE_PATH="$new_node_path$pathsep$env_node_path"
}

$ret=0
if (Test-Path "$basedir/node$exe") {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "$basedir/node$exe"  "$basedir/../ts-node-dev/lib/bin.js" $args
  } else {
    & "$basedir/node$exe"  "$basedir/../ts-node-dev/lib/bin.js" $args
  }
  $ret=$LASTEXITCODE
} else {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "node$exe"  "$basedir/../ts-node-dev/lib/bin.js" $args
  } else {
    & "node$exe"  "$basedir/../ts-node-dev/lib/bin.js" $args
  }
  $ret=$LASTEXITCODE
}
$env:NODE_PATH=$env_node_path
exit $ret
===== ./node_modules/.bin/tsserver =====
#!/bin/sh
basedir=$(dirname "$(echo "$0" | sed -e 's,\\,/,g')")

case `uname` in
    *CYGWIN*) basedir=`cygpath -w "$basedir"`;;
esac

if [ -z "$NODE_PATH" ]; then
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
else
  export NODE_PATH="/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules:$NODE_PATH"
fi
if [ -x "$basedir/node" ]; then
  exec "$basedir/node"  "$basedir/../typescript/bin/tsserver" "$@"
else
  exec node  "$basedir/../typescript/bin/tsserver" "$@"
fi
===== ./node_modules/.bin/tsserver.CMD =====
@SETLOCAL
@IF NOT DEFINED NODE_PATH (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\bin\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
) ELSE (
  @SET "NODE_PATH=C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\bin\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules;%NODE_PATH%"
)
@IF EXIST "%~dp0\node.exe" (
  "%~dp0\node.exe"  "%~dp0\..\typescript\bin\tsserver" %*
) ELSE (
  @SET PATHEXT=%PATHEXT:;.JS;=;%
  node  "%~dp0\..\typescript\bin\tsserver" %*
)
===== ./node_modules/.bin/tsserver.ps1 =====
#!/usr/bin/env pwsh
$basedir=Split-Path $MyInvocation.MyCommand.Definition -Parent

$exe=""
$pathsep=":"
$env_node_path=$env:NODE_PATH
$new_node_path="C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\bin\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules\typescript\node_modules;C:\development\kintask\node_modules\.pnpm\typescript@5.8.2\node_modules;C:\development\kintask\node_modules\.pnpm\node_modules"
if ($PSVersionTable.PSVersion -lt "6.0" -or $IsWindows) {
  # Fix case when both the Windows and Linux builds of Node
  # are installed in the same directory
  $exe=".exe"
  $pathsep=";"
} else {
  $new_node_path="/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/bin/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules/typescript/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/typescript@5.8.2/node_modules:/mnt/c/development/kintask/node_modules/.pnpm/node_modules"
}
if ([string]::IsNullOrEmpty($env_node_path)) {
  $env:NODE_PATH=$new_node_path
} else {
  $env:NODE_PATH="$new_node_path$pathsep$env_node_path"
}

$ret=0
if (Test-Path "$basedir/node$exe") {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "$basedir/node$exe"  "$basedir/../typescript/bin/tsserver" $args
  } else {
    & "$basedir/node$exe"  "$basedir/../typescript/bin/tsserver" $args
  }
  $ret=$LASTEXITCODE
} else {
  # Support pipeline input
  if ($MyInvocation.ExpectingInput) {
    $input | & "node$exe"  "$basedir/../typescript/bin/tsserver" $args
  } else {
    & "node$exe"  "$basedir/../typescript/bin/tsserver" $args
  }
  $ret=$LASTEXITCODE
}
$env:NODE_PATH=$env_node_path
exit $ret
===== ./package.json =====
{
  "name": "backend",
  "version": "1.0.0",
  "private": true,
  "main": "dist/server.js",
  "scripts": {
    "dev": "ts-node-dev --respawn --transpile-only --clear src/server.ts",
    "build": "tsc",
    "start": "node dist/server.js",
    "lint": "eslint src/**/*.ts"
  },
  "dependencies": {
    "@recallnet/chains": "latest",
    "@recallnet/sdk": "latest",
    "@web3-storage/w3up-client": "^17.2.0",
    "axios": "^1.6.8",
    "blocklock-js": "latest",
    "cors": "^2.8.5",
    "dotenv": "^16.4.5",
    "ethers": "^6.11.1",
    "express": "^4.18.3",
    "files-from-path": "^1.1.4",
    "viem": "latest"
  },
  "devDependencies": {
    "@types/cors": "^2.8.17",
    "@types/express": "^4.17.21",
    "@types/node": "^20.11.28",
    "@typescript-eslint/eslint-plugin": "^7.3.1",
    "@typescript-eslint/parser": "^7.3.1",
    "eslint": "^8.57.0",
    "ts-node-dev": "^2.0.0",
    "typescript": "^5.3.3"
  }
}
===== ./repo_contents.txt =====
===== ./src/config.ts =====
// config.ts
import dotenv from 'dotenv';
import path from 'path';

// Load .env file specifically from the backend package root
dotenv.config({ path: path.resolve(__dirname, '../.env') });

const config = {
  port: process.env.PORT || 3001,
  // OpenRouter Config
  openRouterApiKey: process.env.OPENROUTER_API_KEY,
  // W3UP/Storacha Config (Keep for potential use even if not in current files)
  w3upAgentEmail: process.env.W3UP_AGENT_EMAIL,
  kintaskSpaceDid: process.env.KINTASK_SPACE_DID,
  // KG Index CID
  knowledgeBaseIndexCid: process.env.KB_INDEX_CID,
  // IPFS Gateway for Retrieval (Optional Override)
  ipfsGatewayUrl: process.env.IPFS_GATEWAY_URL || 'https://w3s.link/ipfs/', // Default to w3s.link
  // Recall Config (Updated based on recallService.ts usage)
  recallPrivateKey: process.env.RECALL_PRIVATE_KEY, // Private key for Recall wallet
  recallLogBucket: process.env.RECALL_LOG_BUCKET, // Optional: Pre-configured bucket address
  // L2 & Wallet Config (Used by timelockService and contracts)
  l2RpcUrl: process.env.L2_RPC_URL,
  walletPrivateKey: process.env.WALLET_PRIVATE_KEY, // Main wallet for contract interaction
  kintaskContractAddress: process.env.KINTASK_CONTRACT_ADDRESS,
  blocklockSenderProxyAddress: process.env.BLOCKLOCK_SENDER_PROXY_ADDRESS,
};

// Runtime validation for critical variables
// Recall variables are now critical for its functionality
const requiredEnvVars: Array<keyof typeof config> = [
    'openRouterApiKey',
    // 'w3upAgentEmail', // Keeping these optional for now if not directly used by core verification flow
    // 'kintaskSpaceDid',
    'l2RpcUrl',
    'walletPrivateKey', // Main wallet for timelock
    'kintaskContractAddress',
    'blocklockSenderProxyAddress',
    'recallPrivateKey', // Required for Recall logging
];

let missingVars = false;
requiredEnvVars.forEach((varName) => {
  // Allow KB_INDEX_CID to be missing initially
  if (varName === 'knowledgeBaseIndexCid' && !config[varName]) {
      console.warn(`Warning: ${varName} is not set. Run the KG upload script ('pnpm kg:upload') first.`);
      return; // Don't mark as fatal error yet
  }
  if (!config[varName]) {
    // Special handling for optional recallLogBucket
    if (varName === 'recallLogBucket') {
        console.log(`Info: Optional environment variable ${varName} is not set. Recall service will attempt to find/create the bucket.`);
    } else {
        console.error(`FATAL ERROR: Environment variable ${varName} is not set in packages/backend/.env`);
        missingVars = true;
    }
  }
});

// Check KB_INDEX_CID specifically as it's needed by filecoinService
if (!config.knowledgeBaseIndexCid) {
    console.warn(`Warning: knowledgeBaseIndexCid (KB_INDEX_CID) is not set. Filecoin service (verifier) cannot function correctly.`);
    // Decide if this should be fatal or just a warning depending on requirements
    // missingVars = true; // Uncomment to make it fatal
}

// Validate Space DID format (basic check) - Keep validation if needed elsewhere
if (config.kintaskSpaceDid && !config.kintaskSpaceDid.startsWith('did:key:')) {
    console.error(`FATAL ERROR: KINTASK_SPACE_DID (${config.kintaskSpaceDid}) in packages/backend/.env does not look like a valid did:key identifier.`);
    missingVars = true; // Treat as fatal
}


if (missingVars) {
    console.error("\nPlease configure the required variables in packages/backend/.env and restart.");
    process.exit(1); // Exit if critical config is missing
}

export default config;===== ./src/contracts/abi/KintaskCommitment.json =====
// ACTION REQUIRED:
// AFTER RUNNING `pnpm contracts:compile` in the root directory,
// COPY THE CONTENT OF THE FILE:
// `packages/contracts/artifacts/contracts/KintaskCommitment.sol/KintaskCommitment.json`
// AND PASTE IT HERE, REPLACING THIS COMMENT BLOCK AND THE EMPTY {}
{}
===== ./src/contracts/addresses.ts =====
import config from '../config';

export const KINTASK_COMMITMENT_CONTRACT_ADDRESS = config.kintaskContractAddress || '';

// Add other contract addresses if needed

if (!KINTASK_COMMITMENT_CONTRACT_ADDRESS && process.env.NODE_ENV !== 'test') { // Don't warn during tests maybe
    console.warn("Backend Config Warning: KintaskCommitment Contract address (KINTASK_CONTRACT_ADDRESS) is not set in .env!");
}
===== ./src/controllers/verifyController.ts =====
import { Request, Response, NextFunction } from 'express';
import { generateAnswer } from '../services/generatorService';
import { performVerification } from '../services/verifierService';
import { logRecallEvent, getTraceFromRecall } from '../services/recallService';
import { VerificationResultInternal, ApiVerifyResponse } from '../types';
import { getL2ExplorerUrl } from '../utils';
import config from '../config'; // Import config if needed for L2 Chain ID for explorer

export async function handleVerifyRequest(req: Request, res: Response, next: NextFunction): Promise<void> {
  const { question } = req.body;
  const requestTimestamp = new Date().toISOString();
  // Create a unique context ID for this specific request to correlate Recall logs
  const uniqueRequestContext = `req_${Date.now()}_${Math.random().toString(16).substring(2, 8)}`;

  // --- Input Validation ---
  if (!question || typeof question !== 'string' || question.trim() === '') {
    res.status(400).json({ error: 'Invalid request body. Non-empty "question" string is required.' });
    return;
  }
  if (question.length > 1500) { // Limit question length
       res.status(400).json({ error: 'Question exceeds maximum length (1500 characters).' });
       return;
  }

  let verificationResult: VerificationResultInternal | null = null;
  let finalAnswer = "Processing..."; // Initial state

  console.log(`[Controller] Handling request ${uniqueRequestContext} for question: "${question.substring(0, 50)}..."`);
  try {
    // --- Log Start ---
    // Use await to ensure start is logged before proceeding, good for tracing flows
    await logRecallEvent('VERIFICATION_START', { question: question.substring(0, 200) + (question.length > 200 ? '...' : '') }, uniqueRequestContext);

    // --- 1. Generate Answer (Mocked) ---
    finalAnswer = await generateAnswer(question);
    // Check if mock returned an error string
    if (finalAnswer.startsWith('Error:')) {
         await logRecallEvent('VERIFICATION_ERROR', { step: 'GeneratorMock', error: finalAnswer }, uniqueRequestContext);
         throw new Error(`Mock Generator failed: ${finalAnswer}`);
    }
    await logRecallEvent('GENERATOR_MOCK_USED', { question: question.substring(0, 50) + '...', generatedAnswer: finalAnswer.substring(0, 50) + '...' }, uniqueRequestContext);


    // --- 2. Perform Verification ---
    verificationResult = await performVerification(question, finalAnswer, uniqueRequestContext);

    // Handle critical failure within the verification service itself
    if (!verificationResult) {
        await logRecallEvent('VERIFICATION_ERROR', { step: 'Verifier', error: "Verifier service returned null" }, uniqueRequestContext);
        throw new Error("Verification service failed to produce a result.");
    }
    // Handle error status returned by the verifier (e.g., Timelock Failed)
    if (verificationResult.finalVerdict.startsWith('Error:')) {
         console.warn(`[Controller] Verification completed with error status: ${verificationResult.finalVerdict}`);
         // Error already logged within performVerification via addStep
         // We will still return a 200 OK but include the error status in the payload
    } else {
        // Log successful completion calculation only if no error status from verifier
        await logRecallEvent(
            'FINAL_VERDICT_CALCULATED',
            {
                calculatedVerdict: verificationResult.finalVerdict,
                confidence: verificationResult.confidenceScore,
                usedCidsCount: verificationResult.usedFragmentCids.length,
                timelockRequestId: verificationResult.timelockRequestId,
            },
            uniqueRequestContext
        );
    }

    // Log completion of controller handling for this request
    await logRecallEvent('VERIFICATION_COMPLETE', { finalStatus: verificationResult.finalVerdict }, uniqueRequestContext);

    // --- 3. Prepare SUCCESS API Response Payload ---
    const recallTrace = await getTraceFromRecall(uniqueRequestContext); // Fetch trace for response
    const responsePayload: ApiVerifyResponse = {
        answer: finalAnswer,
        status: verificationResult.finalVerdict,
        confidence: verificationResult.confidenceScore,
        usedFragmentCids: verificationResult.usedFragmentCids,
        timelockRequestId: verificationResult.timelockRequestId,
        timelockTxExplorerUrl: verificationResult.timelockCommitTxHash
            ? getL2ExplorerUrl(verificationResult.timelockCommitTxHash) // Util handles undefined RPC/ChainID
            : undefined,
        recallTrace: recallTrace,
        // recallExplorerUrl: // TODO: Add if Recall provides one based on context/trace ID
    };

    console.log(`[Controller] Sending successful response for request ${uniqueRequestContext}`);
    res.status(200).json(responsePayload);

  } catch (error: any) {
    console.error(`[Controller Error Request: ${uniqueRequestContext}]:`, error.message);
    // Log the error that reached the controller catch block
    await logRecallEvent('VERIFICATION_ERROR', { controllerError: error.message, stack: error.stack?.substring(0, 300) }, uniqueRequestContext);

    // --- Prepare ERROR API Response Payload ---
    const recallTraceOnError = await getTraceFromRecall(uniqueRequestContext); // Attempt to get trace even on error
    const errorResponse: ApiVerifyResponse = {
        answer: finalAnswer === "Processing..." ? "Failed to process request." : finalAnswer, // Show generated answer if available
        status: verificationResult?.finalVerdict || 'Error: Verification Failed', // Show status if verifier ran partially
        error: 'Verification process encountered an error.', // Generic error for frontend
        details: error.message, // Specific error message
        recallTrace: recallTraceOnError // Include trace up to failure point
    };
    res.status(500).json(errorResponse);
  }
}
===== ./src/repo_contents.txt =====
===== ./config.ts =====
// kintask/packages/backend/src/config.ts
import dotenv from 'dotenv';
import path from 'path';

// Load .env file specifically from the backend package root
dotenv.config({ path: path.resolve(__dirname, '../.env') });

const config = {
  port: process.env.PORT || 3001,
  // OpenRouter Config
  openRouterApiKey: process.env.OPENROUTER_API_KEY,
  // W3UP/Storacha Config
  w3upAgentEmail: process.env.W3UP_AGENT_EMAIL,
  kintaskSpaceDid: process.env.KINTASK_SPACE_DID,
  // KG Index CID
  knowledgeBaseIndexCid: process.env.KB_INDEX_CID,
  // IPFS Gateway for Retrieval (Optional Override)
  ipfsGatewayUrl: process.env.IPFS_GATEWAY_URL || 'https://w3s.link/ipfs/', // Default to w3s.link
  // Recall Config
  recallApiKey: process.env.RECALL_API_KEY,
  recallApiEndpoint: process.env.RECALL_API_ENDPOINT,
  // L2 & Wallet Config
  l2RpcUrl: process.env.L2_RPC_URL,
  walletPrivateKey: process.env.WALLET_PRIVATE_KEY,
  kintaskContractAddress: process.env.KINTASK_CONTRACT_ADDRESS,
  blocklockSenderProxyAddress: process.env.BLOCKLOCK_SENDER_PROXY_ADDRESS,
};

// Runtime validation for critical variables
// Note: Making recallApiKey and recallApiEndpoint optional for simulation
const requiredEnvVars: Array<keyof Omit<typeof config, 'recallApiKey' | 'recallApiEndpoint' | 'ipfsGatewayUrl'>> = [
    'openRouterApiKey',
    'w3upAgentEmail',
    'kintaskSpaceDid',
    'knowledgeBaseIndexCid', // Still optional initially until script is run
    'l2RpcUrl',
    'walletPrivateKey',
    'kintaskContractAddress',
    'blocklockSenderProxyAddress',
];

let missingVars = false;
requiredEnvVars.forEach((varName) => {
  // Allow KB_INDEX_CID to be missing initially
  if (varName === 'knowledgeBaseIndexCid' && !config[varName]) {
      console.warn(`Warning: ${varName} is not set. Run the KG upload script ('pnpm kg:upload') first.`);
      return; // Don't mark as fatal error yet
  }
  if (!config[varName]) {
    console.error(`FATAL ERROR: Environment variable ${varName} is not set in packages/backend/.env`);
    missingVars = true;
  }
});

// Optional Recall check
if (!config.recallApiKey || !config.recallApiEndpoint) {
    console.warn("Warning: Recall API Key/Endpoint not set. Recall logging will be simulated.");
}

// Validate Space DID format (basic check)
if (config.kintaskSpaceDid && !config.kintaskSpaceDid.startsWith('did:key:')) {
    console.error(`FATAL ERROR: KINTASK_SPACE_DID (${config.kintaskSpaceDid}) in packages/backend/.env does not look like a valid did:key identifier.`);
    missingVars = true; // Treat as fatal
}


if (missingVars) {
    console.error("\nPlease configure the required variables in packages/backend/.env and restart.");
    process.exit(1); // Exit if critical config is missing
}

export default config;===== ./contracts/abi/KintaskCommitment.json =====
// ACTION REQUIRED:
// AFTER RUNNING `pnpm contracts:compile` in the root directory,
// COPY THE CONTENT OF THE FILE:
// `packages/contracts/artifacts/contracts/KintaskCommitment.sol/KintaskCommitment.json`
// AND PASTE IT HERE, REPLACING THIS COMMENT BLOCK AND THE EMPTY {}
{}
===== ./contracts/addresses.ts =====
import config from '../config';

export const KINTASK_COMMITMENT_CONTRACT_ADDRESS = config.kintaskContractAddress || '';

// Add other contract addresses if needed

if (!KINTASK_COMMITMENT_CONTRACT_ADDRESS && process.env.NODE_ENV !== 'test') { // Don't warn during tests maybe
    console.warn("Backend Config Warning: KintaskCommitment Contract address (KINTASK_CONTRACT_ADDRESS) is not set in .env!");
}
===== ./controllers/verifyController.ts =====
import { Request, Response, NextFunction } from 'express';
import { generateAnswer } from '../services/generatorService';
import { performVerification } from '../services/verifierService';
import { logRecallEvent, getTraceFromRecall } from '../services/recallService';
import { VerificationResultInternal, ApiVerifyResponse } from '../types';
import { getL2ExplorerUrl } from '../utils';
import config from '../config'; // Import config if needed for L2 Chain ID for explorer

export async function handleVerifyRequest(req: Request, res: Response, next: NextFunction): Promise<void> {
  const { question } = req.body;
  const requestTimestamp = new Date().toISOString();
  // Create a unique context ID for this specific request to correlate Recall logs
  const uniqueRequestContext = `req_${Date.now()}_${Math.random().toString(16).substring(2, 8)}`;

  // --- Input Validation ---
  if (!question || typeof question !== 'string' || question.trim() === '') {
    res.status(400).json({ error: 'Invalid request body. Non-empty "question" string is required.' });
    return;
  }
  if (question.length > 1500) { // Limit question length
       res.status(400).json({ error: 'Question exceeds maximum length (1500 characters).' });
       return;
  }

  let verificationResult: VerificationResultInternal | null = null;
  let finalAnswer = "Processing..."; // Initial state

  console.log(`[Controller] Handling request ${uniqueRequestContext} for question: "${question.substring(0, 50)}..."`);
  try {
    // --- Log Start ---
    // Use await to ensure start is logged before proceeding, good for tracing flows
    await logRecallEvent('VERIFICATION_START', { question: question.substring(0, 200) + (question.length > 200 ? '...' : '') }, uniqueRequestContext);

    // --- 1. Generate Answer (Mocked) ---
    finalAnswer = await generateAnswer(question);
    // Check if mock returned an error string
    if (finalAnswer.startsWith('Error:')) {
         await logRecallEvent('VERIFICATION_ERROR', { step: 'GeneratorMock', error: finalAnswer }, uniqueRequestContext);
         throw new Error(`Mock Generator failed: ${finalAnswer}`);
    }
    await logRecallEvent('GENERATOR_MOCK_USED', { question: question.substring(0, 50) + '...', generatedAnswer: finalAnswer.substring(0, 50) + '...' }, uniqueRequestContext);


    // --- 2. Perform Verification ---
    verificationResult = await performVerification(question, finalAnswer, uniqueRequestContext);

    // Handle critical failure within the verification service itself
    if (!verificationResult) {
        await logRecallEvent('VERIFICATION_ERROR', { step: 'Verifier', error: "Verifier service returned null" }, uniqueRequestContext);
        throw new Error("Verification service failed to produce a result.");
    }
    // Handle error status returned by the verifier (e.g., Timelock Failed)
    if (verificationResult.finalVerdict.startsWith('Error:')) {
         console.warn(`[Controller] Verification completed with error status: ${verificationResult.finalVerdict}`);
         // Error already logged within performVerification via addStep
         // We will still return a 200 OK but include the error status in the payload
    } else {
        // Log successful completion calculation only if no error status from verifier
        await logRecallEvent(
            'FINAL_VERDICT_CALCULATED',
            {
                calculatedVerdict: verificationResult.finalVerdict,
                confidence: verificationResult.confidenceScore,
                usedCidsCount: verificationResult.usedFragmentCids.length,
                timelockRequestId: verificationResult.timelockRequestId,
            },
            uniqueRequestContext
        );
    }

    // Log completion of controller handling for this request
    await logRecallEvent('VERIFICATION_COMPLETE', { finalStatus: verificationResult.finalVerdict }, uniqueRequestContext);

    // --- 3. Prepare SUCCESS API Response Payload ---
    const recallTrace = await getTraceFromRecall(uniqueRequestContext); // Fetch trace for response
    const responsePayload: ApiVerifyResponse = {
        answer: finalAnswer,
        status: verificationResult.finalVerdict,
        confidence: verificationResult.confidenceScore,
        usedFragmentCids: verificationResult.usedFragmentCids,
        timelockRequestId: verificationResult.timelockRequestId,
        timelockTxExplorerUrl: verificationResult.timelockCommitTxHash
            ? getL2ExplorerUrl(verificationResult.timelockCommitTxHash) // Util handles undefined RPC/ChainID
            : undefined,
        recallTrace: recallTrace,
        // recallExplorerUrl: // TODO: Add if Recall provides one based on context/trace ID
    };

    console.log(`[Controller] Sending successful response for request ${uniqueRequestContext}`);
    res.status(200).json(responsePayload);

  } catch (error: any) {
    console.error(`[Controller Error Request: ${uniqueRequestContext}]:`, error.message);
    // Log the error that reached the controller catch block
    await logRecallEvent('VERIFICATION_ERROR', { controllerError: error.message, stack: error.stack?.substring(0, 300) }, uniqueRequestContext);

    // --- Prepare ERROR API Response Payload ---
    const recallTraceOnError = await getTraceFromRecall(uniqueRequestContext); // Attempt to get trace even on error
    const errorResponse: ApiVerifyResponse = {
        answer: finalAnswer === "Processing..." ? "Failed to process request." : finalAnswer, // Show generated answer if available
        status: verificationResult?.finalVerdict || 'Error: Verification Failed', // Show status if verifier ran partially
        error: 'Verification process encountered an error.', // Generic error for frontend
        details: error.message, // Specific error message
        recallTrace: recallTraceOnError // Include trace up to failure point
    };
    res.status(500).json(errorResponse);
  }
}
===== ./repo_contents.txt =====
===== ./routes/verify.ts =====
import { Router } from 'express';
import { handleVerifyRequest } from '../controllers/verifyController';

const router = Router();

/**
 * @route POST /api/verify
 * @description Endpoint to receive a question, generate an answer, verify it,
 *              commit the verdict via timelock, log the process to Recall,
 *              and return the results.
 * @body { "question": "string" } - The user's question. Max length ~1500 chars recommended.
 * @returns {ApiVerifyResponse} 200 - Success response with answer, status, proofs.
 * @returns {object} 400 - Invalid request body (missing question, too long, etc.).
 * @returns {object} 500 - Internal server error during processing.
 */
router.post('/verify', handleVerifyRequest);

export default router;
===== ./server.ts =====
import express, { Express, Request, Response, NextFunction } from 'express';
import cors from 'cors';
import config from './config';
import verifyRoutes from './routes/verify';
import { startRevealListener, stopRevealListener } from './services/timelockService'; // Import listener controls

const app: Express = express();
const port = config.port;

// --- Middleware ---
app.use(cors()); // Allow requests from frontend (configure origins for production)
app.use(express.json({ limit: '1mb' })); // Parse JSON request bodies, limit size
app.use((req: Request, res: Response, next: NextFunction) => {
    const start = Date.now();
    res.on('finish', () => {
         const duration = Date.now() - start;
         console.log(`[${new Date().toISOString()}] ${req.method} ${req.originalUrl} ${res.statusCode} ${duration}ms`);
    });
    next();
});

// --- Routes ---
app.use('/api', verifyRoutes);

// Root Route / Health Check
app.get('/', (req: Request, res: Response) => {
  res.status(200).json({ status: 'ok', message: 'Kintask Backend is running!'});
});

// --- 404 Handler ---
// Catch-all for routes not defined
app.use((req, res, next) => {
    res.status(404).json({ error: 'Not Found', message: `Endpoint ${req.method} ${req.path} does not exist.` });
});


// --- Global Error Handler ---
// Catches errors passed via next(error)
app.use((err: Error, req: Request, res: Response, next: NextFunction) => {
  console.error("[Global Error Handler]:", err.stack || err);
  // Avoid sending stack trace in production
  const message = process.env.NODE_ENV === 'production' ? 'An unexpected error occurred.' : err.message;
  res.status(500).json({
      error: 'Internal Server Error',
      message: message,
  });
});

// --- Start Server ---
const server = app.listen(port, () => {
  console.log(`[server]: Kintask Backend server is running at http://localhost:${port}`);
  // Initialize Timelock Listener on startup
  try {
      startRevealListener();
  } catch (listenerError) {
       console.error("[Server Startup] Failed to start Timelock listener:", listenerError);
  }
});

// --- Graceful Shutdown ---
const gracefulShutdown = (signal: string) => {
    console.log(`\n${signal} signal received: closing HTTP server...`);
    // Stop listener first
    stopRevealListener();
    server.close(() => {
        console.log('HTTP server closed.');
        // Perform other cleanup if needed (e.g., DB connections)
        console.log("Exiting process.");
        process.exit(0);
    });

    // Force close server after a timeout if graceful shutdown fails
     setTimeout(() => {
         console.error('Could not close connections in time, forcefully shutting down');
         process.exit(1);
     }, 10000); // 10 seconds timeout
};

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT')); // Catches Ctrl+C
===== ./services/filecoinService.ts =====
// kintask/packages/backend/src/services/filecoinService.ts

import axios, { AxiosError } from 'axios';
import config from '../config'; // Import configuration to get gateway URL and index CID
import { KnowledgeFragment } from '../types'; // Import the structure definition

// --- Configuration ---
// Use the gateway specified in config, defaulting to a reliable public one (w3s.link)
const IPFS_GATEWAY = config.ipfsGatewayUrl || 'https://w3s.link/ipfs/';
const MAX_RETRIES = 3; // Number of retry attempts for failed fetches
const RETRY_DELAY_MS = 800; // Initial delay before retrying (will increase exponentially)
const REQUEST_TIMEOUT = 25000; // Timeout for each HTTP request in milliseconds (25 seconds)

console.log(`[Filecoin Service] Using IPFS Gateway for retrieval: ${IPFS_GATEWAY}`);

// Structure expected in the index file uploaded to Filecoin/Storacha
interface IndexFileStructure {
    createdAt: string;
    description?: string;
    fragmentsById?: Record<string, string>; // fragment_id -> cid map (optional)
    index: Record<string, string[]>; // keyword -> [cid] map - Primary index used
    indexRootCid?: string; // Optional: CID of the directory containing all fragments
}

// Simple in-memory cache with TTL (Time To Live) in milliseconds
interface CacheEntry<T> {
    data: T;
    timestamp: number; // When the data was cached
}
const cache = new Map<string, CacheEntry<any>>();
const CACHE_TTL_MS = 10 * 60 * 1000; // Cache validity duration (e.g., 10 minutes)

// --- Cache Utility Functions ---

/**
 * Stores data in the in-memory cache.
 * @param key - The cache key (typically the CID).
 * @param data - The data to store.
 */
function setCache<T>(key: string, data: T) {
    if (!key) return; // Do not cache with empty key
    cache.set(key, { data, timestamp: Date.now() });
    // console.log(`[Cache] Set cache for key: ${key.substring(0,10)}...`);
}

/**
 * Retrieves data from the cache if it exists and is not expired.
 * @param key - The cache key (typically the CID).
 * @returns The cached data or null if not found or expired.
 */
function getCache<T>(key: string): T | null {
    if (!key) return null;
    const entry = cache.get(key);
    if (entry && (Date.now() - entry.timestamp < CACHE_TTL_MS)) {
        // console.log(`[Cache] Hit for key: ${key.substring(0,10)}...`);
        return entry.data as T;
    }
    // console.log(`[Cache] Miss or expired for key: ${key.substring(0,10)}...`);
    cache.delete(key); // Remove expired or non-existent entry
    return null;
}

// --- Core Fetching Logic ---

/**
 * Fetches data from the configured IPFS gateway with caching and retry logic.
 * @param url - The full URL to fetch from the gateway.
 * @param cacheKey - The key to use for caching (typically the CID).
 * @returns The fetched data (parsed as JSON if applicable) or null if fetch fails.
 */
async function fetchWithRetry<T>(url: string, cacheKey: string): Promise<T | null> {
    // 1. Check Cache first
    const cachedData = getCache<T>(cacheKey);
    if (cachedData) {
        return cachedData;
    }

    console.log(`[Filecoin Service] Fetching: ${url} (Cache Key: ${cacheKey.substring(0,10)}...)`);

    // 2. Attempt Fetch with Retries
    for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
        try {
            const response = await axios.get<T>(url, {
                timeout: REQUEST_TIMEOUT,
                // Ensure correct headers for potentially receiving JSON
                headers: {
                    'Accept': 'application/json, application/octet-stream, */*',
                    // 'User-Agent': 'KintaskBackend/1.0' // Optional: Identify your client
                 }
             });

            // Check content type for JSON if expecting it (primarily for fragments/index)
            const contentType = response.headers['content-type'];
            const isJsonExpected = url.includes(config.knowledgeBaseIndexCid || 'INVALID_CID') || cacheKey !== config.knowledgeBaseIndexCid; // Assume fragments & index are JSON

            if (isJsonExpected && (!contentType || !contentType.includes('application/json'))) {
                // Gateways sometimes return HTML error pages or non-JSON for DAG issues
                console.warn(`[Filecoin Service] Attempt ${attempt} for ${cacheKey}: Expected JSON but received Content-Type: ${contentType}. Raw data sample:`, typeof response.data === 'string' ? response.data.substring(0, 100) + '...' : typeof response.data);
                // Treat non-JSON response as an error for expected JSON content
                 throw new Error(`Expected JSON content, but received ${contentType || 'unknown content type'}`);
            }

            // Check for successful status code
            if (response.status === 200 && response.data) {
                console.log(`[Filecoin Service] Successfully fetched ${cacheKey.substring(0,10)}... (Attempt ${attempt})`);
                setCache(cacheKey, response.data); // Cache the successful response
                return response.data;
            } else {
                // Log unexpected success status codes (e.g., 204 No Content?)
                console.warn(`[Filecoin Service] Fetch attempt ${attempt} for ${cacheKey} returned unexpected status: ${response.status}`);
                // Continue to retry loop
            }

        } catch (error: any) {
            const axiosError = error as AxiosError;
            console.warn(`[Filecoin Service] Error fetch attempt ${attempt}/${MAX_RETRIES} for ${cacheKey}:`, axiosError.message);

            // Log details from the error response if available
            if (axiosError.response) {
                 console.warn(`  Gateway Response Status: ${axiosError.response.status}`);
                 // console.warn(`  Gateway Response Headers:`, axiosError.response.headers); // Can be verbose
                 // console.warn(`  Gateway Response Data:`, axiosError.response.data); // Can be verbose/large

                 // Don't retry on 404 Not Found - the content likely doesn't exist
                 if (axiosError.response.status === 404) {
                      console.error(`[Filecoin Service] CID ${cacheKey} not found on gateway (404). Stopping retries.`);
                      return null; // Indicate definitively not found
                 }
                 // Consider stopping retries on other client errors (4xx) too?
            } else if (axiosError.code === 'ECONNABORTED' || axiosError.message.includes('timeout')) {
                console.warn(`  Gateway request timed out.`);
            }

            // If it's the last attempt, log final failure and return null
            if (attempt === MAX_RETRIES) {
                console.error(`[Filecoin Service] Final fetch attempt failed for CID: ${cacheKey} after ${MAX_RETRIES} tries.`);
                return null;
            }

            // Wait before retrying with exponential backoff
            const delay = RETRY_DELAY_MS * Math.pow(2, attempt - 1); // 1s, 2s, 4s...
            console.log(`  Retrying in ${delay}ms...`);
            await new Promise(resolve => setTimeout(resolve, delay));
        }
    }

    // Should not be reached if error handling above is correct, but acts as a fallback
    console.error(`[Filecoin Service] Fetch failed unexpectedly for ${cacheKey} after all attempts.`);
    return null;
}

// --- Exported Service Functions ---

/**
 * Fetches and parses the Knowledge Graph index file from Filecoin/IPFS.
 * @returns The keyword-to-CID index object, or null if fetching fails.
 */
export async function getKnowledgeIndex(): Promise<IndexFileStructure['index'] | null> {
    const indexCid = config.knowledgeBaseIndexCid;
    if (!indexCid) {
        console.error('[Filecoin Service] FATAL ERROR: KB_INDEX_CID is not configured in backend .env.');
        return null;
    }

    const url = `${IPFS_GATEWAY}${indexCid}`;
    console.log(`[Filecoin Service] Getting Knowledge Index (CID: ${indexCid.substring(0,10)}...)`);
    const indexFile = await fetchWithRetry<IndexFileStructure>(url, indexCid); // Use index CID as cache key

    if (indexFile && typeof indexFile.index === 'object' && indexFile.index !== null) {
         // Optional: Log how many keywords are in the loaded index
         console.log(`[Filecoin Service] Successfully loaded index with ${Object.keys(indexFile.index).length} keywords.`);
         return indexFile.index;
    } else {
         console.error(`[Filecoin Service] Failed to fetch or parse index file structure from CID: ${indexCid}`);
         return null;
    }
}

/**
 * Fetches and parses a single Knowledge Fragment JSON object from Filecoin/IPFS using its CID.
 * @param cid - The Content Identifier (CID) of the fragment to fetch.
 * @returns The parsed KnowledgeFragment object, or null if fetching or parsing fails.
 */
export async function fetchKnowledgeFragment(cid: string): Promise<KnowledgeFragment | null> {
    // Basic CID format validation
    if (!cid || typeof cid !== 'string' || (!cid.startsWith('bafy') && !cid.startsWith('Qm'))) {
        console.error(`[Filecoin Service] Invalid CID format provided for fragment fetch: ${cid}`);
        return null;
    }

    const url = `${IPFS_GATEWAY}${cid}`;
    // Use fragment CID as the cache key
    const fragment = await fetchWithRetry<KnowledgeFragment>(url, cid);

    // Optional: Add schema validation here after fetching if needed
    // if (fragment && !isValidKnowledgeFragment(fragment)) {
    //     console.error(`[Filecoin Service] Fetched data for CID ${cid} is not a valid KnowledgeFragment.`);
    //     return null;
    // }

    return fragment;
}

// Optional: Add a function to clear the cache if needed for debugging
export function clearFilecoinCache() {
    console.log("[Filecoin Service] Clearing in-memory cache.");
    cache.clear();
}===== ./services/generatorService.ts =====
// kintask/packages/backend/src/services/generatorService.ts
import axios, { AxiosError } from 'axios'; // Using axios for HTTP requests
import config from '../config'; // Import configuration (includes API key)
import { logRecallEvent } from './recallService'; // Import recall logger for errors


const OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions";
const API_KEY = config.openRouterApiKey;

// --- Model Configuration ---
// ACTION REQUIRED: Choose a model available on OpenRouter.
// Check https://openrouter.ai/models for options and pricing.
// Using the free Mistral model as a default.
const MODEL_IDENTIFIER = "mistralai/mistral-7b-instruct:free";
// --- End Model Configuration ---

// --- Generation Parameters ---
const MAX_TOKENS = 250; // Max length of the generated response
const TEMPERATURE = 0.5; // Lower value = more deterministic, higher = more creative
const TOP_P = 0.9;      // Nucleus sampling
// --- End Generation Parameters ---

let isGeneratorInitialized = false;

function initializeGenerator() {
    if (isGeneratorInitialized) return;
    console.log("[Generator Service] Initializing OpenRouter configuration...");
    if (!API_KEY) {
        // This case should be caught by config.ts validation, but double-check
        console.error("[Generator Service] FATAL ERROR: OPENROUTER_API_KEY is not configured.");
        isGeneratorInitialized = false;
        return; // Prevent setting initialized flag
    }
     console.log(`[Generator Service] Configured to use OpenRouter model: ${MODEL_IDENTIFIER}`);
    isGeneratorInitialized = true;
}

// Ensure service is initialized before first use (lazy initialization)
// initializeGenerator(); // Call this explicitly in server startup if preferred


export async function generateAnswer(question: string, requestContext?: string): Promise<string> {
    if (!isGeneratorInitialized) initializeGenerator(); // Ensure initialized

    if (!API_KEY || !isGeneratorInitialized) {
        console.error("[Generator Service] OpenRouter API Key not configured or service failed initialization.");
        return "Error: AI answer generation service is not available."; // Return error string
    }
    if (!question || question.trim() === '') {
        console.warn("[Generator Service] Received empty question.");
        return "Error: Cannot generate answer for empty question.";
    }

    console.log(`[Generator Service Request: ${requestContext}] Requesting OpenRouter (${MODEL_IDENTIFIER}) answer...`);

    // --- Construct Payload for OpenRouter (OpenAI compatible format) ---
    const systemPrompt = 'You are Kintask, a helpful AI assistant. Provide concise, factual answers based on general knowledge. Avoid hedging or apologies.';
    const payload = {
        model: MODEL_IDENTIFIER,
        messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: question }
        ],
        max_tokens: MAX_TOKENS,
        temperature: TEMPERATURE,
        top_p: TOP_P,
        // stream: false, // Explicitly disable streaming for simple request/response
    };
    // --- End Payload Construction ---

    try {
        const response = await axios.post(
            OPENROUTER_API_URL,
            payload,
            {
                headers: {
                    'Authorization': `Bearer ${API_KEY}`,
                    'Content-Type': 'application/json',
                    // Recommended headers for OpenRouter analytics/tracking
                    'HTTP-Referer': `http://localhost:${config.port || 3001}`, // Use configured port
                    'X-Title': 'Kintask Hackathon', // Your App Name
                },
                timeout: 60000 // 60 second timeout for API call
            }
        );

        // --- Process OpenRouter Response ---
        const choice = response.data?.choices?.[0];
        const answer = choice?.message?.content?.trim();
        const finishReason = choice?.finish_reason;

        console.log(`[Generator Service Request: ${requestContext}] Finish Reason: ${finishReason || 'N/A'}`);

        if (finishReason === 'length') {
            console.warn(`[Generator Service Request: ${requestContext}] OpenRouter response truncated due to max_tokens limit.`);
            // Return the truncated answer, the user might still find it useful
        } else if (finishReason !== 'stop' && finishReason !== null) {
             console.warn(`[Generator Service Request: ${requestContext}] Unusual finish reason: ${finishReason}.`);
        }

        if (!answer) {
            console.warn(`[Generator Service Request: ${requestContext}] OpenRouter returned empty answer content. Response:`, JSON.stringify(response.data).substring(0, 200) + "...");
            // Check for explicit errors in the response structure
            const errorMsg = (response.data as any)?.error?.message || 'The AI model did not provide a valid text answer.';
            // Log this failure to Recall
             if (requestContext) {
                 logRecallEvent('VERIFICATION_ERROR', { step: 'GeneratorParse', error: errorMsg, responseData: response.data }, requestContext)
                    .catch(err => console.error("Error logging generator parse error to recall:", err));
             }
            return `Error: ${errorMsg}`;
        }
        // --- End Response Processing ---

        console.log(`[Generator Service Request: ${requestContext}] Received OpenRouter answer (truncated): "${answer.substring(0, 100)}..."`);
        return answer;

    } catch (error: any) {
        const axiosError = error as AxiosError;
        console.error(`[Generator Service Request: ${requestContext}] Error fetching answer from OpenRouter:`, axiosError.message);

        let detailedErrorMessage = axiosError.message;
        let responseDataForLog: any = null;

        if (axiosError.response) {
            console.error(`  Status: ${axiosError.response.status}`);
            const responseData = axiosError.response.data;
            responseDataForLog = responseData; // Log the actual response data if available
            console.error('  Response Data:', JSON.stringify(responseData).substring(0, 300) + "...");
            // Extract specific error message from OpenRouter/model if available
            detailedErrorMessage = (responseData as any)?.error?.message || `HTTP Error ${axiosError.response.status}`;
        } else if (axiosError.request) {
             console.error('  No response received from OpenRouter.');
             detailedErrorMessage = 'No response received from OpenRouter service.';
        } else {
             console.error('  Error setting up OpenRouter request:', error.message);
             detailedErrorMessage = `Request setup error: ${error.message}`;
        }

        // Log error details to Recall
        if (requestContext) {
            logRecallEvent('VERIFICATION_ERROR', { step: 'GeneratorAPI', error: detailedErrorMessage, responseData: responseDataForLog }, requestContext)
                .catch(err => console.error("Error logging generator API error to recall:", err));
        }

        return `Error: Could not retrieve answer from the AI model (${detailedErrorMessage.substring(0, 80)}...).`; // Return user-friendly error
    }
}===== ./services/recallService.ts =====
// recall.service.ts
import config from '../config';
import { RecallLogEntryData, RecallEventType } from '../types';
import { testnet } from '@recallnet/chains'; // Use the testnet chain definition
import { createWalletClient, http, parseEther, WalletClient, PublicClient, createPublicClient, ChainMismatchError } from 'viem';
import { privateKeyToAccount, Account } from 'viem/accounts';
// Assuming named exports based on example structure
import { RecallClient } from '@recallnet/sdk/client'; // Removed BucketManager import

// --- Module State ---
let recallClientInstance: RecallClient | null = null;
let isRecallInitialized = false;
let logBucketAddress = config.recallLogBucket || null; // Store the bucket address globally
let account: Account | null = null;
const RECALL_BUCKET_ALIAS = 'kintask-log-bucket-v1'; // Unique alias for this project's log bucket
let initPromise: Promise<RecallClient> | null = null; // To handle concurrent initializations

// --- Helper: Create Viem Wallet Client ---
function getWalletClient(): WalletClient {
    if (!config.recallPrivateKey) {
        throw new Error('Recall Private Key (PRIVATE_KEY in .env) is not configured.');
    }
    const formattedPrivateKey = config.recallPrivateKey.startsWith('0x')
        ? config.recallPrivateKey as `0x${string}`
        : `0x${config.recallPrivateKey}` as `0x${string}`;

    if (!account) { // Cache the account object
         account = privateKeyToAccount(formattedPrivateKey);
         console.log(`[Recall Service] Using wallet address: ${account.address} on chain ${testnet.id}`);
    }

    // Ensure the transport is configured for the correct chain
    return createWalletClient({
        account: account,
        chain: testnet, // Explicitly set Recall testnet chain
        transport: http(), // Default HTTP transport - Add RPC URL from testnet config if needed explicitly
                          // transport: http(testnet.rpcUrls.default.http[0]),
    });
}

 // --- Helper: Create Viem Public Client ---
 function getPublicClient(): PublicClient {
     return createPublicClient({
         chain: testnet, // Use Recall testnet chain
         transport: http(),
     });
 }


// --- Helper: Get or Initialize Recall Client (Singleton Pattern) ---
async function getRecallClient(): Promise<RecallClient> {
    if (recallClientInstance && isRecallInitialized) {
        return recallClientInstance;
    }
    // Prevent race conditions during initialization
    if (initPromise) {
        return initPromise;
    }

    initPromise = (async () => {
        console.log("[Recall Service] Initializing Recall Client (getRecallClient)...");
        try {
            const walletClient = getWalletClient(); // Get viem wallet client configured for Recall testnet
            const client = new RecallClient({ walletClient });

            // Basic check: Ensure client has account after initialization
            if (!client.walletClient.account?.address) {
                throw new Error("Failed to initialize client: Wallet address missing.");
            }
            console.log("[Recall Service] Recall Client Initialized successfully.");
            recallClientInstance = client;
            isRecallInitialized = true; // Mark as initialized
            initPromise = null; // Clear promise
            return client;
        } catch (error: any) {
            console.error("[Recall Service] FATAL ERROR initializing Recall Client:", error.message);
            recallClientInstance = null;
            isRecallInitialized = false;
            initPromise = null;
            throw new Error(`Recall Client initialization failed: ${error.message}`); // Rethrow to calling function
        }
    })();

    return initPromise;
}

// --- Helper: Ensure Credit Balance ---
// Returns true if credit was sufficient OR successfully purchased, false otherwise
async function ensureCreditBalanceIfZero(recall: RecallClient): Promise<boolean> {
    console.log("[Recall Service] Checking credit balance...");
    try {
        const creditManager = recall.creditManager();
        const { result: creditBalance } = await creditManager.getCreditBalance();
        const creditFree = creditBalance?.creditFree ?? 0n;
        console.log(`[Recall Service] Current credit_free: ${creditFree.toString()}`);

        if (creditFree === 0n) { // Only buy if exactly zero
            console.log('[Recall Service] credit_free is 0, attempting to buy 1 credit...');
            const amountToBuy = parseEther("1");
            const { meta } = await creditManager.buy(amountToBuy);
            const txHash = meta?.tx?.transactionHash;
            if (!txHash) throw new Error("Credit purchase transaction did not return a hash.");

            console.log(`[Recall Service] Credit purchase transaction sent: ${txHash}. Waiting for confirmation...`);
            const publicClient = getPublicClient();
            const receipt = await publicClient.waitForTransactionReceipt({ hash: txHash, confirmations: 1 });

            if (receipt.status === 'success') {
                 console.log(`[Recall Service] Credit purchased successfully (Tx: ${txHash}).`);
                 await new Promise(resolve => setTimeout(resolve, 3000)); // Allow buffer time
                 return true;
            } else {
                 console.error(`[Recall Service] Credit purchase transaction failed (Tx: ${txHash}). Status: ${receipt.status}`);
                 throw new Error(`Failed to purchase Recall credit (Tx: ${txHash}, Status: ${receipt.status}).`);
            }
        }
        return true; // Credit was > 0 initially
    } catch (error: any) {
        console.error("[Recall Service] Error checking or buying credit:", error.message);
         if (error instanceof ChainMismatchError) {
              console.error("[Recall Service] Chain mismatch detected. Check Recall SDK/Chain config.");
         }
        // Rethrow or return false to indicate failure? Let's rethrow for clarity.
        throw new Error(`Failed to ensure Recall credit balance: ${error.message}`);
    }
}

// --- Helper: Find or Create Log Bucket ---
async function ensureLogBucket(recall: RecallClient): Promise<string> {
    if (logBucketAddress) {
        return logBucketAddress;
    }

    console.log(`[Recall Service] Attempting to find or create log bucket with alias: ${RECALL_BUCKET_ALIAS}`);
    const bucketManager = recall.bucketManager();
    let foundBucket: string | null = null;

    try {
        const { result: listResult } = await bucketManager.list();
        const buckets = listResult?.buckets || [];
        console.log(`[Recall Service] Checking ${buckets.length} accessible buckets for alias...`);

        for (const bucketAddr of buckets) {
            try {
                // list returns { kind: string, addr: string, metadata: Record<string, unknown> }[]
                // No need to call getMetadata separately if list returns it
                if (bucketAddr.metadata?.alias === RECALL_BUCKET_ALIAS) {
                    console.log(`[Recall Service] Found existing log bucket: ${bucketAddr.addr}`);
                    foundBucket = bucketAddr.addr;
                    break;
                }
            } catch (listError: any) { /* Handle specific list errors if needed */ }
        }

        if (!foundBucket) {
            console.log(`[Recall Service] Log bucket alias '${RECALL_BUCKET_ALIAS}' not found. Creating new bucket...`);
            await ensureCreditBalanceIfZero(recall); // Ensure credit before creating

            const createMetaPayload = { alias: RECALL_BUCKET_ALIAS, createdBy: 'KintaskBackend', timestamp: new Date().toISOString() };
            const { result, meta: createMetaInfo } = await bucketManager.create({ metadata: createMetaPayload });
            foundBucket = result?.bucket;
            const createTxHash = createMetaInfo?.tx?.transactionHash;

            if (foundBucket) {
                 console.log(`[Recall Service] Successfully created new log bucket: ${foundBucket} (Tx: ${createTxHash})`);
                 console.warn(`ACTION REQUIRED: Consider adding/updating RECALL_LOG_BUCKET in .env to: ${foundBucket} for faster startup.`);
            } else {
                 const errorMsg = createMetaInfo?.error?.message || "Bucket creation call succeeded but no bucket address was returned.";
                 console.error("[Recall Service] Bucket creation failed:", errorMsg, createMetaInfo);
                 throw new Error(errorMsg);
            }
        }

        logBucketAddress = foundBucket; // Cache address
        return logBucketAddress;

    } catch (error: any) {
        console.error("[Recall Service] Error finding or creating log bucket:", error.message);
        throw new Error(`Failed to ensure Recall log bucket: ${error.message}`);
    }
}

// --- Main Logging Function ---
export async function logRecallEvent(
    type: RecallEventType,
    details: Record<string, any>,
    requestContext: string
): Promise<string | undefined> { // Returns Recall Tx Hash or undefined

    if (!requestContext) {
         console.error("[Recall Service] CRITICAL: logRecallEvent called without requestContext.");
         return undefined;
    }

    let recall: RecallClient;
    let bucketAddr: string;
    try {
        // Get client, bucket, and ensure credit *before* creating log entry object
        recall = await getRecallClient();
        bucketAddr = await ensureLogBucket(recall);
        await ensureCreditBalanceIfZero(recall);
    } catch (setupError: any) {
        console.error(`[Recall Service] Setup failed before logging event ${type} (Context: ${requestContext}):`, setupError.message);
        return undefined; // Cannot log if setup fails
    }

    const logEntry: RecallLogEntryData = {
        timestamp: new Date().toISOString(),
        type: type,
        details: details,
        requestContext: requestContext,
    };

    // Prepare data for storage
    const contentString = JSON.stringify(logEntry);
    const fileBuffer = Buffer.from(contentString, 'utf8');
    const timestampSuffix = logEntry.timestamp.replace(/[:.]/g, '-');
    const key = `${requestContext}/${timestampSuffix}_${type}.json`; // Structure logs by request context

    // console.log(`[Recall Service] Logging Event [${requestContext}] Type=${type} to Bucket ${bucketAddr.substring(0,10)}... Key=${key.substring(0,50)}...`);

    try {
        const bucketManager = recall.bucketManager();
        const { meta } = await bucketManager.add(bucketAddr, key, fileBuffer);
        const txHash = meta?.tx?.transactionHash;

        if (!txHash) {
             console.warn(`[Recall Service] Log add successful (according to SDK meta?) for context ${requestContext}, type ${type}, but no txHash returned. Status uncertain.`);
             // Check meta for other status info if available
             return undefined;
        }

        console.log(`[Recall Service] Log Event ${type} stored for context ${requestContext}. TxHash: ${txHash}`);
        return txHash;

    } catch (error: any) {
        console.error(`[Recall Service] Error adding log event ${type} for context ${requestContext} to bucket ${bucketAddr}:`, error.message);
        return undefined; // Indicate logging failure
    }
}

// --- Trace Retrieval Function ---
export async function getTraceFromRecall(requestContext: string): Promise<RecallLogEntryData[]> {
    if (!requestContext) return [];

    console.log(`[Recall Service] Retrieving trace for context: ${requestContext}`);
    let recall: RecallClient;
    let bucketAddr: string;
    try {
        recall = await getRecallClient();
        // Use cached bucket address if available, otherwise ensure it exists
        bucketAddr = logBucketAddress || await ensureLogBucket(recall);
    } catch (initError: any) {
         console.error(`[Recall Service] Initialization failed for retrieving trace (Context: ${requestContext}):`, initError.message);
         return [];
    }

    try {
        const bucketManager = recall.bucketManager();
        const prefix = `${requestContext}/`; // Query by the context "folder"

        console.log(`[Recall Service] Querying bucket ${bucketAddr.substring(0,10)}... for prefix: ${prefix}`);
        const { result: queryResult } = await bucketManager.query(bucketAddr, { prefix: prefix, delimiter: '' });

        const objectInfos = (queryResult?.objects || []);
        const objectKeys = objectInfos.map(obj => obj.key).filter((k): k is string => !!k && k.endsWith('.json'));

        if (objectKeys.length === 0) {
            console.log(`[Recall Service] No log entries found via query for context: ${requestContext}`);
            return [];
        }
        console.log(`[Recall Service] Found ${objectKeys.length} log keys for context ${requestContext}. Fetching content...`);

        // Fetch content concurrently
        const fetchPromises = objectKeys.map(async (key) => {
             try {
                 const { result: objectResult } = await bucketManager.get(bucketAddr, key);
                 const objectBuf = objectResult as Uint8Array | null; // SDK's get returns Uint8Array
                 if (!objectBuf) {
                     console.warn(`[Recall Service] Got null buffer for key ${key}`);
                     return null;
                 }
                 // Ensure it's a Buffer before decoding (Node.js Buffer handles Uint8Array)
                 const buffer = Buffer.from(objectBuf);
                 const textContent = buffer.toString('utf8');
                 const logEntry = JSON.parse(textContent) as RecallLogEntryData;
                 if (logEntry && logEntry.timestamp && logEntry.type && logEntry.details) {
                      return logEntry;
                 }
                 console.warn(`[Recall Service] Invalid log format found parsing key ${key}`);
                 return null;
             } catch (fetchError: any) {
                  console.error(`[Recall Service] Error fetching/parsing key ${key}: ${fetchError.message}`);
                   if (fetchError.message?.includes("Object not found")) {
                        console.warn(`   -> Object likely deleted or query/get mismatch for key ${key}`);
                   }
                  return null;
             }
        });

        const logEntries = (await Promise.all(fetchPromises))
                            .filter((entry): entry is RecallLogEntryData => entry !== null)
                            .sort((a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()); // Sort chronologically

         console.log(`[Recall Service] Successfully retrieved and parsed ${logEntries.length} log entries for context: ${requestContext}`);
         return logEntries;

    } catch (error: any) {
        console.error(`[Recall Service] Error retrieving trace for context ${requestContext}:`, error.message);
        return []; // Return empty trace on error
    }
}

// Removed duplicate declaration: let logBucketAddress = config.recallLogBucket || null;===== ./services/timelockService.ts =====
import { ethers, Wallet, Contract, AbiCoder, keccak256, getBytes, TransactionResponse, TransactionReceipt, Log, EventLog } from 'ethers';
import { Blocklock, SolidityEncoder, encodeCiphertextToSolidity, TypesLib } from 'blocklock-js';
import config from '../config';
import KintaskCommitmentAbi from '../contracts/abi/KintaskCommitment.json'; // Load the ABI
import { KINTASK_COMMITMENT_CONTRACT_ADDRESS } from '../contracts/addresses';
import { logRecallEvent } from './recallService'; // Import recall logger for reveal events

interface CommitResult {
    requestId: string; // The on-chain request ID from Blocklock
    txHash: string; // The L2 transaction hash
    ciphertextHash: string; // Hash of the encrypted data 'v' field
}

// --- Initialization ---
let provider: ethers.JsonRpcProvider | null = null;
let wallet: Wallet | null = null;
let blocklockJsInstance: Blocklock | null = null;
let commitmentContract: Contract | null = null;
let isTimelockInitialized = false;
let revealListenerAttached = false;
// Simple mapping to associate blocklock request ID with our internal request context for logging reveals
const blocklockIdToRequestContext = new Map<string, string>();
const MAX_CONTEXT_MAP_SIZE = 1000; // Prevent memory leak

// Function to initialize (or re-initialize) the service
// Returns true if initialization is complete or already done, false if required config is missing
function initializeTimelockService(): boolean {
    if (isTimelockInitialized) return true; // Already initialized
    console.log("[Timelock Service] Initializing...");
    try {
        // Validate critical config FIRST
         if (!config.l2RpcUrl || !config.walletPrivateKey || !config.blocklockSenderProxyAddress || !KINTASK_COMMITMENT_CONTRACT_ADDRESS) {
             console.warn("[Timelock Service] Skipping initialization: Missing required L2/Blocklock/Contract configuration in .env");
             return false; // Cannot initialize
         }
         // Validate ABI presence
          if (!KintaskCommitmentAbi.abi || KintaskCommitmentAbi.abi.length === 0) {
               console.error("[Timelock Service] FATAL ERROR: KintaskCommitment ABI not found or empty. Run 'pnpm contracts:compile' and copy ABI.");
               return false; // Cannot initialize without ABI
          }

        provider = new ethers.JsonRpcProvider(config.l2RpcUrl);
        wallet = new Wallet(config.walletPrivateKey, provider);
        blocklockJsInstance = new Blocklock(wallet, config.blocklockSenderProxyAddress);
        commitmentContract = new Contract(KINTASK_COMMITMENT_CONTRACT_ADDRESS, KintaskCommitmentAbi.abi, wallet);

        // Perform async checks AFTER basic setup
         Promise.all([
             provider.getNetwork(),
             commitmentContract.getAddress() // Check if contract connection works
         ]).then(([network, address]) => {
             console.log(`[Timelock Service] Connected to network: ${network.name} (Chain ID: ${network.chainId})`);
             console.log(`[Timelock Service] KintaskCommitment contract instance connected at: ${address}`);
             isTimelockInitialized = true; // Mark as fully initialized only after checks pass
             console.log("[Timelock Service] Initialization complete.");
             // Attempt to start listener only after successful init
              startRevealListener(); // Start listener now that we are initialized
         }).catch(err => {
             console.error("[Timelock Service] Post-initialization check failed (Network or Contract connection issue):", err.message);
             // Keep isTimelockInitialized = false if checks fail
             isTimelockInitialized = false;
         });

         console.log("[Timelock Service] Initialization sequence started (async checks pending)...");
         return true; // Return true indicating initialization started

    } catch (error: any) {
         console.error("[Timelock Service] FATAL Initialization failed:", error.message);
         isTimelockInitialized = false;
         return false; // Indicate failure
    }
}

// Attempt initialization on module load
initializeTimelockService();

// --- Commit Function ---
export async function commitVerdictTimelocked(
    verdict: string,
    delayInBlocks: number = 5, // Default delay
    requestContext?: string // Pass context for mapping reveal logs
): Promise<CommitResult | null> {

    // Check initialization status before proceeding
    if (!isTimelockInitialized || !blocklockJsInstance || !commitmentContract || !provider || !wallet) {
        console.error('[Timelock Service] Service not initialized or ready. Cannot commit verdict.');
        return null; // Fail if not ready
    }

    let txResponse: TransactionResponse | null = null; // Define txResponse outside try
    const logContext = requestContext || 'unknownContext'; // Use provided context or a default

    try {
        const currentBlockNumber = await provider.getBlockNumber();
        const decryptionBlockNumber = BigInt(currentBlockNumber + delayInBlocks);
        console.log(`[Timelock Service Context: ${logContext}] Current Block: ${currentBlockNumber}, Decryption Block Target: ${decryptionBlockNumber}`);

        // 1. Encode verdict string
        const encoder = AbiCoder.defaultAbiCoder();
        const encodedVerdict = encoder.encode(['string'], [verdict]);
        const encodedVerdictBytes = getBytes(encodedVerdict);

        // 2. Encrypt using blocklock-js
        console.log(`[Timelock Service Context: ${logContext}] Encrypting verdict "${verdict}"`);
        const ciphertext: TypesLib.Ciphertext = blocklockJsInstance.encrypt(encodedVerdictBytes, decryptionBlockNumber);
        const solidityCiphertext = encodeCiphertextToSolidity(ciphertext);
        const ciphertextHash = keccak256(solidityCiphertext.v); // Hash the encrypted part V
        console.log(`[Timelock Service Context: ${logContext}] Ciphertext Hash: ${ciphertextHash}`);

        // 3. Call commitVerdict on contract
        console.log(`[Timelock Service Context: ${logContext}] Sending commitVerdict transaction to ${await commitmentContract.getAddress()}...`);
        txResponse = await commitmentContract.commitVerdict(
            decryptionBlockNumber,
            solidityCiphertext
            // Optional: Add gas estimation/limit
            // { gasLimit: 300000 } // Example fixed gas limit
        );
        console.log(`[Timelock Service Context: ${logContext}] Commit transaction sent. Hash: ${txResponse.hash}`);
        console.log(`[Timelock Service Context: ${logContext}] Waiting for confirmation (1 block)...`);
        const receipt: TransactionReceipt | null = await txResponse.wait(1);

        if (!receipt) throw new Error(`Commit transaction ${txResponse.hash} confirmation timed out or receipt was null.`);
        console.log(`[Timelock Service Context: ${logContext}] Commit Tx Confirmed. Status: ${receipt.status}, Block: ${receipt.blockNumber}`);
        if (receipt.status !== 1) throw new Error(`Commit transaction ${txResponse.hash} failed on-chain (Status: 0). Check explorer.`);

        // 4. Parse Blocklock Request ID from logs emitted by *our* contract
        const eventInterface = commitmentContract.interface.getEvent('VerdictCommitted');
        const eventTopic = eventInterface.topicHash;
        const receiptLogs = receipt.logs || []; // Ensure logs is an array
        const log = receiptLogs.find((l: Log) =>
            l.topics[0] === eventTopic &&
            l.address.toLowerCase() === KINTASK_COMMITMENT_CONTRACT_ADDRESS.toLowerCase()
        );

        if (!log) throw new Error(`Could not find VerdictCommitted event log in transaction receipt for ${txResponse.hash}.`);

        const decodedLog = commitmentContract.interface.parseLog({ topics: [...log.topics], data: log.data });
        const blocklockRequestId = decodedLog?.args.blocklockRequestId?.toString();
        if (!blocklockRequestId) throw new Error('Failed to decode Blocklock Request ID from VerdictCommitted event.');

        console.log(`[Timelock Service Context: ${logContext}] Successfully committed. Blocklock Request ID: ${blocklockRequestId}`);

        // Store mapping for the listener
        if (requestContext) {
            if (blocklockIdToRequestContext.size >= MAX_CONTEXT_MAP_SIZE) {
                const oldestKey = blocklockIdToRequestContext.keys().next().value;
                 blocklockIdToRequestContext.delete(oldestKey);
                 console.warn(`[Timelock Service] Context map size limit reached, removed oldest entry: ${oldestKey}`);
            }
            blocklockIdToRequestContext.set(blocklockRequestId, requestContext);
            console.log(`[Timelock Service] Mapped Blocklock ID ${blocklockRequestId} to Context ${requestContext}`);
        } else {
             console.warn("[Timelock Service] Request context not provided for mapping reveal listener.");
        }

        return {
            requestId: blocklockRequestId,
            txHash: txResponse.hash,
            ciphertextHash: ciphertextHash
        };

    } catch (error: any) {
        console.error(`[Timelock Service Error Context: ${logContext}] Error during commit:`, error.message);
        if (txResponse?.hash) console.error(`[Timelock Service] Failing Transaction Hash: ${txResponse.hash}`);
        return null; // Indicate failure
    }
}

// --- Reveal Listener ---
export function startRevealListener() {
    if (revealListenerAttached) {
        // console.log("[Timelock Service] Reveal listener already attached.");
        return;
    }
     // Ensure initialized before attaching listener
     if (!isTimelockInitialized || !commitmentContract) {
         console.warn("[Timelock Service] Cannot start listener, service not fully initialized yet.");
         // Initialization might still be in async checks, listener will start when/if init completes.
         return;
     }

    console.log(`[Timelock Service] Attaching listener for VerdictRevealed events on contract ${KINTASK_COMMITMENT_CONTRACT_ADDRESS}...`);
    try {
        const eventFilter = commitmentContract.filters.VerdictRevealed();

         // Using commitmentContract.on() sets up a persistent listener
         commitmentContract.on(eventFilter, async (requestIdBigInt, requester, revealedVerdictBytes, eventLog) => {
            // Type assertion for ethers v6 EventLog
            const log = eventLog as unknown as EventLog;
            const blocklockRequestId = requestIdBigInt.toString();
            const txHash = log.transactionHash; // Tx hash where the Blocklock callback happened

            console.log(`\n[Timelock Listener] === Received VerdictRevealed Event ===`);
            console.log(`  Blocklock Request ID: ${blocklockRequestId}`);
            console.log(`  Event Source Tx Hash: ${txHash}`); // This is the Blocklock callback tx hash

             // Find the original request context using the mapping
             const requestContext = blocklockIdToRequestContext.get(blocklockRequestId);
             if (!requestContext) {
                 console.warn(`[Timelock Listener] Could not find request context for revealed Blocklock ID: ${blocklockRequestId}. Cannot log details to Recall.`);
                 // It's possible the context map was cleared or this ID was processed already
                 return;
             }
             console.log(`  Associated Request Context: ${requestContext}`);

             // Clean up the mapping immediately to prevent reprocessing
             blocklockIdToRequestContext.delete(blocklockRequestId);

             try {
                // Decode the revealed verdict bytes (assuming it was encoded as a string)
                const encoder = AbiCoder.defaultAbiCoder();
                const [revealedVerdict] = encoder.decode(['string'], revealedVerdictBytes);

                console.log(`[Timelock Listener] Decoded Verdict for context ${requestContext}: "${revealedVerdict}"`);

                // Log this reveal event to Recall Service under the original request context
                await logRecallEvent(
                    'TIMELOCK_REVEAL_RECEIVED',
                    { blocklockRequestId, revealedVerdict, sourceTxHash: txHash, requester },
                    requestContext
                );
                console.log(`[Timelock Listener] Logged TIMELOCK_REVEAL_RECEIVED to Recall for context ${requestContext}`);

                // TODO: Compare revealedVerdict with final calculated verdict from verifierService state?

             } catch(decodeError: any) {
                console.error(`[Timelock Listener] Error decoding revealed verdict for ID ${blocklockRequestId}, Context ${requestContext}:`, decodeError.message);
                // Log decode error to recall
                 await logRecallEvent(
                    'VERIFICATION_ERROR',
                    { stage: 'TimelockRevealDecode', error: decodeError.message, blocklockRequestId, rawBytes: ethers.hexlify(revealedVerdictBytes) },
                    requestContext
                );
             }
         });

        revealListenerAttached = true;
        console.log("[Timelock Service] Listener attached successfully.");

    } catch (error: any) {
        console.error("[Timelock Service] Failed to attach listener:", error.message);
        revealListenerAttached = false;
    }
}

// Function to stop listener (e.g., on shutdown)
export function stopRevealListener() {
     if (revealListenerAttached && commitmentContract) {
         console.log("[Timelock Service] Removing VerdictRevealed listener...");
         try {
             // Use off() or removeAllListeners() depending on specific needs and ethers version guarantees
             commitmentContract.off("VerdictRevealed"); // Attempt to remove specific listener type
             // Alternatively: commitmentContract.removeAllListeners("VerdictRevealed");
             revealListenerAttached = false;
             console.log("[Timelock Service] Listener removed.");
         } catch (error: any) {
             console.error("[Timelock Service] Error removing listener:", error.message);
             revealListenerAttached = false;
         }
     } else {
          // console.log("[Timelock Service] Listener not attached or contract not initialized.");
     }
}
===== ./services/verifierService.ts =====
import {
    KnowledgeFragment,
    VerificationResultInternal,
    RecallLogEntryData,
    RecallEventType,
    VerificationStatus
} from '../types';
import { fetchKnowledgeFragment, getKnowledgeIndex } from './filecoinService';
import { commitVerdictTimelocked } from './timelockService';
import { logRecallEvent } from './recallService';
import { truncateText } from '../utils'; // Import utility
import config from '../config'; // Import config to check if timelock is configured

// --- Helper Function ---
const addStep = async (
    reasoningSteps: RecallLogEntryData[],
    requestContext: string,
    type: RecallEventType,
    details: Record<string, any>
) => {
    const timestamp = new Date().toISOString();
    // Simple truncation for potentially large values in logs
    const truncatedDetails = Object.entries(details).reduce((acc, [key, value]) => {
        try {
            if (typeof value === 'string') {
                acc[key] = truncateText(value, 250); // Truncate long strings
            } else if (Array.isArray(value) && value.length > 15) {
                 acc[key] = value.slice(0, 15).concat(['...truncated...']); // Truncate long arrays
            } else if (key === 'stack') { // Don't stringify stack traces if too long
                 acc[key] = truncateText(value?.toString(), 300);
            } else if (typeof value === 'object' && value !== null && JSON.stringify(value).length > 300) {
                 acc[key] = { _truncated: true, keys: Object.keys(value).slice(0,5) }; // Truncate large objects
            } else if (typeof value === 'bigint') {
                 acc[key] = value.toString(); // Convert BigInts
            }
            else {
                acc[key] = value;
            }
        } catch (e) {
             acc[key] = `<<Error truncating value for key ${key}>>`; // Handle potential errors during truncation/stringification
        }
        return acc;
    }, {} as Record<string, any>);

    const stepData: RecallLogEntryData = { timestamp, type, details: truncatedDetails, requestContext };
    reasoningSteps.push(stepData);
    // Fire-and-forget logging to Recall
    logRecallEvent(type, truncatedDetails, requestContext).catch(err => {
        console.error(`[Verifier Service] Background logging to Recall failed for type ${type}:`, err.message);
    });
};


// --- Main Verification Logic Function ---
export async function performVerification(
    question: string,
    answer: string,
    requestContext: string // Identifier for this specific verification task
): Promise<VerificationResultInternal | null> {

    console.log(`[Verifier Service] Starting verification for context: ${requestContext}`);
    const reasoningSteps: RecallLogEntryData[] = [];
    let usedFragmentCids: string[] = []; // Track CIDs successfully fetched AND used in logic
    let preliminaryVerdict: VerificationStatus = 'Unverified';
    let confidenceScore = 0.5; // Start neutral
    let timelockDetails: Awaited<ReturnType<typeof commitVerdictTimelocked>> = null;

    try {
        // --- Step 1: Input Analysis & Keyword Extraction ---
        const questionLower = question.toLowerCase();
        const answerLower = answer.toLowerCase();
        const stopWords = new Set(['the', 'a', 'an', 'is', 'of', 'in', 'on', 'at', 'to', 'for', 'and', 'or', 'what', 'who', 'where', 'when', 'why', 'how', 'tell', 'me', 'about', 'can', 'you', 'please', 'i', 'it', 'my', 'your']);
        const keywords = [...new Set(
            questionLower.split(/\s+/) // Split by whitespace
                .map(word => word.replace(/[^\w]/g, '').trim()) // Remove punctuation
                .filter(word => word.length >= 3 && !stopWords.has(word)) // Filter length and stopwords
        )];
        await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { step: 'AnalyzeInput', extractedKeywords: keywords });

        // --- Step 2: Fetch Index & Relevant CIDs ---
        await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_ATTEMPT', { stage: 'Index', keywords });
        const index = await getKnowledgeIndex(); // Fetches from cache or network
        let relevantCids: string[] = [];
        if (index) {
            keywords.forEach(kw => {
                if (index[kw]) relevantCids.push(...index[kw]);
            });
            relevantCids = [...new Set(relevantCids)]; // Deduplicate CIDs
            await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_SUCCESS', { stage: 'Index', foundCidsCount: relevantCids.length });
        } else {
            await addStep(reasoningSteps, requestContext, 'VERIFICATION_ERROR', { stage: 'IndexFetch', error: 'Failed to retrieve knowledge index' });
             console.error("[Verifier Service] Failed to retrieve knowledge index. Verification quality may be reduced.");
             // Decide whether to throw or continue. Let's continue for robustness.
        }

        // Limit number of fragments to fetch/process for performance in MVP
        const MAX_FRAGMENTS_TO_PROCESS = 10;
        const cidsToFetch = relevantCids.slice(0, MAX_FRAGMENTS_TO_PROCESS);
        if (relevantCids.length > MAX_FRAGMENTS_TO_PROCESS) {
             await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { warning: 'Too many relevant fragments found', count: relevantCids.length, processingLimit: MAX_FRAGMENTS_TO_PROCESS });
        }


        // --- Step 3: Fetch KG Fragments Concurrently ---
        await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_ATTEMPT', { stage: 'Fragments', cidsToFetchCount: cidsToFetch.length });
        const fetchPromises = cidsToFetch.map(cid =>
            fetchKnowledgeFragment(cid).then(fragment => ({ cid, fragment }))
        );
        const fetchedResults = await Promise.all(fetchPromises);

        const fetchedFragments: KnowledgeFragment[] = [];
        const successfullyFetchedCids = new Set<string>();
        const failedFetches: string[] = [];
        fetchedResults.forEach(result => {
            if (result.fragment) {
                fetchedFragments.push(result.fragment);
                successfullyFetchedCids.add(result.cid);
            } else {
                failedFetches.push(result.cid);
            }
        });
        await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_SUCCESS', { stage: 'Fragments', fetchedCount: fetchedFragments.length, failedCidsCount: failedFetches.length });


        // --- Step 4: Apply Verification Logic ---
        if (fetchedFragments.length === 0 && relevantCids.length > 0) {
             // If index found CIDs but fetching failed for all relevant ones
             console.warn(`[Verifier Service] No relevant knowledge fragments could be fetched for context ${requestContext}, although index suggested ${relevantCids.length}.`);
             await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { warning: 'No fragments fetched despite finding relevant CIDs', failedCids });
             preliminaryVerdict = 'Unverified'; // Cannot verify without data
             confidenceScore = 0.1; // Very low confidence
        } else if (fetchedFragments.length === 0 && relevantCids.length === 0) {
             // If index found no relevant CIDs
              console.log(`[Verifier Service] No relevant knowledge fragments found in index for context ${requestContext}.`);
              await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { info: 'No relevant fragments found in index' });
              preliminaryVerdict = 'Unverified';
              confidenceScore = 0.3; // Slightly higher confidence than fetch failure
        }
        else {
            // Apply logic only if fragments were fetched
            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { step: 'ApplyVerificationLogic', fragmentCount: fetchedFragments.length });
            let supportingScore = 0;
            let contradictingScore = 0;
            let uncertaintyFlags = 0;
            let provenanceIssues = 0;
            const fragmentsUsedInLogic: string[] = [];

            for (const fragment of fetchedFragments) {
                const fragmentId = fragment.fragment_id || `cid:${fragment.previous_version_cid?.substring(0, 8) ?? truncateText([...successfullyFetchedCids][fragmentsUsedInLogic.length], 8)}`;
                fragmentsUsedInLogic.push(fragmentId);

                try {
                    const fragmentConf = fragment.provenance?.confidence_score ?? 0.7;

                    // A) Uncertainty Check
                    if (fragmentConf < 0.4) {
                        uncertaintyFlags++;
                        await addStep(reasoningSteps, requestContext, 'PROVENANCE_CHECK', { check: 'LowConfidenceSource', fragmentId, score: fragmentConf });
                    }

                    // B) Fact Matching Logic (Simple Placeholder)
                    if (fragment.type === 'factual_statement' && fragment.content?.subject && fragment.content?.object) {
                        const subject = fragment.content.subject.toLowerCase();
                        const objectVal = fragment.content.object.toLowerCase();
                        if ((keywords.includes(subject) || questionLower.includes(subject)) && answerLower.includes(objectVal)) {
                            supportingScore += fragmentConf;
                            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { check: 'FactMatch', fragmentId, outcome: 'Support', score: fragmentConf });
                        }
                    }

                    // C) Provenance Checks (Recency Example)
                    if (fragment.provenance?.timestamp_created) {
                        const createdDate = new Date(fragment.provenance.timestamp_created);
                        const ageDays = (Date.now() - createdDate.getTime()) / (1000 * 3600 * 24);
                        if (ageDays > 730) {
                            provenanceIssues++;
                            await addStep(reasoningSteps, requestContext, 'PROVENANCE_CHECK', { check: 'Age', fragmentId, ageDays: Math.round(ageDays), outcome: 'Very Stale (>2yr)' });
                        }
                    }

                    // D) Cross-Chain Attestation Check (Simulated Pass)
                     const attestations = fragment.provenance?.external_attestations;
                      if (attestations && attestations.length > 0) {
                          supportingScore += 0.1 * attestations.length; // Small boost
                          await addStep(reasoningSteps, requestContext, 'CROSSCHAIN_CHECK', { check: 'AttestationExists', fragmentId, count: attestations.length, outcome: 'BoostedConfidence(Simulated)' });
                      }

                } catch (logicError: any) {
                     console.error(`[Verifier Service] Error processing fragment ${fragmentId} for context ${requestContext}: ${logicError.message}`);
                     await addStep(reasoningSteps, requestContext, 'VERIFICATION_ERROR', { stage: 'LogicExecution', fragmentId, error: logicError.message });
                }
            } // End fragment loop

            usedFragmentCids = fragmentsUsedInLogic; // Update based on actual usage

            // Determine Preliminary Verdict
            confidenceScore = 0.5 + (supportingScore - contradictingScore) * 0.5 - (provenanceIssues * 0.05) - (uncertaintyFlags * 0.2);
            confidenceScore = Math.max(0.01, Math.min(0.99, confidenceScore)); // Clamp

            if (uncertaintyFlags > 0) preliminaryVerdict = 'Flagged: Uncertain';
            else if (contradictingScore > supportingScore * 1.5) preliminaryVerdict = 'Flagged: Contradictory';
            else if (supportingScore > 0.5 && confidenceScore > 0.65) preliminaryVerdict = 'Verified';
            else preliminaryVerdict = 'Unverified';

            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', {
                step: 'LogicComplete',
                calculatedVerdict: preliminaryVerdict,
                calculatedConfidence: confidenceScore,
                supportingScore: supportingScore.toFixed(2),
                contradictoryScore: contradictoryScore.toFixed(2),
                uncertaintyFlags, provenanceIssues
            });
        } // End of else block (if fragments were fetched)


        // --- Step 5: Timelock Commit ---
        // Check if contract address is configured before attempting commit
        if (config.kintaskContractAddress && config.blocklockSenderProxyAddress) {
            await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_ATTEMPT', { verdictToCommit: preliminaryVerdict });
            if (!preliminaryVerdict.startsWith('Error:')) { // Only commit if no prior critical error
                timelockDetails = await commitVerdictTimelocked(preliminaryVerdict, 5, requestContext);
                if (timelockDetails) {
                    await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_SUCCESS', {
                        requestId: timelockDetails.requestId,
                        txHash: timelockDetails.txHash,
                        ciphertextHash: timelockDetails.ciphertextHash,
                        committedVerdict: preliminaryVerdict
                    });
                } else {
                    await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_FAILURE', { error: 'commitVerdictTimelocked returned null or failed' });
                    preliminaryVerdict = 'Error: Timelock Failed'; // Update status
                    confidenceScore = 0; // Reset confidence
                }
            } else {
                console.warn(`[Verifier Service] Skipping timelock commit due to prior error status: ${preliminaryVerdict}`);
                await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_FAILURE', { reason: 'Skipped due to prior error', priorStatus: preliminaryVerdict });
            }
        } else {
            console.warn(`[Verifier Service] Skipping timelock commit: KINTASK_CONTRACT_ADDRESS or BLOCKLOCK_SENDER_PROXY_ADDRESS not configured.`);
            await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_FAILURE', { reason: 'Skipped: Contract/Proxy address not configured' });
        }


        // --- Step 6: Final Result Object ---
        const finalResult: VerificationResultInternal = {
            finalVerdict: preliminaryVerdict,
            confidenceScore: parseFloat(confidenceScore.toFixed(2)), // Format confidence
            usedFragmentCids: usedFragmentCids,
            reasoningSteps: reasoningSteps, // Return collected steps for controller
            timelockRequestId: timelockDetails?.requestId,
            timelockCommitTxHash: timelockDetails?.txHash,
            ciphertextHash: timelockDetails?.ciphertextHash
        };

        console.log(`[Verifier Service] Verification complete for context ${requestContext}. Verdict: ${finalResult.finalVerdict}, Confidence: ${finalResult.confidenceScore}`);
        return finalResult;

    } catch (error: any) {
        console.error(`[Verifier Service Error Request: ${requestContext}]:`, error.message, error.stack);
        await addStep(reasoningSteps, requestContext, 'VERIFICATION_ERROR', { error: error.message, stage: 'TopLevelCatch' });
        // Return a consistent error state result
         return {
             finalVerdict: 'Error: Verification Failed',
             confidenceScore: 0,
             usedFragmentCids: usedFragmentCids,
             reasoningSteps: reasoningSteps,
             timelockRequestId: timelockDetails?.requestId,
             timelockCommitTxHash: timelockDetails?.txHash,
             ciphertextHash: timelockDetails?.ciphertextHash
         };
    }
}
===== ./types/index.ts =====
// --- Knowledge Fragment Structure (Stored on Filecoin) ---
export interface KnowledgeFragmentProvenance {
  source_type: string; // e.g., 'dataset_snapshot', 'web_scrape', 'human_curated', 'api_call'
  source_name?: string;
  source_cid?: string; // CID of larger dataset if applicable
  source_url?: string; // URL if scraped
  curation_method?: string;
  curator_id?: string; // e.g., DID
  timestamp_created: string; // ISO 8601
  confidence_score?: number; // 0.0 to 1.0
  external_attestations?: ExternalAttestation[];
}

export interface ExternalAttestation {
    chain: string; // e.g., 'Optimism', 'BaseSepolia'
    type: string; // e.g., 'EAS', 'Verax'
    schema_uid?: string;
    attestation_uid?: string; // Linkable UID on the attestation network
    attestation_data?: Record<string, any>; // Parsed data if relevant
}

export interface KnowledgeFragment {
  fragment_id: string; // Unique identifier for this version
  type: string; // e.g., 'factual_statement', 'rule', 'definition'
  keywords?: string[]; // For indexing
  content: Record<string, any>; // The actual data/fact/rule
  provenance: KnowledgeFragmentProvenance;
  version: number;
  previous_version_cid?: string | null;
}

// --- Verification & Recall ---
export type VerificationStatus =
    | 'Verified'
    | 'Unverified'
    | 'Flagged: Uncertain'
    | 'Flagged: Contradictory'
    | 'Error: Verification Failed'
    | 'Error: Timelock Failed';

// Result returned internally by the Verifier Service
export interface VerificationResultInternal {
  finalVerdict: VerificationStatus;
  confidenceScore: number; // Overall confidence
  usedFragmentCids: string[]; // List of Filecoin CIDs actually used
  reasoningSteps: RecallLogEntryData[]; // Detailed steps taken
  timelockRequestId?: string; // Blocklock on-chain request ID
  timelockCommitTxHash?: string; // L2 Tx hash for the commit
  ciphertextHash?: string; // Hash of the committed ciphertext
}

// --- Recall Logging ---
export type RecallEventType =
    | 'VERIFICATION_START'
    | 'KNOWLEDGE_FETCH_ATTEMPT'
    | 'KNOWLEDGE_FETCH_SUCCESS' // Log CIDs fetched
    | 'TIMELOCK_COMMIT_ATTEMPT'
    | 'TIMELOCK_COMMIT_SUCCESS' // Log Request ID, Ciphertext Hash, Tx Hash
    | 'TIMELOCK_COMMIT_FAILURE'
    | 'REASONING_STEP' // Log rule/fact applied, CID used, outcome
    | 'PROVENANCE_CHECK' // Log check on provenance data
    | 'CROSSCHAIN_CHECK' // Log check on external attestation
    | 'FINAL_VERDICT_CALCULATED' // Log verdict before reveal check
    | 'TIMELOCK_REVEAL_RECEIVED' // Log revealed verdict, check match
    | 'VERIFICATION_COMPLETE'
    | 'VERIFICATION_ERROR'
    | 'GENERATOR_MOCK_USED'; // Added for mock logging

// Structure for data field in Recall log entries
export interface RecallLogEntryData {
  timestamp: string;
  type: RecallEventType;
  details: Record<string, any>; // Context-specific details for each event type
  requestContext?: string; // Identifier for the overall Q&A request
}

// --- API Response Structure (Controller to Frontend) ---
export interface ApiVerifyResponse {
  answer: string;
  status: VerificationStatus;
  confidence?: number;
  usedFragmentCids?: string[];
  timelockRequestId?: string;
  timelockTxExplorerUrl?: string; // Link to L2 explorer for commit Tx
  recallTrace?: RecallLogEntryData[]; // Snippets or full trace for this request
  recallExplorerUrl?: string; // Link to Recall explorer if available
  error?: string; // Optional error message for frontend display
  details?: string; // Optional error details
}
===== ./utils/blocklock-js.d.ts =====
// packages/backend/src/types/blocklock-js.d.ts

/**
 * Placeholder type definitions for 'blocklock-js'.
 * Replace with more specific types if known or provided by the library later.
 * Based on usage in timelockService.ts and Blocklock documentation examples.
 */
declare module 'blocklock-js' {

    // Assuming TypesLib.Ciphertext structure based on Solidity usage
    // This might need adjustments based on the actual JS object structure
    export namespace TypesLib {
      export interface Ciphertext {
        v: Uint8Array | string; // Or Buffer? Usually bytes represented as hex string or Uint8Array
        r: Uint8Array | string;
        s: Uint8Array | string;
        u: [string, string] | [bigint, bigint]; // Point coordinates (often strings or BigInts)
        ephKey?: any; // Optional/Internal? Check library details
      }
    }
  
    // Placeholder for the result of encodeCiphertextToSolidity
    // Based on contract expectation, it's likely a tuple/struct matching Solidity's TypesLib.Ciphertext
    export type SolidityCiphertextStruct = {
       v: string; // Hex string for bytes
       r: string; // Hex string for bytes32 or similar
       s: string; // Hex string for bytes32 or similar
       u: [string, string]; // String tuple for uint256[2]
       // Adjust types based on actual Solidity struct definition
    };
  
    // Main Blocklock class
    export class Blocklock {
      constructor(wallet: any, blocklockSenderProxyAddress: string); // Use 'any' for wallet initially
  
      // Encrypt method signature based on usage
      encrypt(messageBytes: Uint8Array | Buffer, blockHeight: bigint): TypesLib.Ciphertext;
  
      // Decrypt method (if used in JS, based on docs) - Check return type
      decryptWithId(requestId: string | number | bigint): Promise<Uint8Array | Buffer | string>; // Adjust return type
    }
  
    // SolidityEncoder class (if used - based on docs)
    export class SolidityEncoder {
      constructor();
      // Add specific methods if known, otherwise keep it simple
      // Example based on docs:
      encodeUint256(value: bigint | string): string; // Returns hex string likely
      // encodeString(value: string): string;
      // encodeBytes(value: Uint8Array | Buffer | string): string;
      // ... other encoding methods
    }
  
    // Function to convert JS Ciphertext object to Solidity struct/tuple format
    export function encodeCiphertextToSolidity(ciphertext: TypesLib.Ciphertext): SolidityCiphertextStruct; // Adjust return type if needed
  
    // Add other exports from the library if you use them
  }===== ./utils/index.ts =====
import config from '../config';

// Example utility: Build L2 Explorer URL based on configured RPC URL heuristics
export function getL2ExplorerUrl(txHash: string): string | undefined {
    const rpcUrl = config.l2RpcUrl?.toLowerCase() || '';
    if (!rpcUrl || !txHash) return undefined;

    // Add more mappings as needed for supported testnets/mainnets
    if (rpcUrl.includes('base-sepolia') || rpcUrl.includes('84532')) {
        return `https://sepolia.basescan.org/tx/${txHash}`;
    }
    if (rpcUrl.includes('optimism-sepolia') || rpcUrl.includes('11155420')) {
        return `https://sepolia-optimism.etherscan.io/tx/${txHash}`;
    }
     if (rpcUrl.includes('arbitrum-sepolia') || rpcUrl.includes('421614')) {
         return `https://sepolia.arbiscan.io/tx/${txHash}`;
     }
    // Add Polygon Amoy, etc.
    if (rpcUrl.includes('polygon-amoy') || rpcUrl.includes('80002')) {
        return `https://www.oklink.com/amoy/tx/${txHash}`;
    }

    console.warn(`[Utils] No block explorer URL configured for RPC: ${rpcUrl}`);
    return undefined; // Return undefined if no match
}

// Add other shared utility functions here, e.g., text truncation, basic NLP helpers
export function truncateText(text: string | undefined | null, maxLength: number): string {
    if (!text) return '';
    if (text.length <= maxLength) return text;
    return text.substring(0, maxLength - 3) + '...';
}
===== ./src/routes/verify.ts =====
import { Router } from 'express';
import { handleVerifyRequest } from '../controllers/verifyController';

const router = Router();

/**
 * @route POST /api/verify
 * @description Endpoint to receive a question, generate an answer, verify it,
 *              commit the verdict via timelock, log the process to Recall,
 *              and return the results.
 * @body { "question": "string" } - The user's question. Max length ~1500 chars recommended.
 * @returns {ApiVerifyResponse} 200 - Success response with answer, status, proofs.
 * @returns {object} 400 - Invalid request body (missing question, too long, etc.).
 * @returns {object} 500 - Internal server error during processing.
 */
router.post('/verify', handleVerifyRequest);

export default router;
===== ./src/server.ts =====
import express, { Express, Request, Response, NextFunction } from 'express';
import cors from 'cors';
import config from './config';
import verifyRoutes from './routes/verify';
import { startRevealListener, stopRevealListener } from './services/timelockService'; // Import listener controls

const app: Express = express();
const port = config.port;

// --- Middleware ---
app.use(cors()); // Allow requests from frontend (configure origins for production)
app.use(express.json({ limit: '1mb' })); // Parse JSON request bodies, limit size
app.use((req: Request, res: Response, next: NextFunction) => {
    const start = Date.now();
    res.on('finish', () => {
         const duration = Date.now() - start;
         console.log(`[${new Date().toISOString()}] ${req.method} ${req.originalUrl} ${res.statusCode} ${duration}ms`);
    });
    next();
});

// --- Routes ---
app.use('/api', verifyRoutes);

// Root Route / Health Check
app.get('/', (req: Request, res: Response) => {
  res.status(200).json({ status: 'ok', message: 'Kintask Backend is running!'});
});

// --- 404 Handler ---
// Catch-all for routes not defined
app.use((req, res, next) => {
    res.status(404).json({ error: 'Not Found', message: `Endpoint ${req.method} ${req.path} does not exist.` });
});


// --- Global Error Handler ---
// Catches errors passed via next(error)
app.use((err: Error, req: Request, res: Response, next: NextFunction) => {
  console.error("[Global Error Handler]:", err.stack || err);
  // Avoid sending stack trace in production
  const message = process.env.NODE_ENV === 'production' ? 'An unexpected error occurred.' : err.message;
  res.status(500).json({
      error: 'Internal Server Error',
      message: message,
  });
});

// --- Start Server ---
const server = app.listen(port, () => {
  console.log(`[server]: Kintask Backend server is running at http://localhost:${port}`);
  // Initialize Timelock Listener on startup
  try {
      startRevealListener();
  } catch (listenerError) {
       console.error("[Server Startup] Failed to start Timelock listener:", listenerError);
  }
});

// --- Graceful Shutdown ---
const gracefulShutdown = (signal: string) => {
    console.log(`\n${signal} signal received: closing HTTP server...`);
    // Stop listener first
    stopRevealListener();
    server.close(() => {
        console.log('HTTP server closed.');
        // Perform other cleanup if needed (e.g., DB connections)
        console.log("Exiting process.");
        process.exit(0);
    });

    // Force close server after a timeout if graceful shutdown fails
     setTimeout(() => {
         console.error('Could not close connections in time, forcefully shutting down');
         process.exit(1);
     }, 10000); // 10 seconds timeout
};

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT')); // Catches Ctrl+C
===== ./src/services/filecoinService.ts =====
// kintask/packages/backend/src/services/filecoinService.ts

import axios, { AxiosError } from 'axios';
import config from '../config'; // Import configuration to get gateway URL and index CID
import { KnowledgeFragment } from '../types'; // Import the structure definition

// --- Configuration ---
// Use the gateway specified in config, defaulting to a reliable public one (w3s.link)
const IPFS_GATEWAY = config.ipfsGatewayUrl || 'https://w3s.link/ipfs/';
const MAX_RETRIES = 3; // Number of retry attempts for failed fetches
const RETRY_DELAY_MS = 800; // Initial delay before retrying (will increase exponentially)
const REQUEST_TIMEOUT = 25000; // Timeout for each HTTP request in milliseconds (25 seconds)

console.log(`[Filecoin Service] Using IPFS Gateway for retrieval: ${IPFS_GATEWAY}`);

// Structure expected in the index file uploaded to Filecoin/Storacha
interface IndexFileStructure {
    createdAt: string;
    description?: string;
    fragmentsById?: Record<string, string>; // fragment_id -> cid map (optional)
    index: Record<string, string[]>; // keyword -> [cid] map - Primary index used
    indexRootCid?: string; // Optional: CID of the directory containing all fragments
}

// Simple in-memory cache with TTL (Time To Live) in milliseconds
interface CacheEntry<T> {
    data: T;
    timestamp: number; // When the data was cached
}
const cache = new Map<string, CacheEntry<any>>();
const CACHE_TTL_MS = 10 * 60 * 1000; // Cache validity duration (e.g., 10 minutes)

// --- Cache Utility Functions ---

/**
 * Stores data in the in-memory cache.
 * @param key - The cache key (typically the CID).
 * @param data - The data to store.
 */
function setCache<T>(key: string, data: T) {
    if (!key) return; // Do not cache with empty key
    cache.set(key, { data, timestamp: Date.now() });
    // console.log(`[Cache] Set cache for key: ${key.substring(0,10)}...`);
}

/**
 * Retrieves data from the cache if it exists and is not expired.
 * @param key - The cache key (typically the CID).
 * @returns The cached data or null if not found or expired.
 */
function getCache<T>(key: string): T | null {
    if (!key) return null;
    const entry = cache.get(key);
    if (entry && (Date.now() - entry.timestamp < CACHE_TTL_MS)) {
        // console.log(`[Cache] Hit for key: ${key.substring(0,10)}...`);
        return entry.data as T;
    }
    // console.log(`[Cache] Miss or expired for key: ${key.substring(0,10)}...`);
    cache.delete(key); // Remove expired or non-existent entry
    return null;
}

// --- Core Fetching Logic ---

/**
 * Fetches data from the configured IPFS gateway with caching and retry logic.
 * @param url - The full URL to fetch from the gateway.
 * @param cacheKey - The key to use for caching (typically the CID).
 * @returns The fetched data (parsed as JSON if applicable) or null if fetch fails.
 */
async function fetchWithRetry<T>(url: string, cacheKey: string): Promise<T | null> {
    // 1. Check Cache first
    const cachedData = getCache<T>(cacheKey);
    if (cachedData) {
        return cachedData;
    }

    console.log(`[Filecoin Service] Fetching: ${url} (Cache Key: ${cacheKey.substring(0,10)}...)`);

    // 2. Attempt Fetch with Retries
    for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
        try {
            const response = await axios.get<T>(url, {
                timeout: REQUEST_TIMEOUT,
                // Ensure correct headers for potentially receiving JSON
                headers: {
                    'Accept': 'application/json, application/octet-stream, */*',
                    // 'User-Agent': 'KintaskBackend/1.0' // Optional: Identify your client
                 }
             });

            // Check content type for JSON if expecting it (primarily for fragments/index)
            const contentType = response.headers['content-type'];
            const isJsonExpected = url.includes(config.knowledgeBaseIndexCid || 'INVALID_CID') || cacheKey !== config.knowledgeBaseIndexCid; // Assume fragments & index are JSON

            if (isJsonExpected && (!contentType || !contentType.includes('application/json'))) {
                // Gateways sometimes return HTML error pages or non-JSON for DAG issues
                console.warn(`[Filecoin Service] Attempt ${attempt} for ${cacheKey}: Expected JSON but received Content-Type: ${contentType}. Raw data sample:`, typeof response.data === 'string' ? response.data.substring(0, 100) + '...' : typeof response.data);
                // Treat non-JSON response as an error for expected JSON content
                 throw new Error(`Expected JSON content, but received ${contentType || 'unknown content type'}`);
            }

            // Check for successful status code
            if (response.status === 200 && response.data) {
                console.log(`[Filecoin Service] Successfully fetched ${cacheKey.substring(0,10)}... (Attempt ${attempt})`);
                setCache(cacheKey, response.data); // Cache the successful response
                return response.data;
            } else {
                // Log unexpected success status codes (e.g., 204 No Content?)
                console.warn(`[Filecoin Service] Fetch attempt ${attempt} for ${cacheKey} returned unexpected status: ${response.status}`);
                // Continue to retry loop
            }

        } catch (error: any) {
            const axiosError = error as AxiosError;
            console.warn(`[Filecoin Service] Error fetch attempt ${attempt}/${MAX_RETRIES} for ${cacheKey}:`, axiosError.message);

            // Log details from the error response if available
            if (axiosError.response) {
                 console.warn(`  Gateway Response Status: ${axiosError.response.status}`);
                 // console.warn(`  Gateway Response Headers:`, axiosError.response.headers); // Can be verbose
                 // console.warn(`  Gateway Response Data:`, axiosError.response.data); // Can be verbose/large

                 // Don't retry on 404 Not Found - the content likely doesn't exist
                 if (axiosError.response.status === 404) {
                      console.error(`[Filecoin Service] CID ${cacheKey} not found on gateway (404). Stopping retries.`);
                      return null; // Indicate definitively not found
                 }
                 // Consider stopping retries on other client errors (4xx) too?
            } else if (axiosError.code === 'ECONNABORTED' || axiosError.message.includes('timeout')) {
                console.warn(`  Gateway request timed out.`);
            }

            // If it's the last attempt, log final failure and return null
            if (attempt === MAX_RETRIES) {
                console.error(`[Filecoin Service] Final fetch attempt failed for CID: ${cacheKey} after ${MAX_RETRIES} tries.`);
                return null;
            }

            // Wait before retrying with exponential backoff
            const delay = RETRY_DELAY_MS * Math.pow(2, attempt - 1); // 1s, 2s, 4s...
            console.log(`  Retrying in ${delay}ms...`);
            await new Promise(resolve => setTimeout(resolve, delay));
        }
    }

    // Should not be reached if error handling above is correct, but acts as a fallback
    console.error(`[Filecoin Service] Fetch failed unexpectedly for ${cacheKey} after all attempts.`);
    return null;
}

// --- Exported Service Functions ---

/**
 * Fetches and parses the Knowledge Graph index file from Filecoin/IPFS.
 * @returns The keyword-to-CID index object, or null if fetching fails.
 */
export async function getKnowledgeIndex(): Promise<IndexFileStructure['index'] | null> {
    const indexCid = config.knowledgeBaseIndexCid;
    if (!indexCid) {
        console.error('[Filecoin Service] FATAL ERROR: KB_INDEX_CID is not configured in backend .env.');
        return null;
    }

    const url = `${IPFS_GATEWAY}${indexCid}`;
    console.log(`[Filecoin Service] Getting Knowledge Index (CID: ${indexCid.substring(0,10)}...)`);
    const indexFile = await fetchWithRetry<IndexFileStructure>(url, indexCid); // Use index CID as cache key

    if (indexFile && typeof indexFile.index === 'object' && indexFile.index !== null) {
         // Optional: Log how many keywords are in the loaded index
         console.log(`[Filecoin Service] Successfully loaded index with ${Object.keys(indexFile.index).length} keywords.`);
         return indexFile.index;
    } else {
         console.error(`[Filecoin Service] Failed to fetch or parse index file structure from CID: ${indexCid}`);
         return null;
    }
}

/**
 * Fetches and parses a single Knowledge Fragment JSON object from Filecoin/IPFS using its CID.
 * @param cid - The Content Identifier (CID) of the fragment to fetch.
 * @returns The parsed KnowledgeFragment object, or null if fetching or parsing fails.
 */
export async function fetchKnowledgeFragment(cid: string): Promise<KnowledgeFragment | null> {
    // Basic CID format validation
    if (!cid || typeof cid !== 'string' || (!cid.startsWith('bafy') && !cid.startsWith('Qm'))) {
        console.error(`[Filecoin Service] Invalid CID format provided for fragment fetch: ${cid}`);
        return null;
    }

    const url = `${IPFS_GATEWAY}${cid}`;
    // Use fragment CID as the cache key
    const fragment = await fetchWithRetry<KnowledgeFragment>(url, cid);

    // Optional: Add schema validation here after fetching if needed
    // if (fragment && !isValidKnowledgeFragment(fragment)) {
    //     console.error(`[Filecoin Service] Fetched data for CID ${cid} is not a valid KnowledgeFragment.`);
    //     return null;
    // }

    return fragment;
}

// Optional: Add a function to clear the cache if needed for debugging
export function clearFilecoinCache() {
    console.log("[Filecoin Service] Clearing in-memory cache.");
    cache.clear();
}===== ./src/services/generatorService.ts =====
// kintask/packages/backend/src/services/generatorService.ts
import axios, { AxiosError } from 'axios'; // Using axios for HTTP requests
import config from '../config'; // Import configuration (includes API key)
import { logRecallEvent } from './recallService'; // Import recall logger for errors


const OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions";
const API_KEY = config.openRouterApiKey;

// --- Model Configuration ---
// ACTION REQUIRED: Choose a model available on OpenRouter.
// Check https://openrouter.ai/models for options and pricing.
// Using the free Mistral model as a default.
const MODEL_IDENTIFIER = "mistralai/mistral-7b-instruct:free";
// --- End Model Configuration ---

// --- Generation Parameters ---
const MAX_TOKENS = 250; // Max length of the generated response
const TEMPERATURE = 0.5; // Lower value = more deterministic, higher = more creative
const TOP_P = 0.9;      // Nucleus sampling
// --- End Generation Parameters ---

let isGeneratorInitialized = false;

function initializeGenerator() {
    if (isGeneratorInitialized) return;
    console.log("[Generator Service] Initializing OpenRouter configuration...");
    if (!API_KEY) {
        // This case should be caught by config.ts validation, but double-check
        console.error("[Generator Service] FATAL ERROR: OPENROUTER_API_KEY is not configured.");
        isGeneratorInitialized = false;
        return; // Prevent setting initialized flag
    }
     console.log(`[Generator Service] Configured to use OpenRouter model: ${MODEL_IDENTIFIER}`);
    isGeneratorInitialized = true;
}

// Ensure service is initialized before first use (lazy initialization)
// initializeGenerator(); // Call this explicitly in server startup if preferred


export async function generateAnswer(question: string, requestContext?: string): Promise<string> {
    if (!isGeneratorInitialized) initializeGenerator(); // Ensure initialized

    if (!API_KEY || !isGeneratorInitialized) {
        console.error("[Generator Service] OpenRouter API Key not configured or service failed initialization.");
        return "Error: AI answer generation service is not available."; // Return error string
    }
    if (!question || question.trim() === '') {
        console.warn("[Generator Service] Received empty question.");
        return "Error: Cannot generate answer for empty question.";
    }

    console.log(`[Generator Service Request: ${requestContext}] Requesting OpenRouter (${MODEL_IDENTIFIER}) answer...`);

    // --- Construct Payload for OpenRouter (OpenAI compatible format) ---
    const systemPrompt = 'You are Kintask, a helpful AI assistant. Provide concise, factual answers based on general knowledge. Avoid hedging or apologies.';
    const payload = {
        model: MODEL_IDENTIFIER,
        messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: question }
        ],
        max_tokens: MAX_TOKENS,
        temperature: TEMPERATURE,
        top_p: TOP_P,
        // stream: false, // Explicitly disable streaming for simple request/response
    };
    // --- End Payload Construction ---

    try {
        const response = await axios.post(
            OPENROUTER_API_URL,
            payload,
            {
                headers: {
                    'Authorization': `Bearer ${API_KEY}`,
                    'Content-Type': 'application/json',
                    // Recommended headers for OpenRouter analytics/tracking
                    'HTTP-Referer': `http://localhost:${config.port || 3001}`, // Use configured port
                    'X-Title': 'Kintask Hackathon', // Your App Name
                },
                timeout: 60000 // 60 second timeout for API call
            }
        );

        // --- Process OpenRouter Response ---
        const choice = response.data?.choices?.[0];
        const answer = choice?.message?.content?.trim();
        const finishReason = choice?.finish_reason;

        console.log(`[Generator Service Request: ${requestContext}] Finish Reason: ${finishReason || 'N/A'}`);

        if (finishReason === 'length') {
            console.warn(`[Generator Service Request: ${requestContext}] OpenRouter response truncated due to max_tokens limit.`);
            // Return the truncated answer, the user might still find it useful
        } else if (finishReason !== 'stop' && finishReason !== null) {
             console.warn(`[Generator Service Request: ${requestContext}] Unusual finish reason: ${finishReason}.`);
        }

        if (!answer) {
            console.warn(`[Generator Service Request: ${requestContext}] OpenRouter returned empty answer content. Response:`, JSON.stringify(response.data).substring(0, 200) + "...");
            // Check for explicit errors in the response structure
            const errorMsg = (response.data as any)?.error?.message || 'The AI model did not provide a valid text answer.';
            // Log this failure to Recall
             if (requestContext) {
                 logRecallEvent('VERIFICATION_ERROR', { step: 'GeneratorParse', error: errorMsg, responseData: response.data }, requestContext)
                    .catch(err => console.error("Error logging generator parse error to recall:", err));
             }
            return `Error: ${errorMsg}`;
        }
        // --- End Response Processing ---

        console.log(`[Generator Service Request: ${requestContext}] Received OpenRouter answer (truncated): "${answer.substring(0, 100)}..."`);
        return answer;

    } catch (error: any) {
        const axiosError = error as AxiosError;
        console.error(`[Generator Service Request: ${requestContext}] Error fetching answer from OpenRouter:`, axiosError.message);

        let detailedErrorMessage = axiosError.message;
        let responseDataForLog: any = null;

        if (axiosError.response) {
            console.error(`  Status: ${axiosError.response.status}`);
            const responseData = axiosError.response.data;
            responseDataForLog = responseData; // Log the actual response data if available
            console.error('  Response Data:', JSON.stringify(responseData).substring(0, 300) + "...");
            // Extract specific error message from OpenRouter/model if available
            detailedErrorMessage = (responseData as any)?.error?.message || `HTTP Error ${axiosError.response.status}`;
        } else if (axiosError.request) {
             console.error('  No response received from OpenRouter.');
             detailedErrorMessage = 'No response received from OpenRouter service.';
        } else {
             console.error('  Error setting up OpenRouter request:', error.message);
             detailedErrorMessage = `Request setup error: ${error.message}`;
        }

        // Log error details to Recall
        if (requestContext) {
            logRecallEvent('VERIFICATION_ERROR', { step: 'GeneratorAPI', error: detailedErrorMessage, responseData: responseDataForLog }, requestContext)
                .catch(err => console.error("Error logging generator API error to recall:", err));
        }

        return `Error: Could not retrieve answer from the AI model (${detailedErrorMessage.substring(0, 80)}...).`; // Return user-friendly error
    }
}===== ./src/services/recallService.ts =====
// recall.service.ts
import config from '../config';
import { RecallLogEntryData, RecallEventType } from '../types';
import { testnet } from '@recallnet/chains'; // Use the testnet chain definition
import { createWalletClient, http, parseEther, WalletClient, PublicClient, createPublicClient, ChainMismatchError } from 'viem';
import { privateKeyToAccount, Account } from 'viem/accounts';
// Assuming named exports based on example structure
import { RecallClient } from '@recallnet/sdk/client'; // Removed BucketManager import

// --- Module State ---
let recallClientInstance: RecallClient | null = null;
let isRecallInitialized = false;
let logBucketAddress = config.recallLogBucket || null; // Store the bucket address globally
let account: Account | null = null;
const RECALL_BUCKET_ALIAS = 'kintask-log-bucket-v1'; // Unique alias for this project's log bucket
let initPromise: Promise<RecallClient> | null = null; // To handle concurrent initializations

// --- Helper: Create Viem Wallet Client ---
function getWalletClient(): WalletClient {
    if (!config.recallPrivateKey) {
        throw new Error('Recall Private Key (PRIVATE_KEY in .env) is not configured.');
    }
    const formattedPrivateKey = config.recallPrivateKey.startsWith('0x')
        ? config.recallPrivateKey as `0x${string}`
        : `0x${config.recallPrivateKey}` as `0x${string}`;

    if (!account) { // Cache the account object
         account = privateKeyToAccount(formattedPrivateKey);
         console.log(`[Recall Service] Using wallet address: ${account.address} on chain ${testnet.id}`);
    }

    // Ensure the transport is configured for the correct chain
    return createWalletClient({
        account: account,
        chain: testnet, // Explicitly set Recall testnet chain
        transport: http(), // Default HTTP transport - Add RPC URL from testnet config if needed explicitly
                          // transport: http(testnet.rpcUrls.default.http[0]),
    });
}

 // --- Helper: Create Viem Public Client ---
 function getPublicClient(): PublicClient {
     return createPublicClient({
         chain: testnet, // Use Recall testnet chain
         transport: http(),
     });
 }


// --- Helper: Get or Initialize Recall Client (Singleton Pattern) ---
async function getRecallClient(): Promise<RecallClient> {
    if (recallClientInstance && isRecallInitialized) {
        return recallClientInstance;
    }
    // Prevent race conditions during initialization
    if (initPromise) {
        return initPromise;
    }

    initPromise = (async () => {
        console.log("[Recall Service] Initializing Recall Client (getRecallClient)...");
        try {
            const walletClient = getWalletClient(); // Get viem wallet client configured for Recall testnet
            const client = new RecallClient({ walletClient });

            // Basic check: Ensure client has account after initialization
            if (!client.walletClient.account?.address) {
                throw new Error("Failed to initialize client: Wallet address missing.");
            }
            console.log("[Recall Service] Recall Client Initialized successfully.");
            recallClientInstance = client;
            isRecallInitialized = true; // Mark as initialized
            initPromise = null; // Clear promise
            return client;
        } catch (error: any) {
            console.error("[Recall Service] FATAL ERROR initializing Recall Client:", error.message);
            recallClientInstance = null;
            isRecallInitialized = false;
            initPromise = null;
            throw new Error(`Recall Client initialization failed: ${error.message}`); // Rethrow to calling function
        }
    })();

    return initPromise;
}

// --- Helper: Ensure Credit Balance ---
// Returns true if credit was sufficient OR successfully purchased, false otherwise
async function ensureCreditBalanceIfZero(recall: RecallClient): Promise<boolean> {
    console.log("[Recall Service] Checking credit balance...");
    try {
        const creditManager = recall.creditManager();
        const { result: creditBalance } = await creditManager.getCreditBalance();
        const creditFree = creditBalance?.creditFree ?? 0n;
        console.log(`[Recall Service] Current credit_free: ${creditFree.toString()}`);

        if (creditFree === 0n) { // Only buy if exactly zero
            console.log('[Recall Service] credit_free is 0, attempting to buy 1 credit...');
            const amountToBuy = parseEther("1");
            const { meta } = await creditManager.buy(amountToBuy);
            const txHash = meta?.tx?.transactionHash;
            if (!txHash) throw new Error("Credit purchase transaction did not return a hash.");

            console.log(`[Recall Service] Credit purchase transaction sent: ${txHash}. Waiting for confirmation...`);
            const publicClient = getPublicClient();
            const receipt = await publicClient.waitForTransactionReceipt({ hash: txHash, confirmations: 1 });

            if (receipt.status === 'success') {
                 console.log(`[Recall Service] Credit purchased successfully (Tx: ${txHash}).`);
                 await new Promise(resolve => setTimeout(resolve, 3000)); // Allow buffer time
                 return true;
            } else {
                 console.error(`[Recall Service] Credit purchase transaction failed (Tx: ${txHash}). Status: ${receipt.status}`);
                 throw new Error(`Failed to purchase Recall credit (Tx: ${txHash}, Status: ${receipt.status}).`);
            }
        }
        return true; // Credit was > 0 initially
    } catch (error: any) {
        console.error("[Recall Service] Error checking or buying credit:", error.message);
         if (error instanceof ChainMismatchError) {
              console.error("[Recall Service] Chain mismatch detected. Check Recall SDK/Chain config.");
         }
        // Rethrow or return false to indicate failure? Let's rethrow for clarity.
        throw new Error(`Failed to ensure Recall credit balance: ${error.message}`);
    }
}

// --- Helper: Find or Create Log Bucket ---
async function ensureLogBucket(recall: RecallClient): Promise<string> {
    if (logBucketAddress) {
        return logBucketAddress;
    }

    console.log(`[Recall Service] Attempting to find or create log bucket with alias: ${RECALL_BUCKET_ALIAS}`);
    const bucketManager = recall.bucketManager();
    let foundBucket: string | null = null;

    try {
        const { result: listResult } = await bucketManager.list();
        const buckets = listResult?.buckets || [];
        console.log(`[Recall Service] Checking ${buckets.length} accessible buckets for alias...`);

        for (const bucketAddr of buckets) {
            try {
                // list returns { kind: string, addr: string, metadata: Record<string, unknown> }[]
                // No need to call getMetadata separately if list returns it
                if (bucketAddr.metadata?.alias === RECALL_BUCKET_ALIAS) {
                    console.log(`[Recall Service] Found existing log bucket: ${bucketAddr.addr}`);
                    foundBucket = bucketAddr.addr;
                    break;
                }
            } catch (listError: any) { /* Handle specific list errors if needed */ }
        }

        if (!foundBucket) {
            console.log(`[Recall Service] Log bucket alias '${RECALL_BUCKET_ALIAS}' not found. Creating new bucket...`);
            await ensureCreditBalanceIfZero(recall); // Ensure credit before creating

            const createMetaPayload = { alias: RECALL_BUCKET_ALIAS, createdBy: 'KintaskBackend', timestamp: new Date().toISOString() };
            const { result, meta: createMetaInfo } = await bucketManager.create({ metadata: createMetaPayload });
            foundBucket = result?.bucket;
            const createTxHash = createMetaInfo?.tx?.transactionHash;

            if (foundBucket) {
                 console.log(`[Recall Service] Successfully created new log bucket: ${foundBucket} (Tx: ${createTxHash})`);
                 console.warn(`ACTION REQUIRED: Consider adding/updating RECALL_LOG_BUCKET in .env to: ${foundBucket} for faster startup.`);
            } else {
                 const errorMsg = createMetaInfo?.error?.message || "Bucket creation call succeeded but no bucket address was returned.";
                 console.error("[Recall Service] Bucket creation failed:", errorMsg, createMetaInfo);
                 throw new Error(errorMsg);
            }
        }

        logBucketAddress = foundBucket; // Cache address
        return logBucketAddress;

    } catch (error: any) {
        console.error("[Recall Service] Error finding or creating log bucket:", error.message);
        throw new Error(`Failed to ensure Recall log bucket: ${error.message}`);
    }
}

// --- Main Logging Function ---
export async function logRecallEvent(
    type: RecallEventType,
    details: Record<string, any>,
    requestContext: string
): Promise<string | undefined> { // Returns Recall Tx Hash or undefined

    if (!requestContext) {
         console.error("[Recall Service] CRITICAL: logRecallEvent called without requestContext.");
         return undefined;
    }

    let recall: RecallClient;
    let bucketAddr: string;
    try {
        // Get client, bucket, and ensure credit *before* creating log entry object
        recall = await getRecallClient();
        bucketAddr = await ensureLogBucket(recall);
        await ensureCreditBalanceIfZero(recall);
    } catch (setupError: any) {
        console.error(`[Recall Service] Setup failed before logging event ${type} (Context: ${requestContext}):`, setupError.message);
        return undefined; // Cannot log if setup fails
    }

    const logEntry: RecallLogEntryData = {
        timestamp: new Date().toISOString(),
        type: type,
        details: details,
        requestContext: requestContext,
    };

    // Prepare data for storage
    const contentString = JSON.stringify(logEntry);
    const fileBuffer = Buffer.from(contentString, 'utf8');
    const timestampSuffix = logEntry.timestamp.replace(/[:.]/g, '-');
    const key = `${requestContext}/${timestampSuffix}_${type}.json`; // Structure logs by request context

    // console.log(`[Recall Service] Logging Event [${requestContext}] Type=${type} to Bucket ${bucketAddr.substring(0,10)}... Key=${key.substring(0,50)}...`);

    try {
        const bucketManager = recall.bucketManager();
        const { meta } = await bucketManager.add(bucketAddr, key, fileBuffer);
        const txHash = meta?.tx?.transactionHash;

        if (!txHash) {
             console.warn(`[Recall Service] Log add successful (according to SDK meta?) for context ${requestContext}, type ${type}, but no txHash returned. Status uncertain.`);
             // Check meta for other status info if available
             return undefined;
        }

        console.log(`[Recall Service] Log Event ${type} stored for context ${requestContext}. TxHash: ${txHash}`);
        return txHash;

    } catch (error: any) {
        console.error(`[Recall Service] Error adding log event ${type} for context ${requestContext} to bucket ${bucketAddr}:`, error.message);
        return undefined; // Indicate logging failure
    }
}

// --- Trace Retrieval Function ---
export async function getTraceFromRecall(requestContext: string): Promise<RecallLogEntryData[]> {
    if (!requestContext) return [];

    console.log(`[Recall Service] Retrieving trace for context: ${requestContext}`);
    let recall: RecallClient;
    let bucketAddr: string;
    try {
        recall = await getRecallClient();
        // Use cached bucket address if available, otherwise ensure it exists
        bucketAddr = logBucketAddress || await ensureLogBucket(recall);
    } catch (initError: any) {
         console.error(`[Recall Service] Initialization failed for retrieving trace (Context: ${requestContext}):`, initError.message);
         return [];
    }

    try {
        const bucketManager = recall.bucketManager();
        const prefix = `${requestContext}/`; // Query by the context "folder"

        console.log(`[Recall Service] Querying bucket ${bucketAddr.substring(0,10)}... for prefix: ${prefix}`);
        const { result: queryResult } = await bucketManager.query(bucketAddr, { prefix: prefix, delimiter: '' });

        const objectInfos = (queryResult?.objects || []);
        const objectKeys = objectInfos.map(obj => obj.key).filter((k): k is string => !!k && k.endsWith('.json'));

        if (objectKeys.length === 0) {
            console.log(`[Recall Service] No log entries found via query for context: ${requestContext}`);
            return [];
        }
        console.log(`[Recall Service] Found ${objectKeys.length} log keys for context ${requestContext}. Fetching content...`);

        // Fetch content concurrently
        const fetchPromises = objectKeys.map(async (key) => {
             try {
                 const { result: objectResult } = await bucketManager.get(bucketAddr, key);
                 const objectBuf = objectResult as Uint8Array | null; // SDK's get returns Uint8Array
                 if (!objectBuf) {
                     console.warn(`[Recall Service] Got null buffer for key ${key}`);
                     return null;
                 }
                 // Ensure it's a Buffer before decoding (Node.js Buffer handles Uint8Array)
                 const buffer = Buffer.from(objectBuf);
                 const textContent = buffer.toString('utf8');
                 const logEntry = JSON.parse(textContent) as RecallLogEntryData;
                 if (logEntry && logEntry.timestamp && logEntry.type && logEntry.details) {
                      return logEntry;
                 }
                 console.warn(`[Recall Service] Invalid log format found parsing key ${key}`);
                 return null;
             } catch (fetchError: any) {
                  console.error(`[Recall Service] Error fetching/parsing key ${key}: ${fetchError.message}`);
                   if (fetchError.message?.includes("Object not found")) {
                        console.warn(`   -> Object likely deleted or query/get mismatch for key ${key}`);
                   }
                  return null;
             }
        });

        const logEntries = (await Promise.all(fetchPromises))
                            .filter((entry): entry is RecallLogEntryData => entry !== null)
                            .sort((a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()); // Sort chronologically

         console.log(`[Recall Service] Successfully retrieved and parsed ${logEntries.length} log entries for context: ${requestContext}`);
         return logEntries;

    } catch (error: any) {
        console.error(`[Recall Service] Error retrieving trace for context ${requestContext}:`, error.message);
        return []; // Return empty trace on error
    }
}

// Removed duplicate declaration: let logBucketAddress = config.recallLogBucket || null;===== ./src/services/timelockService.ts =====
import { ethers, Wallet, Contract, AbiCoder, keccak256, getBytes, TransactionResponse, TransactionReceipt, Log, EventLog } from 'ethers';
import { Blocklock, SolidityEncoder, encodeCiphertextToSolidity, TypesLib } from 'blocklock-js';
import config from '../config';
import KintaskCommitmentAbi from '../contracts/abi/KintaskCommitment.json'; // Load the ABI
import { KINTASK_COMMITMENT_CONTRACT_ADDRESS } from '../contracts/addresses';
import { logRecallEvent } from './recallService'; // Import recall logger for reveal events

interface CommitResult {
    requestId: string; // The on-chain request ID from Blocklock
    txHash: string; // The L2 transaction hash
    ciphertextHash: string; // Hash of the encrypted data 'v' field
}

// --- Initialization ---
let provider: ethers.JsonRpcProvider | null = null;
let wallet: Wallet | null = null;
let blocklockJsInstance: Blocklock | null = null;
let commitmentContract: Contract | null = null;
let isTimelockInitialized = false;
let revealListenerAttached = false;
// Simple mapping to associate blocklock request ID with our internal request context for logging reveals
const blocklockIdToRequestContext = new Map<string, string>();
const MAX_CONTEXT_MAP_SIZE = 1000; // Prevent memory leak

// Function to initialize (or re-initialize) the service
// Returns true if initialization is complete or already done, false if required config is missing
function initializeTimelockService(): boolean {
    if (isTimelockInitialized) return true; // Already initialized
    console.log("[Timelock Service] Initializing...");
    try {
        // Validate critical config FIRST
         if (!config.l2RpcUrl || !config.walletPrivateKey || !config.blocklockSenderProxyAddress || !KINTASK_COMMITMENT_CONTRACT_ADDRESS) {
             console.warn("[Timelock Service] Skipping initialization: Missing required L2/Blocklock/Contract configuration in .env");
             return false; // Cannot initialize
         }
         // Validate ABI presence
          if (!KintaskCommitmentAbi.abi || KintaskCommitmentAbi.abi.length === 0) {
               console.error("[Timelock Service] FATAL ERROR: KintaskCommitment ABI not found or empty. Run 'pnpm contracts:compile' and copy ABI.");
               return false; // Cannot initialize without ABI
          }

        provider = new ethers.JsonRpcProvider(config.l2RpcUrl);
        wallet = new Wallet(config.walletPrivateKey, provider);
        blocklockJsInstance = new Blocklock(wallet, config.blocklockSenderProxyAddress);
        commitmentContract = new Contract(KINTASK_COMMITMENT_CONTRACT_ADDRESS, KintaskCommitmentAbi.abi, wallet);

        // Perform async checks AFTER basic setup
         Promise.all([
             provider.getNetwork(),
             commitmentContract.getAddress() // Check if contract connection works
         ]).then(([network, address]) => {
             console.log(`[Timelock Service] Connected to network: ${network.name} (Chain ID: ${network.chainId})`);
             console.log(`[Timelock Service] KintaskCommitment contract instance connected at: ${address}`);
             isTimelockInitialized = true; // Mark as fully initialized only after checks pass
             console.log("[Timelock Service] Initialization complete.");
             // Attempt to start listener only after successful init
              startRevealListener(); // Start listener now that we are initialized
         }).catch(err => {
             console.error("[Timelock Service] Post-initialization check failed (Network or Contract connection issue):", err.message);
             // Keep isTimelockInitialized = false if checks fail
             isTimelockInitialized = false;
         });

         console.log("[Timelock Service] Initialization sequence started (async checks pending)...");
         return true; // Return true indicating initialization started

    } catch (error: any) {
         console.error("[Timelock Service] FATAL Initialization failed:", error.message);
         isTimelockInitialized = false;
         return false; // Indicate failure
    }
}

// Attempt initialization on module load
initializeTimelockService();

// --- Commit Function ---
export async function commitVerdictTimelocked(
    verdict: string,
    delayInBlocks: number = 5, // Default delay
    requestContext?: string // Pass context for mapping reveal logs
): Promise<CommitResult | null> {

    // Check initialization status before proceeding
    if (!isTimelockInitialized || !blocklockJsInstance || !commitmentContract || !provider || !wallet) {
        console.error('[Timelock Service] Service not initialized or ready. Cannot commit verdict.');
        return null; // Fail if not ready
    }

    let txResponse: TransactionResponse | null = null; // Define txResponse outside try
    const logContext = requestContext || 'unknownContext'; // Use provided context or a default

    try {
        const currentBlockNumber = await provider.getBlockNumber();
        const decryptionBlockNumber = BigInt(currentBlockNumber + delayInBlocks);
        console.log(`[Timelock Service Context: ${logContext}] Current Block: ${currentBlockNumber}, Decryption Block Target: ${decryptionBlockNumber}`);

        // 1. Encode verdict string
        const encoder = AbiCoder.defaultAbiCoder();
        const encodedVerdict = encoder.encode(['string'], [verdict]);
        const encodedVerdictBytes = getBytes(encodedVerdict);

        // 2. Encrypt using blocklock-js
        console.log(`[Timelock Service Context: ${logContext}] Encrypting verdict "${verdict}"`);
        const ciphertext: TypesLib.Ciphertext = blocklockJsInstance.encrypt(encodedVerdictBytes, decryptionBlockNumber);
        const solidityCiphertext = encodeCiphertextToSolidity(ciphertext);
        const ciphertextHash = keccak256(solidityCiphertext.v); // Hash the encrypted part V
        console.log(`[Timelock Service Context: ${logContext}] Ciphertext Hash: ${ciphertextHash}`);

        // 3. Call commitVerdict on contract
        console.log(`[Timelock Service Context: ${logContext}] Sending commitVerdict transaction to ${await commitmentContract.getAddress()}...`);
        txResponse = await commitmentContract.commitVerdict(
            decryptionBlockNumber,
            solidityCiphertext
            // Optional: Add gas estimation/limit
            // { gasLimit: 300000 } // Example fixed gas limit
        );
        console.log(`[Timelock Service Context: ${logContext}] Commit transaction sent. Hash: ${txResponse.hash}`);
        console.log(`[Timelock Service Context: ${logContext}] Waiting for confirmation (1 block)...`);
        const receipt: TransactionReceipt | null = await txResponse.wait(1);

        if (!receipt) throw new Error(`Commit transaction ${txResponse.hash} confirmation timed out or receipt was null.`);
        console.log(`[Timelock Service Context: ${logContext}] Commit Tx Confirmed. Status: ${receipt.status}, Block: ${receipt.blockNumber}`);
        if (receipt.status !== 1) throw new Error(`Commit transaction ${txResponse.hash} failed on-chain (Status: 0). Check explorer.`);

        // 4. Parse Blocklock Request ID from logs emitted by *our* contract
        const eventInterface = commitmentContract.interface.getEvent('VerdictCommitted');
        const eventTopic = eventInterface.topicHash;
        const receiptLogs = receipt.logs || []; // Ensure logs is an array
        const log = receiptLogs.find((l: Log) =>
            l.topics[0] === eventTopic &&
            l.address.toLowerCase() === KINTASK_COMMITMENT_CONTRACT_ADDRESS.toLowerCase()
        );

        if (!log) throw new Error(`Could not find VerdictCommitted event log in transaction receipt for ${txResponse.hash}.`);

        const decodedLog = commitmentContract.interface.parseLog({ topics: [...log.topics], data: log.data });
        const blocklockRequestId = decodedLog?.args.blocklockRequestId?.toString();
        if (!blocklockRequestId) throw new Error('Failed to decode Blocklock Request ID from VerdictCommitted event.');

        console.log(`[Timelock Service Context: ${logContext}] Successfully committed. Blocklock Request ID: ${blocklockRequestId}`);

        // Store mapping for the listener
        if (requestContext) {
            if (blocklockIdToRequestContext.size >= MAX_CONTEXT_MAP_SIZE) {
                const oldestKey = blocklockIdToRequestContext.keys().next().value;
                 blocklockIdToRequestContext.delete(oldestKey);
                 console.warn(`[Timelock Service] Context map size limit reached, removed oldest entry: ${oldestKey}`);
            }
            blocklockIdToRequestContext.set(blocklockRequestId, requestContext);
            console.log(`[Timelock Service] Mapped Blocklock ID ${blocklockRequestId} to Context ${requestContext}`);
        } else {
             console.warn("[Timelock Service] Request context not provided for mapping reveal listener.");
        }

        return {
            requestId: blocklockRequestId,
            txHash: txResponse.hash,
            ciphertextHash: ciphertextHash
        };

    } catch (error: any) {
        console.error(`[Timelock Service Error Context: ${logContext}] Error during commit:`, error.message);
        if (txResponse?.hash) console.error(`[Timelock Service] Failing Transaction Hash: ${txResponse.hash}`);
        return null; // Indicate failure
    }
}

// --- Reveal Listener ---
export function startRevealListener() {
    if (revealListenerAttached) {
        // console.log("[Timelock Service] Reveal listener already attached.");
        return;
    }
     // Ensure initialized before attaching listener
     if (!isTimelockInitialized || !commitmentContract) {
         console.warn("[Timelock Service] Cannot start listener, service not fully initialized yet.");
         // Initialization might still be in async checks, listener will start when/if init completes.
         return;
     }

    console.log(`[Timelock Service] Attaching listener for VerdictRevealed events on contract ${KINTASK_COMMITMENT_CONTRACT_ADDRESS}...`);
    try {
        const eventFilter = commitmentContract.filters.VerdictRevealed();

         // Using commitmentContract.on() sets up a persistent listener
         commitmentContract.on(eventFilter, async (requestIdBigInt, requester, revealedVerdictBytes, eventLog) => {
            // Type assertion for ethers v6 EventLog
            const log = eventLog as unknown as EventLog;
            const blocklockRequestId = requestIdBigInt.toString();
            const txHash = log.transactionHash; // Tx hash where the Blocklock callback happened

            console.log(`\n[Timelock Listener] === Received VerdictRevealed Event ===`);
            console.log(`  Blocklock Request ID: ${blocklockRequestId}`);
            console.log(`  Event Source Tx Hash: ${txHash}`); // This is the Blocklock callback tx hash

             // Find the original request context using the mapping
             const requestContext = blocklockIdToRequestContext.get(blocklockRequestId);
             if (!requestContext) {
                 console.warn(`[Timelock Listener] Could not find request context for revealed Blocklock ID: ${blocklockRequestId}. Cannot log details to Recall.`);
                 // It's possible the context map was cleared or this ID was processed already
                 return;
             }
             console.log(`  Associated Request Context: ${requestContext}`);

             // Clean up the mapping immediately to prevent reprocessing
             blocklockIdToRequestContext.delete(blocklockRequestId);

             try {
                // Decode the revealed verdict bytes (assuming it was encoded as a string)
                const encoder = AbiCoder.defaultAbiCoder();
                const [revealedVerdict] = encoder.decode(['string'], revealedVerdictBytes);

                console.log(`[Timelock Listener] Decoded Verdict for context ${requestContext}: "${revealedVerdict}"`);

                // Log this reveal event to Recall Service under the original request context
                await logRecallEvent(
                    'TIMELOCK_REVEAL_RECEIVED',
                    { blocklockRequestId, revealedVerdict, sourceTxHash: txHash, requester },
                    requestContext
                );
                console.log(`[Timelock Listener] Logged TIMELOCK_REVEAL_RECEIVED to Recall for context ${requestContext}`);

                // TODO: Compare revealedVerdict with final calculated verdict from verifierService state?

             } catch(decodeError: any) {
                console.error(`[Timelock Listener] Error decoding revealed verdict for ID ${blocklockRequestId}, Context ${requestContext}:`, decodeError.message);
                // Log decode error to recall
                 await logRecallEvent(
                    'VERIFICATION_ERROR',
                    { stage: 'TimelockRevealDecode', error: decodeError.message, blocklockRequestId, rawBytes: ethers.hexlify(revealedVerdictBytes) },
                    requestContext
                );
             }
         });

        revealListenerAttached = true;
        console.log("[Timelock Service] Listener attached successfully.");

    } catch (error: any) {
        console.error("[Timelock Service] Failed to attach listener:", error.message);
        revealListenerAttached = false;
    }
}

// Function to stop listener (e.g., on shutdown)
export function stopRevealListener() {
     if (revealListenerAttached && commitmentContract) {
         console.log("[Timelock Service] Removing VerdictRevealed listener...");
         try {
             // Use off() or removeAllListeners() depending on specific needs and ethers version guarantees
             commitmentContract.off("VerdictRevealed"); // Attempt to remove specific listener type
             // Alternatively: commitmentContract.removeAllListeners("VerdictRevealed");
             revealListenerAttached = false;
             console.log("[Timelock Service] Listener removed.");
         } catch (error: any) {
             console.error("[Timelock Service] Error removing listener:", error.message);
             revealListenerAttached = false;
         }
     } else {
          // console.log("[Timelock Service] Listener not attached or contract not initialized.");
     }
}
===== ./src/services/verifierService.ts =====
import {
    KnowledgeFragment,
    VerificationResultInternal,
    RecallLogEntryData,
    RecallEventType,
    VerificationStatus
} from '../types';
import { fetchKnowledgeFragment, getKnowledgeIndex } from './filecoinService';
import { commitVerdictTimelocked } from './timelockService';
import { logRecallEvent } from './recallService';
import { truncateText } from '../utils'; // Import utility
import config from '../config'; // Import config to check if timelock is configured

// --- Helper Function ---
const addStep = async (
    reasoningSteps: RecallLogEntryData[],
    requestContext: string,
    type: RecallEventType,
    details: Record<string, any>
) => {
    const timestamp = new Date().toISOString();
    // Simple truncation for potentially large values in logs
    const truncatedDetails = Object.entries(details).reduce((acc, [key, value]) => {
        try {
            if (typeof value === 'string') {
                acc[key] = truncateText(value, 250); // Truncate long strings
            } else if (Array.isArray(value) && value.length > 15) {
                 acc[key] = value.slice(0, 15).concat(['...truncated...']); // Truncate long arrays
            } else if (key === 'stack') { // Don't stringify stack traces if too long
                 acc[key] = truncateText(value?.toString(), 300);
            } else if (typeof value === 'object' && value !== null && JSON.stringify(value).length > 300) {
                 acc[key] = { _truncated: true, keys: Object.keys(value).slice(0,5) }; // Truncate large objects
            } else if (typeof value === 'bigint') {
                 acc[key] = value.toString(); // Convert BigInts
            }
            else {
                acc[key] = value;
            }
        } catch (e) {
             acc[key] = `<<Error truncating value for key ${key}>>`; // Handle potential errors during truncation/stringification
        }
        return acc;
    }, {} as Record<string, any>);

    const stepData: RecallLogEntryData = { timestamp, type, details: truncatedDetails, requestContext };
    reasoningSteps.push(stepData);
    // Fire-and-forget logging to Recall
    logRecallEvent(type, truncatedDetails, requestContext).catch(err => {
        console.error(`[Verifier Service] Background logging to Recall failed for type ${type}:`, err.message);
    });
};


// --- Main Verification Logic Function ---
export async function performVerification(
    question: string,
    answer: string,
    requestContext: string // Identifier for this specific verification task
): Promise<VerificationResultInternal | null> {

    console.log(`[Verifier Service] Starting verification for context: ${requestContext}`);
    const reasoningSteps: RecallLogEntryData[] = [];
    let usedFragmentCids: string[] = []; // Track CIDs successfully fetched AND used in logic
    let preliminaryVerdict: VerificationStatus = 'Unverified';
    let confidenceScore = 0.5; // Start neutral
    let timelockDetails: Awaited<ReturnType<typeof commitVerdictTimelocked>> = null;

    try {
        // --- Step 1: Input Analysis & Keyword Extraction ---
        const questionLower = question.toLowerCase();
        const answerLower = answer.toLowerCase();
        const stopWords = new Set(['the', 'a', 'an', 'is', 'of', 'in', 'on', 'at', 'to', 'for', 'and', 'or', 'what', 'who', 'where', 'when', 'why', 'how', 'tell', 'me', 'about', 'can', 'you', 'please', 'i', 'it', 'my', 'your']);
        const keywords = [...new Set(
            questionLower.split(/\s+/) // Split by whitespace
                .map(word => word.replace(/[^\w]/g, '').trim()) // Remove punctuation
                .filter(word => word.length >= 3 && !stopWords.has(word)) // Filter length and stopwords
        )];
        await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { step: 'AnalyzeInput', extractedKeywords: keywords });

        // --- Step 2: Fetch Index & Relevant CIDs ---
        await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_ATTEMPT', { stage: 'Index', keywords });
        const index = await getKnowledgeIndex(); // Fetches from cache or network
        let relevantCids: string[] = [];
        if (index) {
            keywords.forEach(kw => {
                if (index[kw]) relevantCids.push(...index[kw]);
            });
            relevantCids = [...new Set(relevantCids)]; // Deduplicate CIDs
            await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_SUCCESS', { stage: 'Index', foundCidsCount: relevantCids.length });
        } else {
            await addStep(reasoningSteps, requestContext, 'VERIFICATION_ERROR', { stage: 'IndexFetch', error: 'Failed to retrieve knowledge index' });
             console.error("[Verifier Service] Failed to retrieve knowledge index. Verification quality may be reduced.");
             // Decide whether to throw or continue. Let's continue for robustness.
        }

        // Limit number of fragments to fetch/process for performance in MVP
        const MAX_FRAGMENTS_TO_PROCESS = 10;
        const cidsToFetch = relevantCids.slice(0, MAX_FRAGMENTS_TO_PROCESS);
        if (relevantCids.length > MAX_FRAGMENTS_TO_PROCESS) {
             await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { warning: 'Too many relevant fragments found', count: relevantCids.length, processingLimit: MAX_FRAGMENTS_TO_PROCESS });
        }


        // --- Step 3: Fetch KG Fragments Concurrently ---
        await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_ATTEMPT', { stage: 'Fragments', cidsToFetchCount: cidsToFetch.length });
        const fetchPromises = cidsToFetch.map(cid =>
            fetchKnowledgeFragment(cid).then(fragment => ({ cid, fragment }))
        );
        const fetchedResults = await Promise.all(fetchPromises);

        const fetchedFragments: KnowledgeFragment[] = [];
        const successfullyFetchedCids = new Set<string>();
        const failedFetches: string[] = [];
        fetchedResults.forEach(result => {
            if (result.fragment) {
                fetchedFragments.push(result.fragment);
                successfullyFetchedCids.add(result.cid);
            } else {
                failedFetches.push(result.cid);
            }
        });
        await addStep(reasoningSteps, requestContext, 'KNOWLEDGE_FETCH_SUCCESS', { stage: 'Fragments', fetchedCount: fetchedFragments.length, failedCidsCount: failedFetches.length });


        // --- Step 4: Apply Verification Logic ---
        if (fetchedFragments.length === 0 && relevantCids.length > 0) {
             // If index found CIDs but fetching failed for all relevant ones
             console.warn(`[Verifier Service] No relevant knowledge fragments could be fetched for context ${requestContext}, although index suggested ${relevantCids.length}.`);
             await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { warning: 'No fragments fetched despite finding relevant CIDs', failedCids });
             preliminaryVerdict = 'Unverified'; // Cannot verify without data
             confidenceScore = 0.1; // Very low confidence
        } else if (fetchedFragments.length === 0 && relevantCids.length === 0) {
             // If index found no relevant CIDs
              console.log(`[Verifier Service] No relevant knowledge fragments found in index for context ${requestContext}.`);
              await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { info: 'No relevant fragments found in index' });
              preliminaryVerdict = 'Unverified';
              confidenceScore = 0.3; // Slightly higher confidence than fetch failure
        }
        else {
            // Apply logic only if fragments were fetched
            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { step: 'ApplyVerificationLogic', fragmentCount: fetchedFragments.length });
            let supportingScore = 0;
            let contradictingScore = 0;
            let uncertaintyFlags = 0;
            let provenanceIssues = 0;
            const fragmentsUsedInLogic: string[] = [];

            for (const fragment of fetchedFragments) {
                const fragmentId = fragment.fragment_id || `cid:${fragment.previous_version_cid?.substring(0, 8) ?? truncateText([...successfullyFetchedCids][fragmentsUsedInLogic.length], 8)}`;
                fragmentsUsedInLogic.push(fragmentId);

                try {
                    const fragmentConf = fragment.provenance?.confidence_score ?? 0.7;

                    // A) Uncertainty Check
                    if (fragmentConf < 0.4) {
                        uncertaintyFlags++;
                        await addStep(reasoningSteps, requestContext, 'PROVENANCE_CHECK', { check: 'LowConfidenceSource', fragmentId, score: fragmentConf });
                    }

                    // B) Fact Matching Logic (Simple Placeholder)
                    if (fragment.type === 'factual_statement' && fragment.content?.subject && fragment.content?.object) {
                        const subject = fragment.content.subject.toLowerCase();
                        const objectVal = fragment.content.object.toLowerCase();
                        if ((keywords.includes(subject) || questionLower.includes(subject)) && answerLower.includes(objectVal)) {
                            supportingScore += fragmentConf;
                            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', { check: 'FactMatch', fragmentId, outcome: 'Support', score: fragmentConf });
                        }
                    }

                    // C) Provenance Checks (Recency Example)
                    if (fragment.provenance?.timestamp_created) {
                        const createdDate = new Date(fragment.provenance.timestamp_created);
                        const ageDays = (Date.now() - createdDate.getTime()) / (1000 * 3600 * 24);
                        if (ageDays > 730) {
                            provenanceIssues++;
                            await addStep(reasoningSteps, requestContext, 'PROVENANCE_CHECK', { check: 'Age', fragmentId, ageDays: Math.round(ageDays), outcome: 'Very Stale (>2yr)' });
                        }
                    }

                    // D) Cross-Chain Attestation Check (Simulated Pass)
                     const attestations = fragment.provenance?.external_attestations;
                      if (attestations && attestations.length > 0) {
                          supportingScore += 0.1 * attestations.length; // Small boost
                          await addStep(reasoningSteps, requestContext, 'CROSSCHAIN_CHECK', { check: 'AttestationExists', fragmentId, count: attestations.length, outcome: 'BoostedConfidence(Simulated)' });
                      }

                } catch (logicError: any) {
                     console.error(`[Verifier Service] Error processing fragment ${fragmentId} for context ${requestContext}: ${logicError.message}`);
                     await addStep(reasoningSteps, requestContext, 'VERIFICATION_ERROR', { stage: 'LogicExecution', fragmentId, error: logicError.message });
                }
            } // End fragment loop

            usedFragmentCids = fragmentsUsedInLogic; // Update based on actual usage

            // Determine Preliminary Verdict
            confidenceScore = 0.5 + (supportingScore - contradictingScore) * 0.5 - (provenanceIssues * 0.05) - (uncertaintyFlags * 0.2);
            confidenceScore = Math.max(0.01, Math.min(0.99, confidenceScore)); // Clamp

            if (uncertaintyFlags > 0) preliminaryVerdict = 'Flagged: Uncertain';
            else if (contradictingScore > supportingScore * 1.5) preliminaryVerdict = 'Flagged: Contradictory';
            else if (supportingScore > 0.5 && confidenceScore > 0.65) preliminaryVerdict = 'Verified';
            else preliminaryVerdict = 'Unverified';

            await addStep(reasoningSteps, requestContext, 'REASONING_STEP', {
                step: 'LogicComplete',
                calculatedVerdict: preliminaryVerdict,
                calculatedConfidence: confidenceScore,
                supportingScore: supportingScore.toFixed(2),
                contradictoryScore: contradictoryScore.toFixed(2),
                uncertaintyFlags, provenanceIssues
            });
        } // End of else block (if fragments were fetched)


        // --- Step 5: Timelock Commit ---
        // Check if contract address is configured before attempting commit
        if (config.kintaskContractAddress && config.blocklockSenderProxyAddress) {
            await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_ATTEMPT', { verdictToCommit: preliminaryVerdict });
            if (!preliminaryVerdict.startsWith('Error:')) { // Only commit if no prior critical error
                timelockDetails = await commitVerdictTimelocked(preliminaryVerdict, 5, requestContext);
                if (timelockDetails) {
                    await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_SUCCESS', {
                        requestId: timelockDetails.requestId,
                        txHash: timelockDetails.txHash,
                        ciphertextHash: timelockDetails.ciphertextHash,
                        committedVerdict: preliminaryVerdict
                    });
                } else {
                    await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_FAILURE', { error: 'commitVerdictTimelocked returned null or failed' });
                    preliminaryVerdict = 'Error: Timelock Failed'; // Update status
                    confidenceScore = 0; // Reset confidence
                }
            } else {
                console.warn(`[Verifier Service] Skipping timelock commit due to prior error status: ${preliminaryVerdict}`);
                await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_FAILURE', { reason: 'Skipped due to prior error', priorStatus: preliminaryVerdict });
            }
        } else {
            console.warn(`[Verifier Service] Skipping timelock commit: KINTASK_CONTRACT_ADDRESS or BLOCKLOCK_SENDER_PROXY_ADDRESS not configured.`);
            await addStep(reasoningSteps, requestContext, 'TIMELOCK_COMMIT_FAILURE', { reason: 'Skipped: Contract/Proxy address not configured' });
        }


        // --- Step 6: Final Result Object ---
        const finalResult: VerificationResultInternal = {
            finalVerdict: preliminaryVerdict,
            confidenceScore: parseFloat(confidenceScore.toFixed(2)), // Format confidence
            usedFragmentCids: usedFragmentCids,
            reasoningSteps: reasoningSteps, // Return collected steps for controller
            timelockRequestId: timelockDetails?.requestId,
            timelockCommitTxHash: timelockDetails?.txHash,
            ciphertextHash: timelockDetails?.ciphertextHash
        };

        console.log(`[Verifier Service] Verification complete for context ${requestContext}. Verdict: ${finalResult.finalVerdict}, Confidence: ${finalResult.confidenceScore}`);
        return finalResult;

    } catch (error: any) {
        console.error(`[Verifier Service Error Request: ${requestContext}]:`, error.message, error.stack);
        await addStep(reasoningSteps, requestContext, 'VERIFICATION_ERROR', { error: error.message, stage: 'TopLevelCatch' });
        // Return a consistent error state result
         return {
             finalVerdict: 'Error: Verification Failed',
             confidenceScore: 0,
             usedFragmentCids: usedFragmentCids,
             reasoningSteps: reasoningSteps,
             timelockRequestId: timelockDetails?.requestId,
             timelockCommitTxHash: timelockDetails?.txHash,
             ciphertextHash: timelockDetails?.ciphertextHash
         };
    }
}
===== ./src/types/blocklock-js.d.ts =====
// packages/backend/src/types/blocklock-js.d.ts

/**
 * Placeholder type definitions for 'blocklock-js'.
 * Replace with more specific types if known or provided by the library later.
 * Based on usage in timelockService.ts and Blocklock documentation examples.
 */
declare module 'blocklock-js' {

    // Assuming TypesLib.Ciphertext structure based on Solidity usage
    // This might need adjustments based on the actual JS object structure
    export namespace TypesLib {
      export interface Ciphertext {
        v: Uint8Array | string; // Or Buffer? Usually bytes represented as hex string or Uint8Array
        r: Uint8Array | string;
        s: Uint8Array | string;
        u: [string, string] | [bigint, bigint]; // Point coordinates (often strings or BigInts)
        ephKey?: any; // Optional/Internal? Check library details
      }
    }
  
    // Placeholder for the result of encodeCiphertextToSolidity
    // Based on contract expectation, it's likely a tuple/struct matching Solidity's TypesLib.Ciphertext
    export type SolidityCiphertextStruct = {
       v: string; // Hex string for bytes
       r: string; // Hex string for bytes32 or similar
       s: string; // Hex string for bytes32 or similar
       u: [string, string]; // String tuple for uint256[2]
       // Adjust types based on actual Solidity struct definition
    };
  
    // Main Blocklock class
    export class Blocklock {
      constructor(wallet: any, blocklockSenderProxyAddress: string); // Use 'any' for wallet initially
  
      // Encrypt method signature based on usage
      encrypt(messageBytes: Uint8Array | Buffer, blockHeight: bigint): TypesLib.Ciphertext;
  
      // Decrypt method (if used in JS, based on docs) - Check return type
      decryptWithId(requestId: string | number | bigint): Promise<Uint8Array | Buffer | string>; // Adjust return type
    }
  
    // SolidityEncoder class (if used - based on docs)
    export class SolidityEncoder {
      constructor();
      // Add specific methods if known, otherwise keep it simple
      // Example based on docs:
      encodeUint256(value: bigint | string): string; // Returns hex string likely
      // encodeString(value: string): string;
      // encodeBytes(value: Uint8Array | Buffer | string): string;
      // ... other encoding methods
    }
  
    // Function to convert JS Ciphertext object to Solidity struct/tuple format
    export function encodeCiphertextToSolidity(ciphertext: TypesLib.Ciphertext): SolidityCiphertextStruct; // Adjust return type if needed
  
    // Add other exports from the library if you use them
  }===== ./src/types/index.ts =====
// --- Knowledge Fragment Structure (Stored on Filecoin) ---
export interface KnowledgeFragmentProvenance {
  source_type: string; // e.g., 'dataset_snapshot', 'web_scrape', 'human_curated', 'api_call'
  source_name?: string;
  source_cid?: string; // CID of larger dataset if applicable
  source_url?: string; // URL if scraped
  curation_method?: string;
  curator_id?: string; // e.g., DID
  timestamp_created: string; // ISO 8601
  confidence_score?: number; // 0.0 to 1.0
  external_attestations?: ExternalAttestation[];
}

export interface ExternalAttestation {
    chain: string; // e.g., 'Optimism', 'BaseSepolia'
    type: string; // e.g., 'EAS', 'Verax'
    schema_uid?: string;
    attestation_uid?: string; // Linkable UID on the attestation network
    attestation_data?: Record<string, any>; // Parsed data if relevant
}

export interface KnowledgeFragment {
  fragment_id: string; // Unique identifier for this version
  type: string; // e.g., 'factual_statement', 'rule', 'definition'
  keywords?: string[]; // For indexing
  content: Record<string, any>; // The actual data/fact/rule
  provenance: KnowledgeFragmentProvenance;
  version: number;
  previous_version_cid?: string | null;
}

// --- Verification & Recall ---
export type VerificationStatus =
    | 'Verified'
    | 'Unverified'
    | 'Flagged: Uncertain'
    | 'Flagged: Contradictory'
    | 'Error: Verification Failed'
    | 'Error: Timelock Failed';

// Result returned internally by the Verifier Service
export interface VerificationResultInternal {
  finalVerdict: VerificationStatus;
  confidenceScore: number; // Overall confidence
  usedFragmentCids: string[]; // List of Filecoin CIDs actually used
  reasoningSteps: RecallLogEntryData[]; // Detailed steps taken
  timelockRequestId?: string; // Blocklock on-chain request ID
  timelockCommitTxHash?: string; // L2 Tx hash for the commit
  ciphertextHash?: string; // Hash of the committed ciphertext
}

// --- Recall Logging ---
export type RecallEventType =
    | 'VERIFICATION_START'
    | 'KNOWLEDGE_FETCH_ATTEMPT'
    | 'KNOWLEDGE_FETCH_SUCCESS' // Log CIDs fetched
    | 'TIMELOCK_COMMIT_ATTEMPT'
    | 'TIMELOCK_COMMIT_SUCCESS' // Log Request ID, Ciphertext Hash, Tx Hash
    | 'TIMELOCK_COMMIT_FAILURE'
    | 'REASONING_STEP' // Log rule/fact applied, CID used, outcome
    | 'PROVENANCE_CHECK' // Log check on provenance data
    | 'CROSSCHAIN_CHECK' // Log check on external attestation
    | 'FINAL_VERDICT_CALCULATED' // Log verdict before reveal check
    | 'TIMELOCK_REVEAL_RECEIVED' // Log revealed verdict, check match
    | 'VERIFICATION_COMPLETE'
    | 'VERIFICATION_ERROR'
    | 'GENERATOR_MOCK_USED'; // Added for mock logging

// Structure for data field in Recall log entries
export interface RecallLogEntryData {
  timestamp: string;
  type: RecallEventType;
  details: Record<string, any>; // Context-specific details for each event type
  requestContext?: string; // Identifier for the overall Q&A request
}

// --- API Response Structure (Controller to Frontend) ---
export interface ApiVerifyResponse {
  answer: string;
  status: VerificationStatus;
  confidence?: number;
  usedFragmentCids?: string[];
  timelockRequestId?: string;
  timelockTxExplorerUrl?: string; // Link to L2 explorer for commit Tx
  recallTrace?: RecallLogEntryData[]; // Snippets or full trace for this request
  recallExplorerUrl?: string; // Link to Recall explorer if available
  error?: string; // Optional error message for frontend display
  details?: string; // Optional error details
}
===== ./src/utils/index.ts =====
import config from '../config';

// Example utility: Build L2 Explorer URL based on configured RPC URL heuristics
export function getL2ExplorerUrl(txHash: string): string | undefined {
    const rpcUrl = config.l2RpcUrl?.toLowerCase() || '';
    if (!rpcUrl || !txHash) return undefined;

    // Add more mappings as needed for supported testnets/mainnets
    if (rpcUrl.includes('base-sepolia') || rpcUrl.includes('84532')) {
        return `https://sepolia.basescan.org/tx/${txHash}`;
    }
    if (rpcUrl.includes('optimism-sepolia') || rpcUrl.includes('11155420')) {
        return `https://sepolia-optimism.etherscan.io/tx/${txHash}`;
    }
     if (rpcUrl.includes('arbitrum-sepolia') || rpcUrl.includes('421614')) {
         return `https://sepolia.arbiscan.io/tx/${txHash}`;
     }
    // Add Polygon Amoy, etc.
    if (rpcUrl.includes('polygon-amoy') || rpcUrl.includes('80002')) {
        return `https://www.oklink.com/amoy/tx/${txHash}`;
    }

    console.warn(`[Utils] No block explorer URL configured for RPC: ${rpcUrl}`);
    return undefined; // Return undefined if no match
}

// Add other shared utility functions here, e.g., text truncation, basic NLP helpers
export function truncateText(text: string | undefined | null, maxLength: number): string {
    if (!text) return '';
    if (text.length <= maxLength) return text;
    return text.substring(0, maxLength - 3) + '...';
}
===== ./tsconfig.json =====
// kintask/packages/backend/tsconfig.json
{
  "compilerOptions": {
    "target": "ES2022",        // Use a target that supports modern features like top-level await
    "module": "NodeNext",     // <--- CHANGE: Use NodeNext module system
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,    // Keep enabled, generally helpful
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "moduleResolution": "NodeNext", // <--- CHANGE: Use NodeNext resolution
    "sourceMap": true,
    "baseUrl": "./",
    "paths": {
      "@/*": ["src/*"]
    }
    // Ensure no "types" array limiting type lookups if present
  },
  "ts-node": { // Add ts-node config if using it directly (ts-node-dev uses it)
    "esm": true, // Tell ts-node to handle ESM potential
    "experimentalSpecifierResolution": "node" // May help resolution
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}